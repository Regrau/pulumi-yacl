// *** WARNING: this file was generated by the Pulumi Terraform Bridge (tfgen) Tool. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

import * as pulumi from "@pulumi/pulumi";
import * as inputs from "../types/input";
import * as outputs from "../types/output";

export interface AlbBackendGroupGrpcBackend {
    /**
     * Healthcheck specification that will be used by this backend. Structure is documented below.
     */
    healthcheck?: outputs.AlbBackendGroupGrpcBackendHealthcheck;
    /**
     * Load Balancing Config specification that will be used by this backend. Structure is documented below.
     */
    loadBalancingConfig?: outputs.AlbBackendGroupGrpcBackendLoadBalancingConfig;
    /**
     * Name of the backend.
     */
    name: string;
    /**
     * Port for incoming traffic.
     */
    port?: number;
    /**
     * References target groups for the backend.
     */
    targetGroupIds: string[];
    /**
     * Tls specification that will be used by this backend. Structure is documented below.
     */
    tls?: outputs.AlbBackendGroupGrpcBackendTls;
    /**
     * Weight of the backend. Traffic will be split between backends of the same BackendGroup according to their weights.
     */
    weight?: number;
}

export interface AlbBackendGroupGrpcBackendHealthcheck {
    /**
     * Grpc Healthcheck specification that will be used by this healthcheck. Structure is documented below.
     */
    grpcHealthcheck?: outputs.AlbBackendGroupGrpcBackendHealthcheckGrpcHealthcheck;
    /**
     * Optional alternative port for health checking.
     */
    healthcheckPort?: number;
    /**
     * Number of consecutive successful health checks required to promote endpoint into the healthy state. 0 means 1. Note that during startup, only a single successful health check is required to mark a host healthy.
     */
    healthyThreshold?: number;
    /**
     * Http Healthcheck specification that will be used by this healthcheck. Structure is documented below.
     */
    httpHealthcheck?: outputs.AlbBackendGroupGrpcBackendHealthcheckHttpHealthcheck;
    /**
     * Interval between health checks.
     */
    interval: string;
    /**
     * An optional jitter amount as a percentage of interval. If specified, during every interval value of (interval_ms * intervalJitterPercent / 100) will be added to the wait time.
     */
    intervalJitterPercent?: number;
    /**
     * Stream Healthcheck specification that will be used by this healthcheck. Structure is documented below.
     */
    streamHealthcheck?: outputs.AlbBackendGroupGrpcBackendHealthcheckStreamHealthcheck;
    /**
     * Time to wait for a health check response.
     */
    timeout: string;
    /**
     * Number of consecutive failed health checks required to demote endpoint into the unhealthy state. 0 means 1. Note that for HTTP health checks, a single 503 immediately makes endpoint unhealthy.
     */
    unhealthyThreshold?: number;
}

export interface AlbBackendGroupGrpcBackendHealthcheckGrpcHealthcheck {
    /**
     * Service name for grpc.health.v1.HealthCheckRequest message.
     */
    serviceName?: string;
}

export interface AlbBackendGroupGrpcBackendHealthcheckHttpHealthcheck {
    /**
     * "Host" HTTP header value.
     */
    host?: string;
    /**
     * If set, health checks will use HTTP2.
     */
    http2?: boolean;
    /**
     * HTTP path.
     */
    path: string;
}

export interface AlbBackendGroupGrpcBackendHealthcheckStreamHealthcheck {
    /**
     * Data that must be contained in the messages received from targets for a successful health check. If not specified, no messages are expected from targets, and those that are received are not checked.
     */
    receive?: string;
    /**
     * Message sent to targets during TCP data transfer.  If not specified, no data is sent to the target.
     */
    send?: string;
}

export interface AlbBackendGroupGrpcBackendLoadBalancingConfig {
    /**
     * Percent of traffic to be sent to the same availability zone. The rest will be equally divided between other zones.
     */
    localityAwareRoutingPercent?: number;
    /**
     * Load balancing mode for the backend. Possible values: "ROUND_ROBIN", "RANDOM", "LEAST_REQUEST", "MAGLEV_HASH".
     */
    mode?: string;
    /**
     * If percentage of healthy hosts in the backend is lower than panic_threshold, traffic will be routed to all backends no matter what the health status is. This helps to avoid healthy backends overloading  when everything is bad. Zero means no panic threshold.
     */
    panicThreshold?: number;
    /**
     * If set, will route requests only to the same availability zone. Balancer won't know about endpoints in other zones.
     */
    strictLocality?: boolean;
}

export interface AlbBackendGroupGrpcBackendTls {
    /**
     * [SNI](https://en.wikipedia.org/wiki/Server_Name_Indication) string for TLS connections.
     * * `validation_context.0.trusted_ca_id` - (Optional) Trusted CA certificate ID in the Certificate Manager.
     * * `validation_context.0.trusted_ca_bytes` - (Optional) PEM-encoded trusted CA certificate chain.
     */
    sni?: string;
    validationContext?: outputs.AlbBackendGroupGrpcBackendTlsValidationContext;
}

export interface AlbBackendGroupGrpcBackendTlsValidationContext {
    trustedCaBytes?: string;
    trustedCaId?: string;
}

export interface AlbBackendGroupHttpBackend {
    /**
     * Healthcheck specification that will be used by this backend. Structure is documented below.
     */
    healthcheck?: outputs.AlbBackendGroupHttpBackendHealthcheck;
    /**
     * If set, health checks will use HTTP2.
     */
    http2?: boolean;
    /**
     * Load Balancing Config specification that will be used by this backend. Structure is documented below.
     */
    loadBalancingConfig?: outputs.AlbBackendGroupHttpBackendLoadBalancingConfig;
    /**
     * Name of the backend.
     */
    name: string;
    /**
     * Port for incoming traffic.
     */
    port?: number;
    storageBucket?: string;
    /**
     * References target groups for the backend.
     */
    targetGroupIds?: string[];
    /**
     * Tls specification that will be used by this backend. Structure is documented below.
     */
    tls?: outputs.AlbBackendGroupHttpBackendTls;
    /**
     * Weight of the backend. Traffic will be split between backends of the same BackendGroup according to their weights.
     */
    weight?: number;
}

export interface AlbBackendGroupHttpBackendHealthcheck {
    /**
     * Grpc Healthcheck specification that will be used by this healthcheck. Structure is documented below.
     */
    grpcHealthcheck?: outputs.AlbBackendGroupHttpBackendHealthcheckGrpcHealthcheck;
    /**
     * Optional alternative port for health checking.
     */
    healthcheckPort?: number;
    /**
     * Number of consecutive successful health checks required to promote endpoint into the healthy state. 0 means 1. Note that during startup, only a single successful health check is required to mark a host healthy.
     */
    healthyThreshold?: number;
    /**
     * Http Healthcheck specification that will be used by this healthcheck. Structure is documented below.
     */
    httpHealthcheck?: outputs.AlbBackendGroupHttpBackendHealthcheckHttpHealthcheck;
    /**
     * Interval between health checks.
     */
    interval: string;
    /**
     * An optional jitter amount as a percentage of interval. If specified, during every interval value of (interval_ms * intervalJitterPercent / 100) will be added to the wait time.
     */
    intervalJitterPercent?: number;
    /**
     * Stream Healthcheck specification that will be used by this healthcheck. Structure is documented below.
     */
    streamHealthcheck?: outputs.AlbBackendGroupHttpBackendHealthcheckStreamHealthcheck;
    /**
     * Time to wait for a health check response.
     */
    timeout: string;
    /**
     * Number of consecutive failed health checks required to demote endpoint into the unhealthy state. 0 means 1. Note that for HTTP health checks, a single 503 immediately makes endpoint unhealthy.
     */
    unhealthyThreshold?: number;
}

export interface AlbBackendGroupHttpBackendHealthcheckGrpcHealthcheck {
    /**
     * Service name for grpc.health.v1.HealthCheckRequest message.
     */
    serviceName?: string;
}

export interface AlbBackendGroupHttpBackendHealthcheckHttpHealthcheck {
    /**
     * "Host" HTTP header value.
     */
    host?: string;
    /**
     * If set, health checks will use HTTP2.
     */
    http2?: boolean;
    /**
     * HTTP path.
     */
    path: string;
}

export interface AlbBackendGroupHttpBackendHealthcheckStreamHealthcheck {
    /**
     * Data that must be contained in the messages received from targets for a successful health check. If not specified, no messages are expected from targets, and those that are received are not checked.
     */
    receive?: string;
    /**
     * Message sent to targets during TCP data transfer.  If not specified, no data is sent to the target.
     */
    send?: string;
}

export interface AlbBackendGroupHttpBackendLoadBalancingConfig {
    /**
     * Percent of traffic to be sent to the same availability zone. The rest will be equally divided between other zones.
     */
    localityAwareRoutingPercent?: number;
    /**
     * Load balancing mode for the backend. Possible values: "ROUND_ROBIN", "RANDOM", "LEAST_REQUEST", "MAGLEV_HASH".
     */
    mode?: string;
    /**
     * If percentage of healthy hosts in the backend is lower than panic_threshold, traffic will be routed to all backends no matter what the health status is. This helps to avoid healthy backends overloading  when everything is bad. Zero means no panic threshold.
     */
    panicThreshold?: number;
    /**
     * If set, will route requests only to the same availability zone. Balancer won't know about endpoints in other zones.
     */
    strictLocality?: boolean;
}

export interface AlbBackendGroupHttpBackendTls {
    /**
     * [SNI](https://en.wikipedia.org/wiki/Server_Name_Indication) string for TLS connections.
     * * `validation_context.0.trusted_ca_id` - (Optional) Trusted CA certificate ID in the Certificate Manager.
     * * `validation_context.0.trusted_ca_bytes` - (Optional) PEM-encoded trusted CA certificate chain.
     */
    sni?: string;
    validationContext?: outputs.AlbBackendGroupHttpBackendTlsValidationContext;
}

export interface AlbBackendGroupHttpBackendTlsValidationContext {
    trustedCaBytes?: string;
    trustedCaId?: string;
}

export interface AlbBackendGroupSessionAffinity {
    connection?: outputs.AlbBackendGroupSessionAffinityConnection;
    cookie?: outputs.AlbBackendGroupSessionAffinityCookie;
    header?: outputs.AlbBackendGroupSessionAffinityHeader;
}

export interface AlbBackendGroupSessionAffinityConnection {
    sourceIp?: boolean;
}

export interface AlbBackendGroupSessionAffinityCookie {
    /**
     * Name of the backend.
     */
    name: string;
    ttl?: string;
}

export interface AlbBackendGroupSessionAffinityHeader {
    headerName: string;
}

export interface AlbBackendGroupStreamBackend {
    enableProxyProtocol?: boolean;
    /**
     * Healthcheck specification that will be used by this backend. Structure is documented below.
     */
    healthcheck?: outputs.AlbBackendGroupStreamBackendHealthcheck;
    /**
     * Load Balancing Config specification that will be used by this backend. Structure is documented below.
     */
    loadBalancingConfig?: outputs.AlbBackendGroupStreamBackendLoadBalancingConfig;
    /**
     * Name of the backend.
     */
    name: string;
    /**
     * Port for incoming traffic.
     */
    port?: number;
    /**
     * References target groups for the backend.
     */
    targetGroupIds: string[];
    /**
     * Tls specification that will be used by this backend. Structure is documented below.
     */
    tls?: outputs.AlbBackendGroupStreamBackendTls;
    /**
     * Weight of the backend. Traffic will be split between backends of the same BackendGroup according to their weights.
     */
    weight?: number;
}

export interface AlbBackendGroupStreamBackendHealthcheck {
    /**
     * Grpc Healthcheck specification that will be used by this healthcheck. Structure is documented below.
     */
    grpcHealthcheck?: outputs.AlbBackendGroupStreamBackendHealthcheckGrpcHealthcheck;
    /**
     * Optional alternative port for health checking.
     */
    healthcheckPort?: number;
    /**
     * Number of consecutive successful health checks required to promote endpoint into the healthy state. 0 means 1. Note that during startup, only a single successful health check is required to mark a host healthy.
     */
    healthyThreshold?: number;
    /**
     * Http Healthcheck specification that will be used by this healthcheck. Structure is documented below.
     */
    httpHealthcheck?: outputs.AlbBackendGroupStreamBackendHealthcheckHttpHealthcheck;
    /**
     * Interval between health checks.
     */
    interval: string;
    /**
     * An optional jitter amount as a percentage of interval. If specified, during every interval value of (interval_ms * intervalJitterPercent / 100) will be added to the wait time.
     */
    intervalJitterPercent?: number;
    /**
     * Stream Healthcheck specification that will be used by this healthcheck. Structure is documented below.
     */
    streamHealthcheck?: outputs.AlbBackendGroupStreamBackendHealthcheckStreamHealthcheck;
    /**
     * Time to wait for a health check response.
     */
    timeout: string;
    /**
     * Number of consecutive failed health checks required to demote endpoint into the unhealthy state. 0 means 1. Note that for HTTP health checks, a single 503 immediately makes endpoint unhealthy.
     */
    unhealthyThreshold?: number;
}

export interface AlbBackendGroupStreamBackendHealthcheckGrpcHealthcheck {
    /**
     * Service name for grpc.health.v1.HealthCheckRequest message.
     */
    serviceName?: string;
}

export interface AlbBackendGroupStreamBackendHealthcheckHttpHealthcheck {
    /**
     * "Host" HTTP header value.
     */
    host?: string;
    /**
     * If set, health checks will use HTTP2.
     */
    http2?: boolean;
    /**
     * HTTP path.
     */
    path: string;
}

export interface AlbBackendGroupStreamBackendHealthcheckStreamHealthcheck {
    /**
     * Data that must be contained in the messages received from targets for a successful health check. If not specified, no messages are expected from targets, and those that are received are not checked.
     */
    receive?: string;
    /**
     * Message sent to targets during TCP data transfer.  If not specified, no data is sent to the target.
     */
    send?: string;
}

export interface AlbBackendGroupStreamBackendLoadBalancingConfig {
    /**
     * Percent of traffic to be sent to the same availability zone. The rest will be equally divided between other zones.
     */
    localityAwareRoutingPercent?: number;
    /**
     * Load balancing mode for the backend. Possible values: "ROUND_ROBIN", "RANDOM", "LEAST_REQUEST", "MAGLEV_HASH".
     */
    mode?: string;
    /**
     * If percentage of healthy hosts in the backend is lower than panic_threshold, traffic will be routed to all backends no matter what the health status is. This helps to avoid healthy backends overloading  when everything is bad. Zero means no panic threshold.
     */
    panicThreshold?: number;
    /**
     * If set, will route requests only to the same availability zone. Balancer won't know about endpoints in other zones.
     */
    strictLocality?: boolean;
}

export interface AlbBackendGroupStreamBackendTls {
    /**
     * [SNI](https://en.wikipedia.org/wiki/Server_Name_Indication) string for TLS connections.
     * * `validation_context.0.trusted_ca_id` - (Optional) Trusted CA certificate ID in the Certificate Manager.
     * * `validation_context.0.trusted_ca_bytes` - (Optional) PEM-encoded trusted CA certificate chain.
     */
    sni?: string;
    validationContext?: outputs.AlbBackendGroupStreamBackendTlsValidationContext;
}

export interface AlbBackendGroupStreamBackendTlsValidationContext {
    trustedCaBytes?: string;
    trustedCaId?: string;
}

export interface AlbHttpRouterRouteOptions {
    rbac?: outputs.AlbHttpRouterRouteOptionsRbac;
}

export interface AlbHttpRouterRouteOptionsRbac {
    action?: string;
    principals: outputs.AlbHttpRouterRouteOptionsRbacPrincipal[];
}

export interface AlbHttpRouterRouteOptionsRbacPrincipal {
    andPrincipals: outputs.AlbHttpRouterRouteOptionsRbacPrincipalAndPrincipal[];
}

export interface AlbHttpRouterRouteOptionsRbacPrincipalAndPrincipal {
    any?: boolean;
    header?: outputs.AlbHttpRouterRouteOptionsRbacPrincipalAndPrincipalHeader;
    remoteIp?: string;
}

export interface AlbHttpRouterRouteOptionsRbacPrincipalAndPrincipalHeader {
    /**
     * Name of the HTTP Router. Provided by the client when the HTTP Router is created.
     */
    name: string;
    value?: outputs.AlbHttpRouterRouteOptionsRbacPrincipalAndPrincipalHeaderValue;
}

export interface AlbHttpRouterRouteOptionsRbacPrincipalAndPrincipalHeaderValue {
    exact?: string;
    prefix?: string;
    regex?: string;
}

export interface AlbLoadBalancerAllocationPolicy {
    /**
     * Unique set of locations. The structure is documented below.
     */
    locations: outputs.AlbLoadBalancerAllocationPolicyLocation[];
}

export interface AlbLoadBalancerAllocationPolicyLocation {
    /**
     * If set, will disable all L7 instances in the zone for request handling.
     */
    disableTraffic?: boolean;
    /**
     * Provided by the client or computed automatically.
     */
    subnetId: string;
    /**
     * ID of the zone that location is located at.
     */
    zoneId: string;
}

export interface AlbLoadBalancerListener {
    /**
     * Network endpoints (addresses and ports) of the listener. The structure is documented below.
     */
    endpoints?: outputs.AlbLoadBalancerListenerEndpoint[];
    /**
     * HTTP listener resource. The structure is documented below.
     */
    http?: outputs.AlbLoadBalancerListenerHttp;
    /**
     * name of SNI match.
     */
    name: string;
    /**
     * Stream listener resource. The structure is documented below.
     */
    stream?: outputs.AlbLoadBalancerListenerStream;
    /**
     * TLS listener resource. The structure is documented below.
     */
    tls?: outputs.AlbLoadBalancerListenerTls;
}

export interface AlbLoadBalancerListenerEndpoint {
    /**
     * Provided by the client or computed automatically.
     */
    addresses: outputs.AlbLoadBalancerListenerEndpointAddress[];
    /**
     * One or more ports to listen on.
     */
    ports: number[];
}

export interface AlbLoadBalancerListenerEndpointAddress {
    /**
     * External IPv4 address. The structure is documented below.
     */
    externalIpv4Address?: outputs.AlbLoadBalancerListenerEndpointAddressExternalIpv4Address;
    /**
     * External IPv6 address. The structure is documented below.
     */
    externalIpv6Address?: outputs.AlbLoadBalancerListenerEndpointAddressExternalIpv6Address;
    /**
     * Internal IPv4 address. The structure is documented below.
     */
    internalIpv4Address?: outputs.AlbLoadBalancerListenerEndpointAddressInternalIpv4Address;
}

export interface AlbLoadBalancerListenerEndpointAddressExternalIpv4Address {
    /**
     * Provided by the client or computed automatically.
     */
    address: string;
}

export interface AlbLoadBalancerListenerEndpointAddressExternalIpv6Address {
    /**
     * Provided by the client or computed automatically.
     */
    address: string;
}

export interface AlbLoadBalancerListenerEndpointAddressInternalIpv4Address {
    /**
     * Provided by the client or computed automatically.
     */
    address: string;
    /**
     * Provided by the client or computed automatically.
     */
    subnetId: string;
}

export interface AlbLoadBalancerListenerHttp {
    /**
     * HTTP handler that sets plaintext HTTP router. The structure is documented below.
     */
    handler?: outputs.AlbLoadBalancerListenerHttpHandler;
    /**
     * Shortcut for adding http > https redirects. The structure is documented below.
     */
    redirects?: outputs.AlbLoadBalancerListenerHttpRedirects;
}

export interface AlbLoadBalancerListenerHttpHandler {
    /**
     * If set, will enable only HTTP1 protocol with HTTP1.0 support.
     */
    allowHttp10?: boolean;
    /**
     * If set, will enable HTTP2 protocol for the handler. The structure is documented below.
     */
    http2Options?: outputs.AlbLoadBalancerListenerHttpHandlerHttp2Options;
    /**
     * HTTP router id.
     */
    httpRouterId?: string;
    /**
     * When unset, will preserve the incoming x-request-id header, otherwise would rewrite it with a new value.
     */
    rewriteRequestId?: boolean;
}

export interface AlbLoadBalancerListenerHttpHandlerHttp2Options {
    /**
     * Maximum number of concurrent streams.
     */
    maxConcurrentStreams?: number;
}

export interface AlbLoadBalancerListenerHttpRedirects {
    /**
     * If set redirects all unencrypted HTTP requests to the same URI with scheme changed to `https`.
     */
    httpToHttps?: boolean;
}

export interface AlbLoadBalancerListenerStream {
    /**
     * HTTP handler that sets plaintext HTTP router. The structure is documented below.
     */
    handler?: outputs.AlbLoadBalancerListenerStreamHandler;
}

export interface AlbLoadBalancerListenerStreamHandler {
    /**
     * Backend group id.
     */
    backendGroupId?: string;
}

export interface AlbLoadBalancerListenerTls {
    /**
     * TLS handler resource. The structure is documented below.
     */
    defaultHandler: outputs.AlbLoadBalancerListenerTlsDefaultHandler;
    /**
     * SNI match resource. The structure is documented below.
     */
    sniHandlers?: outputs.AlbLoadBalancerListenerTlsSniHandler[];
}

export interface AlbLoadBalancerListenerTlsDefaultHandler {
    /**
     * Certificate IDs in the Certificate Manager. Multiple TLS certificates can be associated
     * with the same context to allow both RSA and ECDSA certificates. Only the first certificate of each type will be used.
     */
    certificateIds: string[];
    /**
     * HTTP handler resource. The structure is documented below.
     */
    httpHandler?: outputs.AlbLoadBalancerListenerTlsDefaultHandlerHttpHandler;
    /**
     * Stream handler resource. The structure is documented below.
     */
    streamHandler?: outputs.AlbLoadBalancerListenerTlsDefaultHandlerStreamHandler;
}

export interface AlbLoadBalancerListenerTlsDefaultHandlerHttpHandler {
    /**
     * If set, will enable only HTTP1 protocol with HTTP1.0 support.
     */
    allowHttp10?: boolean;
    /**
     * If set, will enable HTTP2 protocol for the handler. The structure is documented below.
     */
    http2Options?: outputs.AlbLoadBalancerListenerTlsDefaultHandlerHttpHandlerHttp2Options;
    /**
     * HTTP router id.
     */
    httpRouterId?: string;
    /**
     * When unset, will preserve the incoming x-request-id header, otherwise would rewrite it with a new value.
     */
    rewriteRequestId?: boolean;
}

export interface AlbLoadBalancerListenerTlsDefaultHandlerHttpHandlerHttp2Options {
    /**
     * Maximum number of concurrent streams.
     */
    maxConcurrentStreams?: number;
}

export interface AlbLoadBalancerListenerTlsDefaultHandlerStreamHandler {
    /**
     * Backend group id.
     */
    backendGroupId?: string;
}

export interface AlbLoadBalancerListenerTlsSniHandler {
    /**
     * HTTP handler that sets plaintext HTTP router. The structure is documented below.
     */
    handler: outputs.AlbLoadBalancerListenerTlsSniHandlerHandler;
    /**
     * name of SNI match.
     */
    name: string;
    /**
     * A set of server names.
     */
    serverNames: string[];
}

export interface AlbLoadBalancerListenerTlsSniHandlerHandler {
    /**
     * Certificate IDs in the Certificate Manager. Multiple TLS certificates can be associated
     * with the same context to allow both RSA and ECDSA certificates. Only the first certificate of each type will be used.
     */
    certificateIds: string[];
    /**
     * HTTP handler resource. The structure is documented below.
     */
    httpHandler?: outputs.AlbLoadBalancerListenerTlsSniHandlerHandlerHttpHandler;
    /**
     * Stream handler resource. The structure is documented below.
     */
    streamHandler?: outputs.AlbLoadBalancerListenerTlsSniHandlerHandlerStreamHandler;
}

export interface AlbLoadBalancerListenerTlsSniHandlerHandlerHttpHandler {
    /**
     * If set, will enable only HTTP1 protocol with HTTP1.0 support.
     */
    allowHttp10?: boolean;
    /**
     * If set, will enable HTTP2 protocol for the handler. The structure is documented below.
     */
    http2Options?: outputs.AlbLoadBalancerListenerTlsSniHandlerHandlerHttpHandlerHttp2Options;
    /**
     * HTTP router id.
     */
    httpRouterId?: string;
    /**
     * When unset, will preserve the incoming x-request-id header, otherwise would rewrite it with a new value.
     */
    rewriteRequestId?: boolean;
}

export interface AlbLoadBalancerListenerTlsSniHandlerHandlerHttpHandlerHttp2Options {
    /**
     * Maximum number of concurrent streams.
     */
    maxConcurrentStreams?: number;
}

export interface AlbLoadBalancerListenerTlsSniHandlerHandlerStreamHandler {
    /**
     * Backend group id.
     */
    backendGroupId?: string;
}

export interface AlbLoadBalancerLogOptions {
    /**
     * Set to true to disable Cloud Logging for the balancer
     */
    disable?: boolean;
    /**
     * List of rules to discard a fraction of logs. The structure is documented below.
     */
    discardRules?: outputs.AlbLoadBalancerLogOptionsDiscardRule[];
    /**
     * Cloud Logging group ID to send logs to. Leave empty to use the balancer folder default log group.
     */
    logGroupId?: string;
}

export interface AlbLoadBalancerLogOptionsDiscardRule {
    discardPercent?: number;
    /**
     * list of grpc codes by name, e.g, _["NOT_FOUND", "RESOURCE_EXHAUSTED"]_
     */
    grpcCodes?: string[];
    /**
     * list of http code intervals _1XX_-_5XX_ or _ALL_
     */
    httpCodeIntervals?: string[];
    /**
     * list of http codes _100_-_599_
     */
    httpCodes?: number[];
}

export interface AlbTargetGroupTarget {
    /**
     * IP address of the target.
     */
    ipAddress: string;
    privateIpv4Address?: boolean;
    /**
     * ID of the subnet that targets are connected to.
     * All targets in the target group must be connected to the same subnet within a single availability zone.
     */
    subnetId?: string;
}

export interface AlbVirtualHostModifyRequestHeader {
    /**
     * Append string to the header value.
     */
    append?: string;
    /**
     * name of the route.
     */
    name: string;
    /**
     * If set, remove the header.
     */
    remove?: boolean;
    /**
     * New value for a header. Header values support the following 
     * [formatters](https://www.envoyproxy.io/docs/envoy/latest/configuration/http/http_conn_man/headers#custom-request-response-headers).
     */
    replace?: string;
}

export interface AlbVirtualHostModifyResponseHeader {
    /**
     * Append string to the header value.
     */
    append?: string;
    /**
     * name of the route.
     */
    name: string;
    /**
     * If set, remove the header.
     */
    remove?: boolean;
    /**
     * New value for a header. Header values support the following 
     * [formatters](https://www.envoyproxy.io/docs/envoy/latest/configuration/http/http_conn_man/headers#custom-request-response-headers).
     */
    replace?: string;
}

export interface AlbVirtualHostRoute {
    /**
     * GRPC route resource. The structure is documented below.
     */
    grpcRoute?: outputs.AlbVirtualHostRouteGrpcRoute;
    /**
     * HTTP route resource. The structure is documented below.
     */
    httpRoute?: outputs.AlbVirtualHostRouteHttpRoute;
    /**
     * name of the route.
     */
    name?: string;
    routeOptions?: outputs.AlbVirtualHostRouteRouteOptions;
}

export interface AlbVirtualHostRouteGrpcRoute {
    /**
     * Checks "/" prefix by default. The structure is documented below.
     */
    grpcMatches?: outputs.AlbVirtualHostRouteGrpcRouteGrpcMatch[];
    /**
     * GRPC route action resource. The structure is documented below.
     */
    grpcRouteAction?: outputs.AlbVirtualHostRouteGrpcRouteGrpcRouteAction;
    /**
     * GRPC status response action resource. The structure is documented below.
     */
    grpcStatusResponseAction?: outputs.AlbVirtualHostRouteGrpcRouteGrpcStatusResponseAction;
}

export interface AlbVirtualHostRouteGrpcRouteGrpcMatch {
    /**
     * If not set, all services/methods are assumed. The structure is documented below.
     */
    fqmn?: outputs.AlbVirtualHostRouteGrpcRouteGrpcMatchFqmn;
}

export interface AlbVirtualHostRouteGrpcRouteGrpcMatchFqmn {
    /**
     * Match exactly.
     */
    exact?: string;
    /**
     * Match prefix.
     */
    prefix?: string;
    /**
     * Match regex.
     */
    regex?: string;
}

export interface AlbVirtualHostRouteGrpcRouteGrpcRouteAction {
    /**
     * If set, will automatically rewrite host.
     */
    autoHostRewrite?: boolean;
    /**
     * Backend group to route requests.
     */
    backendGroupId: string;
    /**
     * Host rewrite specifier.
     */
    hostRewrite?: string;
    /**
     * Specifies the idle timeout (time without any data transfer for the active request) for the
     * route. It is useful for streaming scenarios - one should set idleTimeout to something meaningful and maxTimeout
     * to the maximum time the stream is allowed to be alive. If not specified, there is no
     * per-route idle timeout.
     */
    idleTimeout?: string;
    /**
     * Lower timeout may be specified by the client (using grpc-timeout header). If not set, default is 
     * 60 seconds.
     */
    maxTimeout?: string;
}

export interface AlbVirtualHostRouteGrpcRouteGrpcStatusResponseAction {
    /**
     * The status of the response. Supported values are: ok, invalid_argumet, not_found, 
     * permission_denied, unauthenticated, unimplemented, internal, unavailable.
     */
    status?: string;
}

export interface AlbVirtualHostRouteHttpRoute {
    /**
     * Direct response action resource. The structure is documented below.
     */
    directResponseAction?: outputs.AlbVirtualHostRouteHttpRouteDirectResponseAction;
    /**
     * Checks "/" prefix by default. The structure is documented below.
     */
    httpMatches?: outputs.AlbVirtualHostRouteHttpRouteHttpMatch[];
    /**
     * HTTP route action resource. The structure is documented below.
     */
    httpRouteAction?: outputs.AlbVirtualHostRouteHttpRouteHttpRouteAction;
    /**
     * Redirect action resource. The structure is documented below.
     */
    redirectAction?: outputs.AlbVirtualHostRouteHttpRouteRedirectAction;
}

export interface AlbVirtualHostRouteHttpRouteDirectResponseAction {
    /**
     * Response body text.
     */
    body?: string;
    /**
     * The status of the response. Supported values are: ok, invalid_argumet, not_found, 
     * permission_denied, unauthenticated, unimplemented, internal, unavailable.
     */
    status?: number;
}

export interface AlbVirtualHostRouteHttpRouteHttpMatch {
    /**
     * List of methods(strings).
     */
    httpMethods?: string[];
    /**
     * If not set, '/' is assumed. The structure is documented below.
     */
    path?: outputs.AlbVirtualHostRouteHttpRouteHttpMatchPath;
}

export interface AlbVirtualHostRouteHttpRouteHttpMatchPath {
    /**
     * Match exactly.
     */
    exact?: string;
    /**
     * Match prefix.
     */
    prefix?: string;
    /**
     * Match regex.
     */
    regex?: string;
}

export interface AlbVirtualHostRouteHttpRouteHttpRouteAction {
    /**
     * If set, will automatically rewrite host.
     */
    autoHostRewrite?: boolean;
    /**
     * Backend group to route requests.
     */
    backendGroupId: string;
    /**
     * Host rewrite specifier.
     */
    hostRewrite?: string;
    /**
     * Specifies the idle timeout (time without any data transfer for the active request) for the
     * route. It is useful for streaming scenarios - one should set idleTimeout to something meaningful and maxTimeout
     * to the maximum time the stream is allowed to be alive. If not specified, there is no
     * per-route idle timeout.
     */
    idleTimeout?: string;
    /**
     * If not empty, matched path prefix will be replaced by this value.
     */
    prefixRewrite?: string;
    /**
     * Specifies the request timeout (overall time request processing is allowed to take) for the 
     * route. If not set, default is 60 seconds.
     */
    timeout?: string;
    /**
     * List of upgrade types. Only specified upgrade types will be allowed. For example, 
     * "websocket".
     */
    upgradeTypes?: string[];
}

export interface AlbVirtualHostRouteHttpRouteRedirectAction {
    removeQuery?: boolean;
    /**
     * Replaces hostname.
     */
    replaceHost?: string;
    /**
     * Replace path.
     */
    replacePath?: string;
    /**
     * Replaces port.
     */
    replacePort?: number;
    /**
     * Replace only matched prefix. Example:<br/> match:{ prefix_match: "/some" } <br/> 
     * redirect: { replace_prefix: "/other" } <br/> will redirect "/something" to "/otherthing".
     */
    replacePrefix?: string;
    /**
     * Replaces scheme. If the original scheme is `http` or `https`, will also remove the 
     * 80 or 443 port, if present.
     */
    replaceScheme?: string;
    /**
     * The HTTP status code to use in the redirect response. Supported values are: 
     * moved_permanently, found, see_other, temporary_redirect, permanent_redirect.
     */
    responseCode?: string;
}

export interface AlbVirtualHostRouteOptions {
    rbac?: outputs.AlbVirtualHostRouteOptionsRbac;
}

export interface AlbVirtualHostRouteOptionsRbac {
    action?: string;
    principals: outputs.AlbVirtualHostRouteOptionsRbacPrincipal[];
}

export interface AlbVirtualHostRouteOptionsRbacPrincipal {
    andPrincipals: outputs.AlbVirtualHostRouteOptionsRbacPrincipalAndPrincipal[];
}

export interface AlbVirtualHostRouteOptionsRbacPrincipalAndPrincipal {
    any?: boolean;
    header?: outputs.AlbVirtualHostRouteOptionsRbacPrincipalAndPrincipalHeader;
    remoteIp?: string;
}

export interface AlbVirtualHostRouteOptionsRbacPrincipalAndPrincipalHeader {
    /**
     * name of the route.
     */
    name: string;
    value?: outputs.AlbVirtualHostRouteOptionsRbacPrincipalAndPrincipalHeaderValue;
}

export interface AlbVirtualHostRouteOptionsRbacPrincipalAndPrincipalHeaderValue {
    /**
     * Match exactly.
     */
    exact?: string;
    /**
     * Match prefix.
     */
    prefix?: string;
    /**
     * Match regex.
     */
    regex?: string;
}

export interface AlbVirtualHostRouteRouteOptions {
    rbac?: outputs.AlbVirtualHostRouteRouteOptionsRbac;
}

export interface AlbVirtualHostRouteRouteOptionsRbac {
    action?: string;
    principals: outputs.AlbVirtualHostRouteRouteOptionsRbacPrincipal[];
}

export interface AlbVirtualHostRouteRouteOptionsRbacPrincipal {
    andPrincipals: outputs.AlbVirtualHostRouteRouteOptionsRbacPrincipalAndPrincipal[];
}

export interface AlbVirtualHostRouteRouteOptionsRbacPrincipalAndPrincipal {
    any?: boolean;
    header?: outputs.AlbVirtualHostRouteRouteOptionsRbacPrincipalAndPrincipalHeader;
    remoteIp?: string;
}

export interface AlbVirtualHostRouteRouteOptionsRbacPrincipalAndPrincipalHeader {
    /**
     * name of the route.
     */
    name: string;
    value?: outputs.AlbVirtualHostRouteRouteOptionsRbacPrincipalAndPrincipalHeaderValue;
}

export interface AlbVirtualHostRouteRouteOptionsRbacPrincipalAndPrincipalHeaderValue {
    /**
     * Match exactly.
     */
    exact?: string;
    /**
     * Match prefix.
     */
    prefix?: string;
    /**
     * Match regex.
     */
    regex?: string;
}

export interface ApiGatewayCanary {
    /**
     * A set of values for variables in gateway specification.
     */
    variables?: {[key: string]: string};
    weight?: number;
}

export interface ApiGatewayConnectivity {
    networkId: string;
}

export interface ApiGatewayCustomDomain {
    certificateId: string;
    domainId: string;
    fqdn: string;
}

export interface BackupPolicyReattempts {
    /**
     * — enables or disables scheduling.
     */
    enabled?: boolean;
    /**
     * — Retry interval. See `intervalType` for available values
     */
    interval?: string;
    /**
     * — Maximum number of attempts before throwing an error
     */
    maxAttempts?: number;
}

export interface BackupPolicyRetention {
    /**
     * — Defines whether retention rule applies after creating backup or before.
     */
    afterBackup?: boolean;
    rules?: outputs.BackupPolicyRetentionRule[];
}

export interface BackupPolicyRetentionRule {
    /**
     * — Deletes backups that older than `maxAge`. Exactly one of `maxCount` or `maxAge` should be set.
     */
    maxAge?: string;
    /**
     * — Deletes backups if it's count exceeds `maxCount`. Exactly one of `maxCount` or `maxAge` should be set.
     */
    maxCount?: number;
    repeatPeriods?: string[];
}

export interface BackupPolicyScheduling {
    /**
     * — enables or disables scheduling.
     */
    enabled?: boolean;
    /**
     * — Perform backup by interval, since last backup of the host. Maximum value is: 9999 days.
     * See `intervalType` for available values. Exactly on of options should be set: `executeByInterval` or `executeByTime`.
     */
    executeByInterval?: number;
    /**
     * — Perform backup periodically at specific time. Exactly on of options should be set: `executeByInterval` or `executeByTime`.
     */
    executeByTimes?: outputs.BackupPolicySchedulingExecuteByTime[];
    /**
     * — Maximum number of backup processes allowed to run in parallel. 0 for unlimited.
     */
    maxParallelBackups?: number;
    /**
     * — Configuration of the random delay between the execution of parallel tasks.
     * See `intervalType` for available values.
     */
    randomMaxDelay?: string;
    /**
     * — Scheme of the backups.
     * Available values are: `"ALWAYS_INCREMENTAL"`, `"ALWAYS_FULL"`, `"WEEKLY_FULL_DAILY_INCREMENTAL"`, `'WEEKLY_INCREMENTAL"`.
     */
    scheme?: string;
    /**
     * — A day of week to start weekly backups.
     * See `dayType` for available values.
     */
    weeklyBackupDay?: string;
}

export interface BackupPolicySchedulingExecuteByTime {
    /**
     * — If true, schedule will be applied on the last day of month.
     * See `dayType` for available values.
     */
    includeLastDayOfMonth?: boolean;
    /**
     * — List of days when schedule applies. Used in `"MONTHLY"` type.
     */
    monthdays?: number[];
    months?: number[];
    /**
     * — List of time in format `"HH:MM" (24-hours format)`, when the schedule applies.
     */
    repeatAts?: string[];
    /**
     * — Frequency of backup repetition. See `intervalType` for available values.
     */
    repeatEvery?: string;
    /**
     * — Type of the scheduling. Available values are: `"HOURLY"`, `"DAILY"`, `"WEEKLY"`, `"MONTHLY"`.
     */
    type: string;
    /**
     * — List of weekdays when the backup will be applied. Used in `"WEEKLY"` type.
     */
    weekdays?: string[];
}

export interface BackupPolicyVmSnapshotReattempts {
    /**
     * — enables or disables scheduling.
     */
    enabled?: boolean;
    /**
     * — Retry interval. See `intervalType` for available values
     */
    interval?: string;
    /**
     * — Maximum number of attempts before throwing an error
     */
    maxAttempts?: number;
}

export interface CdnOriginGroupOrigin {
    backup?: boolean;
    enabled?: boolean;
    originGroupId: number;
    source: string;
}

export interface CdnResourceOptions {
    /**
     * HTTP methods for your CDN content. By default the following methods are allowed: GET, HEAD, POST, PUT, PATCH, DELETE, OPTIONS. In case some methods are not allowed to the user, they will get the 405 (Method Not Allowed) response. If the method is not supported, the user gets the 501 (Not Implemented) response.
     */
    allowedHttpMethods: string[];
    /**
     * set up a cache period for the end-users browser. Content will be cached due to origin settings. If there are no cache settings on your origin, the content will not be cached. The list of HTTP response codes that can be cached in browsers: 200, 201, 204, 206, 301, 302, 303, 304, 307, 308. Other response codes will not be cached. The default value is 4 days.
     */
    browserCacheSettings: number;
    /**
     * list HTTP headers that must be included in responses to clients.
     */
    cacheHttpHeaders: string[];
    /**
     * parameter that lets browsers get access to selected resources from a domain different to a domain from which the request is received.
     */
    cors: string[];
    /**
     * custom value for the Host header. Your server must be able to process requests with the chosen header.
     */
    customHostHeader: string;
    /**
     * wildcard additional CNAME. If a resource has a wildcard additional CNAME, you can use your own certificate for content delivery via HTTPS. Read-only.
     */
    customServerName: string;
    /**
     * setup a cache status.
     */
    disableCache: boolean;
    /**
     * disabling proxy force ranges.
     */
    disableProxyForceRanges: boolean;
    /**
     * content will be cached according to origin cache settings. The value applies for a response with codes 200, 201, 204, 206, 301, 302, 303, 304, 307, 308 if an origin server does not have caching HTTP headers. Responses with other codes will not be cached.
     */
    edgeCacheSettings: number;
    /**
     * option helps you to reduce the bandwidth between origin and CDN servers. Also, content delivery speed becomes higher because of reducing the time for compressing files in a CDN.
     */
    fetchedCompressed: boolean;
    /**
     * choose the Forward Host header option if is important to send in the request to the Origin the same Host header as was sent in the request to CDN server.
     */
    forwardHostHeader: boolean;
    /**
     * GZip compression at CDN servers reduces file size by 70% and can be as high as 90%.
     */
    gzipOn: boolean;
    /**
     * set for ignoring cookie.
     */
    ignoreCookie: boolean;
    /**
     * files with different query parameters are cached as objects with the same key regardless of the parameter value. selected by default.
     */
    ignoreQueryParams: boolean;
    /**
     * allows caching for GET, HEAD and POST requests.
     */
    proxyCacheMethodsSet: boolean;
    /**
     * files with the specified query parameters are cached as objects with the same key, files with other parameters are cached as objects with different keys.
     */
    queryParamsBlacklists: string[];
    /**
     * files with the specified query parameters are cached as objects with different keys, files with other parameters are cached as objects with the same key.
     */
    queryParamsWhitelists: string[];
    /**
     * set up a redirect from HTTP to HTTPS.
     */
    redirectHttpToHttps: boolean;
    /**
     * set up a redirect from HTTPS to HTTP.
     */
    redirectHttpsToHttp: boolean;
    /**
     * files larger than 10 MB will be requested and cached in parts (no larger than 10 MB each part). It reduces time to first byte. The origin must support HTTP Range requests.
     */
    slice: boolean;
    /**
     * set up custom headers that CDN servers will send in requests to origins.
     */
    staticRequestHeaders: {[key: string]: string};
    /**
     * set up custom headers that CDN servers will send in response to clients.
     */
    staticResponseHeaders: {[key: string]: string};
}

export interface CdnResourceSslCertificate {
    certificateManagerId?: string;
    status: string;
    type: string;
}

export interface CmCertificateChallenge {
    /**
     * Time the challenge was created.
     */
    createdAt: string;
    /**
     * DNS record name (only for DNS challenge).
     */
    dnsName: string;
    /**
     * DNS record type: `"TXT"` or `"CNAME"` (only for DNS challenge).
     */
    dnsType: string;
    /**
     * DNS record value (only for DNS challenge).
     */
    dnsValue: string;
    /**
     * Validated domain.
     */
    domain: string;
    /**
     * The content that should be made accessible with the given `httpUrl` (only for HTTP challenge).
     */
    httpContent: string;
    /**
     * URL where the challenge content httpContent should be placed (only for HTTP challenge).
     */
    httpUrl: string;
    /**
     * Current status message.
     */
    message: string;
    /**
     * Challenge type `"DNS"` or `"HTTP"`.
     */
    type: string;
    /**
     * Last time the challenge was updated.
     */
    updatedAt: string;
}

export interface CmCertificateManaged {
    /**
     * . Expected number of challenge count needed to validate certificate. 
     * Resource creation will fail if the specified value does not match the actual number of challenges received from issue provider.
     * This argument is helpful for safe automatic resource creation for passing challenges for multi-domain certificates.
     */
    challengeCount?: number;
    /**
     * Domain owner-check method. Possible values:
     * - "DNS_CNAME" - you will need to create a CNAME dns record with the specified value. Recommended for fully automated certificate renewal;
     * - "DNS_TXT" - you will need to create a TXT dns record with specified value;
     * - "HTTP" - you will need to place specified value into specified url.
     */
    challengeType: string;
}

export interface CmCertificateSelfManaged {
    /**
     * Certificate with chain.
     */
    certificate: string;
    /**
     * Private key of certificate.
     */
    privateKey?: string;
    /**
     * Lockbox secret specification for getting private key. Structure is documented below.
     */
    privateKeyLockboxSecret?: outputs.CmCertificateSelfManagedPrivateKeyLockboxSecret;
}

export interface CmCertificateSelfManagedPrivateKeyLockboxSecret {
    /**
     * Lockbox secret Id.
     */
    id: string;
    /**
     * Key of the Lockbox secret, the value of which contains the private key of the certificate.
     */
    key: string;
}

export interface ComputeDiskDiskPlacementPolicy {
    /**
     * Specifies Disk Placement Group id.
     */
    diskPlacementGroupId: string;
}

export interface ComputeInstanceBootDisk {
    /**
     * Whether the disk is auto-deleted when the instance
     * is deleted. The default value is false.
     */
    autoDelete?: boolean;
    /**
     * Name of the device representing the filesystem on the instance.
     */
    deviceName: string;
    /**
     * ID of the disk that is attached to the instance.
     */
    diskId: string;
    /**
     * Parameters for a new disk that will be created
     * alongside the new instance. Either `initializeParams` or `diskId` must be set. The structure is documented below.
     */
    initializeParams: outputs.ComputeInstanceBootDiskInitializeParams;
    /**
     * Mode of access to the filesystem that should be attached. By default, filesystem is attached 
     * in `READ_WRITE` mode.
     */
    mode: string;
}

export interface ComputeInstanceBootDiskInitializeParams {
    /**
     * Block size of the disk, specified in bytes.
     */
    blockSize: number;
    /**
     * Description of the boot disk.
     */
    description: string;
    /**
     * A disk image to initialize this disk from.
     */
    imageId: string;
    /**
     * Name of the boot disk.
     */
    name: string;
    /**
     * Size of the disk in GB.
     */
    size: number;
    /**
     * A snapshot to initialize this disk from.
     */
    snapshotId: string;
    /**
     * Disk type.
     */
    type?: string;
}

export interface ComputeInstanceFilesystem {
    /**
     * Name of the device representing the filesystem on the instance.
     */
    deviceName: string;
    /**
     * ID of the filesystem that should be attached.
     */
    filesystemId: string;
    /**
     * Mode of access to the filesystem that should be attached. By default, filesystem is attached 
     * in `READ_WRITE` mode.
     */
    mode?: string;
}

export interface ComputeInstanceGroupAllocationPolicy {
    /**
     * A list of availability zones.
     */
    zones: string[];
}

export interface ComputeInstanceGroupApplicationLoadBalancer {
    /**
     * Timeout for waiting for the VM to be checked by the load balancer. If the timeout is exceeded, the VM will be turned off based on the deployment policy. Specified in seconds.
     */
    maxOpeningTrafficDuration?: number;
    /**
     * The status message of the instance.
     */
    statusMessage: string;
    /**
     * A description of the target group.
     */
    targetGroupDescription?: string;
    targetGroupId: string;
    /**
     * A set of key/value label pairs.
     */
    targetGroupLabels?: {[key: string]: string};
    /**
     * The name of the target group.
     */
    targetGroupName?: string;
}

export interface ComputeInstanceGroupDeployPolicy {
    /**
     * The maximum number of instances that can be created at the same time.
     */
    maxCreating?: number;
    /**
     * The maximum number of instances that can be deleted at the same time.
     */
    maxDeleting?: number;
    /**
     * The maximum number of instances that can be temporarily allocated above the group's target size
     * during the update process.
     */
    maxExpansion: number;
    /**
     * The maximum number of running instances that can be taken offline (stopped or deleted) at the same time
     * during the update process.
     */
    maxUnavailable: number;
    /**
     * The amount of time in seconds to allow for an instance to start.
     * Instance will be considered up and running (and start receiving traffic) only after the startupDuration
     * has elapsed and all health checks are passed.
     */
    startupDuration?: number;
    /**
     * Affects the lifecycle of the instance during deployment. If set to `proactive` (default), Instance Groups
     * can forcefully stop a running instance. If `opportunistic`, Instance Groups does not stop a running instance. Instead,
     * it will wait until the instance stops itself or becomes unhealthy.
     */
    strategy: string;
}

export interface ComputeInstanceGroupHealthCheck {
    /**
     * The number of successful health checks before the managed instance is declared healthy.
     */
    healthyThreshold?: number;
    /**
     * HTTP check options. The structure is documented below.
     */
    httpOptions?: outputs.ComputeInstanceGroupHealthCheckHttpOptions;
    /**
     * The interval to wait between health checks in seconds.
     */
    interval?: number;
    /**
     * TCP check options. The structure is documented below.
     */
    tcpOptions?: outputs.ComputeInstanceGroupHealthCheckTcpOptions;
    /**
     * The length of time to wait for a response before the health check times out in seconds.
     */
    timeout?: number;
    /**
     * The number of failed health checks before the managed instance is declared unhealthy.
     */
    unhealthyThreshold?: number;
}

export interface ComputeInstanceGroupHealthCheckHttpOptions {
    /**
     * The URL path used for health check requests.
     */
    path: string;
    /**
     * The port used for TCP health checks.
     */
    port: number;
}

export interface ComputeInstanceGroupHealthCheckTcpOptions {
    /**
     * The port used for TCP health checks.
     */
    port: number;
}

export interface ComputeInstanceGroupInstance {
    /**
     * DNS record fqdn (must have dot at the end).
     */
    fqdn: string;
    /**
     * The ID of the instance.
     */
    instanceId: string;
    /**
     * Name template of the instance.  
     * In order to be unique it must contain at least one of instance unique placeholders:
     * {instance.short_id}
     * {instance.index}
     * combination of {instance.zone_id} and {instance.index_in_zone}
     * Example: my-instance-{instance.index}
     * If not set, default is used: {instance_group.id}-{instance.short_id}
     * It may also contain another placeholders, see metadata doc for full list.
     */
    name: string;
    /**
     * Network specifications for the instance. This can be used multiple times for adding multiple interfaces. The structure is documented below.
     */
    networkInterfaces: outputs.ComputeInstanceGroupInstanceNetworkInterface[];
    /**
     * The status of the instance.
     */
    status: string;
    statusChangedAt: string;
    /**
     * The status message of the instance.
     */
    statusMessage: string;
    /**
     * The ID of the availability zone where the instance resides.
     */
    zoneId: string;
}

export interface ComputeInstanceGroupInstanceNetworkInterface {
    /**
     * The index of the network interface as generated by the server.
     */
    index: number;
    /**
     * Manual set static IP address.
     */
    ipAddress: string;
    /**
     * True if IPv4 address allocated for the network interface.
     */
    ipv4: boolean;
    ipv6: boolean;
    /**
     * Manual set static IPv6 address.
     */
    ipv6Address: string;
    /**
     * The MAC address assigned to the network interface.
     */
    macAddress: string;
    /**
     * Flag for using NAT.
     */
    nat: boolean;
    /**
     * A public address that can be used to access the internet over NAT. Use `variables` to set.
     */
    natIpAddress: string;
    /**
     * The IP version for the public address.
     */
    natIpVersion: string;
    /**
     * The ID of the subnet to attach this interface to. The subnet must reside in the same zone where this instance was created.
     */
    subnetId: string;
}

export interface ComputeInstanceGroupInstanceTemplate {
    /**
     * Boot disk specifications for the instance. The structure is documented below.
     */
    bootDisk: outputs.ComputeInstanceGroupInstanceTemplateBootDisk;
    /**
     * A description of the boot disk.
     */
    description?: string;
    /**
     * Hostname template for the instance.   
     * This field is used to generate the FQDN value of instance.
     * The hostname must be unique within the network and region.
     * If not specified, the hostname will be equal to id of the instance
     * and FQDN will be `<id>.auto.internal`. Otherwise FQDN will be `<hostname>.<region_id>.internal`.
     * In order to be unique it must contain at least on of instance unique placeholders:
     * {instance.short_id}
     * {instance.index}
     * combination of {instance.zone_id} and {instance.index_in_zone}
     * Example: my-instance-{instance.index}
     * If not set, `name` value will be used
     * It may also contain another placeholders, see metadata doc for full list.
     */
    hostname?: string;
    /**
     * A map of labels of metric.
     */
    labels: {[key: string]: string};
    /**
     * A set of metadata key/value pairs to make available from within the instance.
     */
    metadata: {[key: string]: string};
    /**
     * Name template of the instance.  
     * In order to be unique it must contain at least one of instance unique placeholders:
     * {instance.short_id}
     * {instance.index}
     * combination of {instance.zone_id} and {instance.index_in_zone}
     * Example: my-instance-{instance.index}
     * If not set, default is used: {instance_group.id}-{instance.short_id}
     * It may also contain another placeholders, see metadata doc for full list.
     */
    name?: string;
    /**
     * Network specifications for the instance. This can be used multiple times for adding multiple interfaces. The structure is documented below.
     */
    networkInterfaces: outputs.ComputeInstanceGroupInstanceTemplateNetworkInterface[];
    /**
     * Network acceleration type for instance. The structure is documented below.
     */
    networkSettings?: outputs.ComputeInstanceGroupInstanceTemplateNetworkSetting[];
    /**
     * The placement policy configuration. The structure is documented below.
     */
    placementPolicy?: outputs.ComputeInstanceGroupInstanceTemplatePlacementPolicy;
    /**
     * The ID of the hardware platform configuration for the instance. The default is 'standard-v1'.
     */
    platformId?: string;
    /**
     * Compute resource specifications for the instance. The structure is documented below.
     */
    resources: outputs.ComputeInstanceGroupInstanceTemplateResources;
    /**
     * The scheduling policy configuration. The structure is documented below.
     */
    schedulingPolicy: outputs.ComputeInstanceGroupInstanceTemplateSchedulingPolicy;
    /**
     * A list of disks to attach to the instance. The structure is documented below.
     */
    secondaryDisks?: outputs.ComputeInstanceGroupInstanceTemplateSecondaryDisk[];
    /**
     * The ID of the service account authorized for this instance.
     */
    serviceAccountId?: string;
}

export interface ComputeInstanceGroupInstanceTemplateBootDisk {
    /**
     * This value can be used to reference the device under `/dev/disk/by-id/`.
     */
    deviceName: string;
    /**
     * ID of the existing disk. To set use variables.
     */
    diskId?: string;
    /**
     * Parameters for creating a disk alongside the instance. The structure is documented below.
     */
    initializeParams?: outputs.ComputeInstanceGroupInstanceTemplateBootDiskInitializeParams;
    /**
     * The access mode to the disk resource. By default a disk is attached in `READ_WRITE` mode.
     */
    mode?: string;
}

export interface ComputeInstanceGroupInstanceTemplateBootDiskInitializeParams {
    /**
     * A description of the boot disk.
     */
    description?: string;
    /**
     * The disk image to initialize this disk from.
     */
    imageId: string;
    /**
     * The number of instances in the instance group.
     */
    size: number;
    /**
     * The snapshot to initialize this disk from.
     */
    snapshotId: string;
    /**
     * Network acceleration type. By default a network is in `STANDARD` mode.
     */
    type?: string;
}

export interface ComputeInstanceGroupInstanceTemplateNetworkInterface {
    /**
     * List of dns records.  The structure is documented below.
     */
    dnsRecords?: outputs.ComputeInstanceGroupInstanceTemplateNetworkInterfaceDnsRecord[];
    /**
     * Manual set static IP address.
     */
    ipAddress: string;
    /**
     * True if IPv4 address allocated for the network interface.
     */
    ipv4?: boolean;
    ipv6: boolean;
    /**
     * Manual set static IPv6 address.
     */
    ipv6Address: string;
    /**
     * List of ipv6 dns records.  The structure is documented below.
     */
    ipv6DnsRecords?: outputs.ComputeInstanceGroupInstanceTemplateNetworkInterfaceIpv6DnsRecord[];
    /**
     * Flag for using NAT.
     */
    nat: boolean;
    /**
     * List of nat dns records.  The structure is documented below.
     */
    natDnsRecords?: outputs.ComputeInstanceGroupInstanceTemplateNetworkInterfaceNatDnsRecord[];
    /**
     * A public address that can be used to access the internet over NAT. Use `variables` to set.
     */
    natIpAddress?: string;
    /**
     * The ID of the network.
     */
    networkId?: string;
    /**
     * Security group ids for network interface.
     */
    securityGroupIds?: string[];
    /**
     * The ID of the subnets to attach this interface to.
     */
    subnetIds?: string[];
}

export interface ComputeInstanceGroupInstanceTemplateNetworkInterfaceDnsRecord {
    /**
     * DNS zone id (if not set, private zone used).
     */
    dnsZoneId?: string;
    /**
     * DNS record fqdn (must have dot at the end).
     */
    fqdn: string;
    /**
     * When set to true, also create PTR DNS record.
     */
    ptr: boolean;
    /**
     * DNS record TTL.
     */
    ttl?: number;
}

export interface ComputeInstanceGroupInstanceTemplateNetworkInterfaceIpv6DnsRecord {
    /**
     * DNS zone id (if not set, private zone used).
     */
    dnsZoneId?: string;
    /**
     * DNS record fqdn (must have dot at the end).
     */
    fqdn: string;
    /**
     * When set to true, also create PTR DNS record.
     */
    ptr: boolean;
    /**
     * DNS record TTL.
     */
    ttl?: number;
}

export interface ComputeInstanceGroupInstanceTemplateNetworkInterfaceNatDnsRecord {
    /**
     * DNS zone id (if not set, private zone used).
     */
    dnsZoneId?: string;
    /**
     * DNS record fqdn (must have dot at the end).
     */
    fqdn: string;
    /**
     * When set to true, also create PTR DNS record.
     */
    ptr: boolean;
    /**
     * DNS record TTL.
     */
    ttl?: number;
}

export interface ComputeInstanceGroupInstanceTemplateNetworkSetting {
    /**
     * Network acceleration type. By default a network is in `STANDARD` mode.
     */
    type?: string;
}

export interface ComputeInstanceGroupInstanceTemplatePlacementPolicy {
    /**
     * Specifies the id of the Placement Group to assign to the instances.
     */
    placementGroupId: string;
}

export interface ComputeInstanceGroupInstanceTemplateResources {
    /**
     * If provided, specifies baseline core performance as a percent.
     */
    coreFraction?: number;
    /**
     * The number of CPU cores for the instance.
     */
    cores: number;
    gpus?: number;
    /**
     * The memory size in GB.
     */
    memory: number;
}

export interface ComputeInstanceGroupInstanceTemplateSchedulingPolicy {
    /**
     * Specifies if the instance is preemptible. Defaults to false.
     */
    preemptible?: boolean;
}

export interface ComputeInstanceGroupInstanceTemplateSecondaryDisk {
    /**
     * This value can be used to reference the device under `/dev/disk/by-id/`.
     */
    deviceName?: string;
    /**
     * ID of the existing disk. To set use variables.
     */
    diskId?: string;
    /**
     * Parameters for creating a disk alongside the instance. The structure is documented below.
     */
    initializeParams?: outputs.ComputeInstanceGroupInstanceTemplateSecondaryDiskInitializeParams;
    /**
     * The access mode to the disk resource. By default a disk is attached in `READ_WRITE` mode.
     */
    mode?: string;
}

export interface ComputeInstanceGroupInstanceTemplateSecondaryDiskInitializeParams {
    /**
     * A description of the boot disk.
     */
    description?: string;
    /**
     * The disk image to initialize this disk from.
     */
    imageId?: string;
    /**
     * The number of instances in the instance group.
     */
    size?: number;
    /**
     * The snapshot to initialize this disk from.
     */
    snapshotId?: string;
    /**
     * Network acceleration type. By default a network is in `STANDARD` mode.
     */
    type?: string;
}

export interface ComputeInstanceGroupLoadBalancer {
    /**
     * Timeout for waiting for the VM to be checked by the load balancer. If the timeout is exceeded, the VM will be turned off based on the deployment policy. Specified in seconds.
     */
    maxOpeningTrafficDuration?: number;
    /**
     * The status message of the instance.
     */
    statusMessage: string;
    /**
     * A description of the target group.
     */
    targetGroupDescription?: string;
    targetGroupId: string;
    /**
     * A set of key/value label pairs.
     */
    targetGroupLabels?: {[key: string]: string};
    /**
     * The name of the target group.
     */
    targetGroupName?: string;
}

export interface ComputeInstanceGroupScalePolicy {
    /**
     * The auto scaling policy of the instance group. The structure is documented below.
     */
    autoScale?: outputs.ComputeInstanceGroupScalePolicyAutoScale;
    /**
     * The fixed scaling policy of the instance group. The structure is documented below.
     */
    fixedScale?: outputs.ComputeInstanceGroupScalePolicyFixedScale;
    /**
     * The test auto scaling policy of the instance group. Use it to test how the auto scale works. The structure is documented below.
     */
    testAutoScale?: outputs.ComputeInstanceGroupScalePolicyTestAutoScale;
}

export interface ComputeInstanceGroupScalePolicyAutoScale {
    /**
     * Target CPU load level.
     */
    cpuUtilizationTarget?: number;
    /**
     * A list of custom rules. The structure is documented below.
     */
    customRules?: outputs.ComputeInstanceGroupScalePolicyAutoScaleCustomRule[];
    /**
     * The initial number of instances in the instance group.
     */
    initialSize: number;
    /**
     * The maximum number of virtual machines in the group.
     */
    maxSize?: number;
    /**
     * The amount of time, in seconds, that metrics are averaged for.
     * If the average value at the end of the interval is higher than the `cpuUtilizationTarget`,
     * the instance group will increase the number of virtual machines in the group.
     */
    measurementDuration: number;
    /**
     * The minimum number of virtual machines in a single availability zone.
     */
    minZoneSize?: number;
    /**
     * The minimum time interval, in seconds, to monitor the load before
     * an instance group can reduce the number of virtual machines in the group. During this time, the group
     * will not decrease even if the average load falls below the value of `cpuUtilizationTarget`.
     */
    stabilizationDuration: number;
    /**
     * The warm-up time of the virtual machine, in seconds. During this time,
     * traffic is fed to the virtual machine, but load metrics are not taken into account.
     */
    warmupDuration: number;
}

export interface ComputeInstanceGroupScalePolicyAutoScaleCustomRule {
    /**
     * Folder ID of custom metric in Yandex Monitoring that should be used for scaling.
     */
    folderId?: string;
    /**
     * A map of labels of metric.
     */
    labels?: {[key: string]: string};
    /**
     * The name of metric.
     */
    metricName: string;
    /**
     * Metric type, `GAUGE` or `COUNTER`.
     */
    metricType: string;
    /**
     * Rule type: `UTILIZATION` - This type means that the metric applies to one instance.
     * First, Instance Groups calculates the average metric value for each instance,
     * then averages the values for instances in one availability zone.
     * This type of metric must have the `instanceId` label. `WORKLOAD` - This type means that the metric applies to instances in one availability zone.
     * This type of metric must have the `zoneId` label.
     */
    ruleType: string;
    /**
     * Service of custom metric in Yandex Monitoring that should be used for scaling.
     */
    service?: string;
    /**
     * Target metric value level.
     */
    target: number;
}

export interface ComputeInstanceGroupScalePolicyFixedScale {
    /**
     * The number of instances in the instance group.
     */
    size: number;
}

export interface ComputeInstanceGroupScalePolicyTestAutoScale {
    /**
     * Target CPU load level.
     */
    cpuUtilizationTarget?: number;
    /**
     * A list of custom rules. The structure is documented below.
     */
    customRules?: outputs.ComputeInstanceGroupScalePolicyTestAutoScaleCustomRule[];
    /**
     * The initial number of instances in the instance group.
     */
    initialSize: number;
    /**
     * The maximum number of virtual machines in the group.
     */
    maxSize?: number;
    /**
     * The amount of time, in seconds, that metrics are averaged for.
     * If the average value at the end of the interval is higher than the `cpuUtilizationTarget`,
     * the instance group will increase the number of virtual machines in the group.
     */
    measurementDuration: number;
    /**
     * The minimum number of virtual machines in a single availability zone.
     */
    minZoneSize?: number;
    /**
     * The minimum time interval, in seconds, to monitor the load before
     * an instance group can reduce the number of virtual machines in the group. During this time, the group
     * will not decrease even if the average load falls below the value of `cpuUtilizationTarget`.
     */
    stabilizationDuration: number;
    /**
     * The warm-up time of the virtual machine, in seconds. During this time,
     * traffic is fed to the virtual machine, but load metrics are not taken into account.
     */
    warmupDuration: number;
}

export interface ComputeInstanceGroupScalePolicyTestAutoScaleCustomRule {
    /**
     * Folder ID of custom metric in Yandex Monitoring that should be used for scaling.
     */
    folderId?: string;
    /**
     * A map of labels of metric.
     */
    labels?: {[key: string]: string};
    /**
     * The name of metric.
     */
    metricName: string;
    /**
     * Metric type, `GAUGE` or `COUNTER`.
     */
    metricType: string;
    /**
     * Rule type: `UTILIZATION` - This type means that the metric applies to one instance.
     * First, Instance Groups calculates the average metric value for each instance,
     * then averages the values for instances in one availability zone.
     * This type of metric must have the `instanceId` label. `WORKLOAD` - This type means that the metric applies to instances in one availability zone.
     * This type of metric must have the `zoneId` label.
     */
    ruleType: string;
    /**
     * Service of custom metric in Yandex Monitoring that should be used for scaling.
     */
    service?: string;
    /**
     * Target metric value level.
     */
    target: number;
}

export interface ComputeInstanceLocalDisk {
    /**
     * Name of the device representing the filesystem on the instance.
     */
    deviceName: string;
    /**
     * Size of the disk, specified in bytes.
     */
    sizeBytes: number;
}

export interface ComputeInstanceMetadataOptions {
    awsV1HttpEndpoint: number;
    awsV1HttpToken: number;
    gceHttpEndpoint: number;
    gceHttpToken: number;
}

export interface ComputeInstanceNetworkInterface {
    /**
     * List of configurations for creating ipv4 DNS records. The structure is documented below.
     */
    dnsRecords?: outputs.ComputeInstanceNetworkInterfaceDnsRecord[];
    index: number;
    /**
     * The private IP address to assign to the instance. If
     * empty, the address will be automatically assigned from the specified subnet.
     */
    ipAddress: string;
    /**
     * Allocate an IPv4 address for the interface. The default value is `true`.
     */
    ipv4?: boolean;
    /**
     * If true, allocate an IPv6 address for the interface.
     * The address will be automatically assigned from the specified subnet.
     */
    ipv6: boolean;
    /**
     * The private IPv6 address to assign to the instance.
     */
    ipv6Address: string;
    /**
     * List of configurations for creating ipv6 DNS records. The structure is documented below.
     */
    ipv6DnsRecords?: outputs.ComputeInstanceNetworkInterfaceIpv6DnsRecord[];
    macAddress: string;
    /**
     * Provide a public address, for instance, to access the internet over NAT.
     */
    nat?: boolean;
    /**
     * List of configurations for creating ipv4 NAT DNS records. The structure is documented below.
     */
    natDnsRecords?: outputs.ComputeInstanceNetworkInterfaceNatDnsRecord[];
    /**
     * Provide a public address, for instance, to access the internet over NAT. Address should be already reserved in web UI.
     */
    natIpAddress: string;
    natIpVersion: string;
    /**
     * Security group ids for network interface.
     */
    securityGroupIds: string[];
    /**
     * ID of the subnet to attach this
     * interface to. The subnet must exist in the same zone where this instance will be
     * created.
     */
    subnetId: string;
}

export interface ComputeInstanceNetworkInterfaceDnsRecord {
    /**
     * DNS zone ID (if not set, private zone used).
     */
    dnsZoneId?: string;
    /**
     * DNS record FQDN (must have a dot at the end).
     */
    fqdn: string;
    /**
     * When set to true, also create a PTR DNS record.
     */
    ptr?: boolean;
    /**
     * DNS record TTL. in seconds
     */
    ttl?: number;
}

export interface ComputeInstanceNetworkInterfaceIpv6DnsRecord {
    /**
     * DNS zone ID (if not set, private zone used).
     */
    dnsZoneId?: string;
    /**
     * DNS record FQDN (must have a dot at the end).
     */
    fqdn: string;
    /**
     * When set to true, also create a PTR DNS record.
     */
    ptr?: boolean;
    /**
     * DNS record TTL. in seconds
     */
    ttl?: number;
}

export interface ComputeInstanceNetworkInterfaceNatDnsRecord {
    /**
     * DNS zone ID (if not set, private zone used).
     */
    dnsZoneId?: string;
    /**
     * DNS record FQDN (must have a dot at the end).
     */
    fqdn: string;
    /**
     * When set to true, also create a PTR DNS record.
     */
    ptr?: boolean;
    /**
     * DNS record TTL. in seconds
     */
    ttl?: number;
}

export interface ComputeInstancePlacementPolicy {
    /**
     * List of host affinity rules. The structure is documented below.
     */
    hostAffinityRules: outputs.ComputeInstancePlacementPolicyHostAffinityRule[];
    /**
     * Specifies the id of the Placement Group to assign to the instance.
     */
    placementGroupId?: string;
}

export interface ComputeInstancePlacementPolicyHostAffinityRule {
    /**
     * Affinity label or one of reserved values - `yc.hostId`, `yc.hostGroupId`.
     */
    key: string;
    /**
     * Affinity action. The only value supported is `IN`.
     */
    op: string;
    values: string[];
}

export interface ComputeInstanceResources {
    /**
     * If provided, specifies baseline performance for a core as a percent.
     */
    coreFraction?: number;
    /**
     * CPU cores for the instance.
     */
    cores: number;
    gpus?: number;
    /**
     * Memory size in GB.
     */
    memory: number;
}

export interface ComputeInstanceSchedulingPolicy {
    /**
     * Specifies if the instance is preemptible. Defaults to false.
     */
    preemptible?: boolean;
}

export interface ComputeInstanceSecondaryDisk {
    /**
     * Whether the disk is auto-deleted when the instance
     * is deleted. The default value is false.
     */
    autoDelete?: boolean;
    /**
     * Name of the device representing the filesystem on the instance.
     */
    deviceName: string;
    /**
     * ID of the disk that is attached to the instance.
     */
    diskId: string;
    /**
     * Mode of access to the filesystem that should be attached. By default, filesystem is attached 
     * in `READ_WRITE` mode.
     */
    mode?: string;
}

export interface ComputeSnapshotScheduleSchedulePolicy {
    /**
     * Cron expression to schedule snapshots (in cron format "* * * * *").
     */
    expression?: string;
    /**
     * Time to start the snapshot schedule (in format RFC3339 "2006-01-02T15:04:05Z07:00"). If empty current time will be used. Unlike an `expression` that specifies regularity rules, the `startAt` parameter determines from what point these rules will be applied.
     */
    startAt: string;
}

export interface ComputeSnapshotScheduleSnapshotSpec {
    /**
     * Description to assign to snapshots created by this snapshot schedule.
     */
    description?: string;
    /**
     * A set of key/value label pairs to assign to snapshots created by this snapshot schedule.
     */
    labels?: {[key: string]: string};
}

export interface ContainerRepositoryLifecyclePolicyRule {
    /**
     * Description of the lifecycle policy.
     */
    description: string;
    /**
     * The period of time that must pass after creating a image for it to suit the automatic deletion criteria. It must be a multiple of 24 hours.
     */
    expirePeriod?: string;
    /**
     * The number of images to be retained even if the expirePeriod already expired.
     */
    retainedTop: number;
    /**
     * Tag to specify a filter as a regular expression. For example `.*` - all images with tags.
     */
    tagRegexp?: string;
    /**
     * If enabled, rules apply to untagged Docker images.
     */
    untagged: boolean;
}

export interface DataprocClusterClusterConfig {
    /**
     * Data Proc specific options. The structure is documented below.
     */
    hadoop?: outputs.DataprocClusterClusterConfigHadoop;
    /**
     * Configuration of the Data Proc subcluster. The structure is documented below.
     */
    subclusterSpecs: outputs.DataprocClusterClusterConfigSubclusterSpec[];
    /**
     * Version of Data Proc image.
     */
    versionId: string;
}

export interface DataprocClusterClusterConfigHadoop {
    /**
     * A set of key/value pairs that are used to configure cluster services.
     */
    properties?: {[key: string]: string};
    /**
     * List of services to run on Data Proc cluster.
     */
    services?: string[];
    /**
     * List of SSH public keys to put to the hosts of the cluster. For information on how to connect to the cluster, see [the official documentation](https://cloud.yandex.com/docs/data-proc/operations/connect).
     */
    sshPublicKeys?: string[];
}

export interface DataprocClusterClusterConfigSubclusterSpec {
    /**
     * If true then assign public IP addresses to the hosts of the subclusters.
     */
    assignPublicIp?: boolean;
    /**
     * Autoscaling configuration for compute subclusters.
     */
    autoscalingConfig?: outputs.DataprocClusterClusterConfigSubclusterSpecAutoscalingConfig;
    /**
     * Number of hosts within Data Proc subcluster.
     */
    hostsCount: number;
    /**
     * (Computed) ID of a new Data Proc cluster.
     */
    id: string;
    /**
     * Name of the Data Proc subcluster.
     */
    name: string;
    /**
     * Resources allocated to each host of the Data Proc subcluster. The structure is documented below.
     */
    resources: outputs.DataprocClusterClusterConfigSubclusterSpecResources;
    /**
     * Role of the subcluster in the Data Proc cluster.
     */
    role: string;
    /**
     * The ID of the subnet, to which hosts of the subcluster belong. Subnets of all the subclusters must belong to the same VPC network.
     */
    subnetId: string;
}

export interface DataprocClusterClusterConfigSubclusterSpecAutoscalingConfig {
    /**
     * Defines an autoscaling rule based on the average CPU utilization of the instance group. If not set default autoscaling metric will be used.
     */
    cpuUtilizationTarget?: number;
    /**
     * Timeout to gracefully decommission nodes during downscaling. In seconds.
     */
    decommissionTimeout?: number;
    /**
     * Maximum number of nodes in autoscaling subclusters.
     */
    maxHostsCount: number;
    /**
     * Time in seconds allotted for averaging metrics.
     */
    measurementDuration?: number;
    /**
     * Bool flag -- whether to use preemptible compute instances. Preemptible instances are stopped at least once every 24 hours, and can be stopped at any time if their resources are needed by Compute. For more information, see [Preemptible Virtual Machines](https://cloud.yandex.com/docs/compute/concepts/preemptible-vm).
     */
    preemptible?: boolean;
    /**
     * Minimum amount of time in seconds allotted for monitoring before Instance Groups can reduce the number of instances in the group. During this time, the group size doesn't decrease, even if the new metric values indicate that it should.
     */
    stabilizationDuration?: number;
    /**
     * The warmup time of the instance in seconds. During this time, traffic is sent to the instance, but instance metrics are not collected.
     */
    warmupDuration?: number;
}

export interface DataprocClusterClusterConfigSubclusterSpecResources {
    /**
     * Volume of the storage available to a host, in gigabytes.
     */
    diskSize: number;
    /**
     * Type of the storage of a host. One of `network-hdd` (default) or `network-ssd`.
     */
    diskTypeId?: string;
    /**
     * The ID of the preset for computational resources available to a host. All available presets are listed in the [documentation](https://cloud.yandex.com/docs/data-proc/concepts/instance-types).
     */
    resourcePresetId: string;
}

export interface DatatransferEndpointSettings {
    /**
     * Settings specific to the ClickHouse source endpoint.
     */
    clickhouseSource?: outputs.DatatransferEndpointSettingsClickhouseSource;
    /**
     * Settings specific to the ClickHouse target endpoint.
     */
    clickhouseTarget?: outputs.DatatransferEndpointSettingsClickhouseTarget;
    /**
     * Settings specific to the Kafka source endpoint.
     */
    kafkaSource?: outputs.DatatransferEndpointSettingsKafkaSource;
    /**
     * Settings specific to the Kafka target endpoint.
     */
    kafkaTarget?: outputs.DatatransferEndpointSettingsKafkaTarget;
    /**
     * Settings specific to the MongoDB source endpoint.
     */
    mongoSource?: outputs.DatatransferEndpointSettingsMongoSource;
    /**
     * Settings specific to the MongoDB target endpoint.
     */
    mongoTarget?: outputs.DatatransferEndpointSettingsMongoTarget;
    /**
     * Settings specific to the MySQL source endpoint.
     */
    mysqlSource?: outputs.DatatransferEndpointSettingsMysqlSource;
    /**
     * Settings specific to the MySQL target endpoint.
     */
    mysqlTarget?: outputs.DatatransferEndpointSettingsMysqlTarget;
    /**
     * Settings specific to the PostgreSQL source endpoint.
     */
    postgresSource?: outputs.DatatransferEndpointSettingsPostgresSource;
    /**
     * Settings specific to the PostgreSQL target endpoint.
     */
    postgresTarget?: outputs.DatatransferEndpointSettingsPostgresTarget;
    /**
     * Settings specific to the YDB source endpoint.
     */
    ydbSource?: outputs.DatatransferEndpointSettingsYdbSource;
    /**
     * Settings specific to the YDB target endpoint.
     */
    ydbTarget?: outputs.DatatransferEndpointSettingsYdbTarget;
}

export interface DatatransferEndpointSettingsClickhouseSource {
    /**
     * Connection settings. The structure is documented below.
     */
    connection: outputs.DatatransferEndpointSettingsClickhouseSourceConnection;
    /**
     * List of tables which will not be transfered, formatted as `schemaname.tablename`.
     */
    excludeTables: string[];
    /**
     * List of tables to transfer, formatted as `schemaname.tablename`. If omitted or an empty list is specified, all tables will be transferred.
     */
    includeTables: string[];
    /**
     * List of security groups that the transfer associated with this endpoint should use.
     */
    securityGroups: string[];
    /**
     * Identifier of the Yandex Cloud VPC subnetwork to user for accessing the database. If omitted, the server has to be accessible via Internet.
     */
    subnetId: string;
}

export interface DatatransferEndpointSettingsClickhouseSourceConnection {
    /**
     * Connection options. The structure is documented below.
     */
    connectionOptions: outputs.DatatransferEndpointSettingsClickhouseSourceConnectionConnectionOptions;
}

export interface DatatransferEndpointSettingsClickhouseSourceConnectionConnectionOptions {
    /**
     * Database name.
     */
    database: string;
    /**
     * Identifier of the Managed ClickHouse cluster.
     */
    mdbClusterId?: string;
    /**
     * Connection settings of the on-premise ClickHouse server.
     */
    onPremise?: outputs.DatatransferEndpointSettingsClickhouseSourceConnectionConnectionOptionsOnPremise;
    /**
     * Password for the database access. This is a block with a single field named `raw` which should contain the password.
     */
    password: outputs.DatatransferEndpointSettingsClickhouseSourceConnectionConnectionOptionsPassword;
    /**
     * User for database access.
     */
    user: string;
}

export interface DatatransferEndpointSettingsClickhouseSourceConnectionConnectionOptionsOnPremise {
    /**
     * TCP port number for the HTTP interface of the ClickHouse server.
     */
    httpPort: number;
    /**
     * TCP port number for the native interface of the ClickHouse server.
     */
    nativePort: number;
    /**
     * The list of ClickHouse shards. The structure is documented below.
     */
    shards: outputs.DatatransferEndpointSettingsClickhouseSourceConnectionConnectionOptionsOnPremiseShard[];
    /**
     * TLS settings for the server connection. Empty implies plaintext connection. The structure is documented below.
     */
    tlsMode: outputs.DatatransferEndpointSettingsClickhouseSourceConnectionConnectionOptionsOnPremiseTlsMode;
}

export interface DatatransferEndpointSettingsClickhouseSourceConnectionConnectionOptionsOnPremiseShard {
    /**
     * List of ClickHouse server host names.
     */
    hosts: string[];
    /**
     * Arbitrary shard name. This name may be used in `sharding` block to specify custom sharding rules.
     */
    name: string;
}

export interface DatatransferEndpointSettingsClickhouseSourceConnectionConnectionOptionsOnPremiseTlsMode {
    /**
     * Empty block designating that the connection is not secured, i.e. plaintext connection.
     */
    disabled?: outputs.DatatransferEndpointSettingsClickhouseSourceConnectionConnectionOptionsOnPremiseTlsModeDisabled;
    /**
     * If this attribute is not an empty block, then TLS is used for the server connection. The structure is documented below.
     */
    enabled?: outputs.DatatransferEndpointSettingsClickhouseSourceConnectionConnectionOptionsOnPremiseTlsModeEnabled;
}

export interface DatatransferEndpointSettingsClickhouseSourceConnectionConnectionOptionsOnPremiseTlsModeDisabled {
}

export interface DatatransferEndpointSettingsClickhouseSourceConnectionConnectionOptionsOnPremiseTlsModeEnabled {
    /**
     * X.509 certificate of the certificate authority which issued the server's certificate, in PEM format. If empty, the server's certificate must be signed by a well-known CA.
     */
    caCertificate: string;
}

export interface DatatransferEndpointSettingsClickhouseSourceConnectionConnectionOptionsPassword {
    raw: string;
}

export interface DatatransferEndpointSettingsClickhouseTarget {
    /**
     * Table renaming rules. The structure is documented below.
     */
    altNames: outputs.DatatransferEndpointSettingsClickhouseTargetAltName[];
    /**
     * How to clean collections when activating the transfer. One of "DISABLED", "DROP" or "TRUNCATE".
     */
    cleanupPolicy: string;
    /**
     * Name of the ClickHouse cluster. For managed ClickHouse clusters defaults to managed cluster ID.
     */
    clickhouseClusterName: string;
    /**
     * Connection settings. The structure is documented below.
     */
    connection: outputs.DatatransferEndpointSettingsClickhouseTargetConnection;
    /**
     * List of security groups that the transfer associated with this endpoint should use.
     */
    securityGroups: string[];
    /**
     * Shard selection rules for the data being transferred. The structure is documented below.
     */
    sharding: outputs.DatatransferEndpointSettingsClickhouseTargetSharding;
    /**
     * Identifier of the Yandex Cloud VPC subnetwork to user for accessing the database. If omitted, the server has to be accessible via Internet.
     */
    subnetId: string;
}

export interface DatatransferEndpointSettingsClickhouseTargetAltName {
    fromName: string;
    toName: string;
}

export interface DatatransferEndpointSettingsClickhouseTargetConnection {
    /**
     * Connection options. The structure is documented below.
     */
    connectionOptions: outputs.DatatransferEndpointSettingsClickhouseTargetConnectionConnectionOptions;
}

export interface DatatransferEndpointSettingsClickhouseTargetConnectionConnectionOptions {
    /**
     * Database name.
     */
    database: string;
    /**
     * Identifier of the Managed ClickHouse cluster.
     */
    mdbClusterId?: string;
    /**
     * Connection settings of the on-premise ClickHouse server.
     */
    onPremise?: outputs.DatatransferEndpointSettingsClickhouseTargetConnectionConnectionOptionsOnPremise;
    /**
     * Password for the database access. This is a block with a single field named `raw` which should contain the password.
     */
    password: outputs.DatatransferEndpointSettingsClickhouseTargetConnectionConnectionOptionsPassword;
    /**
     * User for database access.
     */
    user: string;
}

export interface DatatransferEndpointSettingsClickhouseTargetConnectionConnectionOptionsOnPremise {
    /**
     * TCP port number for the HTTP interface of the ClickHouse server.
     */
    httpPort: number;
    /**
     * TCP port number for the native interface of the ClickHouse server.
     */
    nativePort: number;
    /**
     * The list of ClickHouse shards. The structure is documented below.
     */
    shards: outputs.DatatransferEndpointSettingsClickhouseTargetConnectionConnectionOptionsOnPremiseShard[];
    /**
     * TLS settings for the server connection. Empty implies plaintext connection. The structure is documented below.
     */
    tlsMode: outputs.DatatransferEndpointSettingsClickhouseTargetConnectionConnectionOptionsOnPremiseTlsMode;
}

export interface DatatransferEndpointSettingsClickhouseTargetConnectionConnectionOptionsOnPremiseShard {
    /**
     * List of ClickHouse server host names.
     */
    hosts: string[];
    /**
     * Arbitrary shard name. This name may be used in `sharding` block to specify custom sharding rules.
     */
    name: string;
}

export interface DatatransferEndpointSettingsClickhouseTargetConnectionConnectionOptionsOnPremiseTlsMode {
    /**
     * Empty block designating that the connection is not secured, i.e. plaintext connection.
     */
    disabled?: outputs.DatatransferEndpointSettingsClickhouseTargetConnectionConnectionOptionsOnPremiseTlsModeDisabled;
    /**
     * If this attribute is not an empty block, then TLS is used for the server connection. The structure is documented below.
     */
    enabled?: outputs.DatatransferEndpointSettingsClickhouseTargetConnectionConnectionOptionsOnPremiseTlsModeEnabled;
}

export interface DatatransferEndpointSettingsClickhouseTargetConnectionConnectionOptionsOnPremiseTlsModeDisabled {
}

export interface DatatransferEndpointSettingsClickhouseTargetConnectionConnectionOptionsOnPremiseTlsModeEnabled {
    /**
     * X.509 certificate of the certificate authority which issued the server's certificate, in PEM format. If empty, the server's certificate must be signed by a well-known CA.
     */
    caCertificate: string;
}

export interface DatatransferEndpointSettingsClickhouseTargetConnectionConnectionOptionsPassword {
    raw: string;
}

export interface DatatransferEndpointSettingsClickhouseTargetSharding {
    /**
     * Shard data by the hash value of the specified column. The structure is documented below.
     */
    columnValueHash?: outputs.DatatransferEndpointSettingsClickhouseTargetShardingColumnValueHash;
    /**
     * Shard data by ID of the transfer.
     */
    transferId?: outputs.DatatransferEndpointSettingsClickhouseTargetShardingTransferId;
}

export interface DatatransferEndpointSettingsClickhouseTargetShardingColumnValueHash {
    /**
     * The name of the column to calculate hash from.
     */
    columnName: string;
}

export interface DatatransferEndpointSettingsClickhouseTargetShardingTransferId {
}

export interface DatatransferEndpointSettingsKafkaSource {
    /**
     * Authentication data.
     */
    auth: outputs.DatatransferEndpointSettingsKafkaSourceAuth;
    /**
     * Connection settings. The structure is documented below.
     */
    connection: outputs.DatatransferEndpointSettingsKafkaSourceConnection;
    /**
     * Data parsing parameters. If not set, the source messages are read in raw.
     */
    parser: outputs.DatatransferEndpointSettingsKafkaSourceParser;
    /**
     * List of security groups that the transfer associated with this endpoint should use.
     */
    securityGroups: string[];
    /**
     * Full source topic name.
     */
    topicName: string;
    /**
     * Transform data with a custom Cloud Function.
     */
    transformer: outputs.DatatransferEndpointSettingsKafkaSourceTransformer;
}

export interface DatatransferEndpointSettingsKafkaSourceAuth {
    /**
     * Connection without authentication data.
     */
    noAuth?: outputs.DatatransferEndpointSettingsKafkaSourceAuthNoAuth;
    /**
     * Authentication using sasl.
     */
    sasl?: outputs.DatatransferEndpointSettingsKafkaSourceAuthSasl;
}

export interface DatatransferEndpointSettingsKafkaSourceAuthNoAuth {
}

export interface DatatransferEndpointSettingsKafkaSourceAuthSasl {
    mechanism: string;
    /**
     * Password for the database access. This is a block with a single field named `raw` which should contain the password.
     */
    password: outputs.DatatransferEndpointSettingsKafkaSourceAuthSaslPassword;
    /**
     * User for the database access.
     */
    user: string;
}

export interface DatatransferEndpointSettingsKafkaSourceAuthSaslPassword {
    raw: string;
}

export interface DatatransferEndpointSettingsKafkaSourceConnection {
    /**
     * Identifier of the Managed Kafka cluster.
     */
    clusterId?: string;
    /**
     * Connection settings of the on-premise Kafka server.
     */
    onPremise?: outputs.DatatransferEndpointSettingsKafkaSourceConnectionOnPremise;
}

export interface DatatransferEndpointSettingsKafkaSourceConnectionOnPremise {
    /**
     * List of Kafka broker URLs.
     */
    brokerUrls: string[];
    /**
     * Identifier of the Yandex Cloud VPC subnetwork to user for accessing the database. If omitted, the server has to be accessible via Internet.
     */
    subnetId: string;
    /**
     * TLS settings for the server connection. Empty implies plaintext connection. The structure is documented below.
     */
    tlsMode: outputs.DatatransferEndpointSettingsKafkaSourceConnectionOnPremiseTlsMode;
}

export interface DatatransferEndpointSettingsKafkaSourceConnectionOnPremiseTlsMode {
    /**
     * Empty block designating that the connection is not secured, i.e. plaintext connection.
     */
    disabled?: outputs.DatatransferEndpointSettingsKafkaSourceConnectionOnPremiseTlsModeDisabled;
    /**
     * If this attribute is not an empty block, then TLS is used for the server connection. The structure is documented below.
     */
    enabled?: outputs.DatatransferEndpointSettingsKafkaSourceConnectionOnPremiseTlsModeEnabled;
}

export interface DatatransferEndpointSettingsKafkaSourceConnectionOnPremiseTlsModeDisabled {
}

export interface DatatransferEndpointSettingsKafkaSourceConnectionOnPremiseTlsModeEnabled {
    /**
     * X.509 certificate of the certificate authority which issued the server's certificate, in PEM format. If empty, the server's certificate must be signed by a well-known CA.
     */
    caCertificate: string;
}

export interface DatatransferEndpointSettingsKafkaSourceParser {
    /**
     * Parse Audit Trails data. Empty struct.
     */
    auditTrailsV1Parser?: outputs.DatatransferEndpointSettingsKafkaSourceParserAuditTrailsV1Parser;
    /**
     * Parse Cloud Logging data. Empty struct.
     */
    cloudLoggingParser?: outputs.DatatransferEndpointSettingsKafkaSourceParserCloudLoggingParser;
    /**
     * Parse data in json format.
     */
    jsonParser?: outputs.DatatransferEndpointSettingsKafkaSourceParserJsonParser;
    /**
     * Parse data if tskv format.
     */
    tskvParser?: outputs.DatatransferEndpointSettingsKafkaSourceParserTskvParser;
}

export interface DatatransferEndpointSettingsKafkaSourceParserAuditTrailsV1Parser {
}

export interface DatatransferEndpointSettingsKafkaSourceParserCloudLoggingParser {
}

export interface DatatransferEndpointSettingsKafkaSourceParserJsonParser {
    /**
     * Add fields, that are not in the schema, into the _rest column.
     */
    addRestColumn: boolean;
    /**
     * Data parsing scheme.The structure is documented below.
     */
    dataSchema: outputs.DatatransferEndpointSettingsKafkaSourceParserJsonParserDataSchema;
    /**
     * Allow null keys. If `false` - null keys will be putted to unparsed data
     */
    nullKeysAllowed: boolean;
}

export interface DatatransferEndpointSettingsKafkaSourceParserJsonParserDataSchema {
    /**
     * Description of the data schema in the array of `fields` structure (documented below).
     */
    fields?: outputs.DatatransferEndpointSettingsKafkaSourceParserJsonParserDataSchemaFields;
    /**
     * Description of the data schema as JSON specification.
     */
    jsonFields?: string;
}

export interface DatatransferEndpointSettingsKafkaSourceParserJsonParserDataSchemaFields {
    /**
     * Description of the data schema in the array of `fields` structure (documented below).
     */
    fields: outputs.DatatransferEndpointSettingsKafkaSourceParserJsonParserDataSchemaFieldsField[];
}

export interface DatatransferEndpointSettingsKafkaSourceParserJsonParserDataSchemaFieldsField {
    /**
     * -Mark field as Primary Key.
     */
    key: boolean;
    /**
     * Name of the endpoint.
     */
    name: string;
    /**
     * Path to the field.
     */
    path: string;
    /**
     * Mark field as required.
     */
    required: boolean;
    /**
     * Field type, one of: `INT64`, `INT32`, `INT16`, `INT8`, `UINT64`, `UINT32`, `UINT16`, `UINT8`, `DOUBLE`, `BOOLEAN`, `STRING`, `UTF8`, `ANY`, `DATETIME`.
     */
    type: string;
}

export interface DatatransferEndpointSettingsKafkaSourceParserTskvParser {
    /**
     * Add fields, that are not in the schema, into the _rest column.
     */
    addRestColumn: boolean;
    /**
     * Data parsing scheme.The structure is documented below.
     */
    dataSchema: outputs.DatatransferEndpointSettingsKafkaSourceParserTskvParserDataSchema;
    /**
     * Allow null keys. If `false` - null keys will be putted to unparsed data
     */
    nullKeysAllowed: boolean;
}

export interface DatatransferEndpointSettingsKafkaSourceParserTskvParserDataSchema {
    /**
     * Description of the data schema in the array of `fields` structure (documented below).
     */
    fields?: outputs.DatatransferEndpointSettingsKafkaSourceParserTskvParserDataSchemaFields;
    /**
     * Description of the data schema as JSON specification.
     */
    jsonFields?: string;
}

export interface DatatransferEndpointSettingsKafkaSourceParserTskvParserDataSchemaFields {
    /**
     * Description of the data schema in the array of `fields` structure (documented below).
     */
    fields: outputs.DatatransferEndpointSettingsKafkaSourceParserTskvParserDataSchemaFieldsField[];
}

export interface DatatransferEndpointSettingsKafkaSourceParserTskvParserDataSchemaFieldsField {
    /**
     * -Mark field as Primary Key.
     */
    key: boolean;
    /**
     * Name of the endpoint.
     */
    name: string;
    /**
     * Path to the field.
     */
    path: string;
    /**
     * Mark field as required.
     */
    required: boolean;
    /**
     * Field type, one of: `INT64`, `INT32`, `INT16`, `INT8`, `UINT64`, `UINT32`, `UINT16`, `UINT8`, `DOUBLE`, `BOOLEAN`, `STRING`, `UTF8`, `ANY`, `DATETIME`.
     */
    type: string;
}

export interface DatatransferEndpointSettingsKafkaSourceTransformer {
    bufferFlushInterval: string;
    bufferSize: string;
    cloudFunction: string;
    invocationTimeout: string;
    numberOfRetries: number;
    serviceAccountId: string;
}

export interface DatatransferEndpointSettingsKafkaTarget {
    /**
     * Authentication data.
     */
    auth: outputs.DatatransferEndpointSettingsKafkaTargetAuth;
    /**
     * Connection settings. The structure is documented below.
     */
    connection: outputs.DatatransferEndpointSettingsKafkaTargetConnection;
    /**
     * List of security groups that the transfer associated with this endpoint should use.
     */
    securityGroups: string[];
    /**
     * Data serialization settings.
     */
    serializer: outputs.DatatransferEndpointSettingsKafkaTargetSerializer;
    /**
     * Target topic settings.
     */
    topicSettings: outputs.DatatransferEndpointSettingsKafkaTargetTopicSettings;
}

export interface DatatransferEndpointSettingsKafkaTargetAuth {
    /**
     * Connection without authentication data.
     */
    noAuth?: outputs.DatatransferEndpointSettingsKafkaTargetAuthNoAuth;
    /**
     * Authentication using sasl.
     */
    sasl?: outputs.DatatransferEndpointSettingsKafkaTargetAuthSasl;
}

export interface DatatransferEndpointSettingsKafkaTargetAuthNoAuth {
}

export interface DatatransferEndpointSettingsKafkaTargetAuthSasl {
    mechanism: string;
    /**
     * Password for the database access. This is a block with a single field named `raw` which should contain the password.
     */
    password: outputs.DatatransferEndpointSettingsKafkaTargetAuthSaslPassword;
    /**
     * User for the database access.
     */
    user: string;
}

export interface DatatransferEndpointSettingsKafkaTargetAuthSaslPassword {
    raw: string;
}

export interface DatatransferEndpointSettingsKafkaTargetConnection {
    /**
     * Identifier of the Managed Kafka cluster.
     */
    clusterId?: string;
    /**
     * Connection settings of the on-premise Kafka server.
     */
    onPremise?: outputs.DatatransferEndpointSettingsKafkaTargetConnectionOnPremise;
}

export interface DatatransferEndpointSettingsKafkaTargetConnectionOnPremise {
    /**
     * List of Kafka broker URLs.
     */
    brokerUrls: string[];
    /**
     * Identifier of the Yandex Cloud VPC subnetwork to user for accessing the database. If omitted, the server has to be accessible via Internet.
     */
    subnetId: string;
    /**
     * TLS settings for the server connection. Empty implies plaintext connection. The structure is documented below.
     */
    tlsMode: outputs.DatatransferEndpointSettingsKafkaTargetConnectionOnPremiseTlsMode;
}

export interface DatatransferEndpointSettingsKafkaTargetConnectionOnPremiseTlsMode {
    /**
     * Empty block designating that the connection is not secured, i.e. plaintext connection.
     */
    disabled?: outputs.DatatransferEndpointSettingsKafkaTargetConnectionOnPremiseTlsModeDisabled;
    /**
     * If this attribute is not an empty block, then TLS is used for the server connection. The structure is documented below.
     */
    enabled?: outputs.DatatransferEndpointSettingsKafkaTargetConnectionOnPremiseTlsModeEnabled;
}

export interface DatatransferEndpointSettingsKafkaTargetConnectionOnPremiseTlsModeDisabled {
}

export interface DatatransferEndpointSettingsKafkaTargetConnectionOnPremiseTlsModeEnabled {
    /**
     * X.509 certificate of the certificate authority which issued the server's certificate, in PEM format. If empty, the server's certificate must be signed by a well-known CA.
     */
    caCertificate: string;
}

export interface DatatransferEndpointSettingsKafkaTargetSerializer {
    /**
     * Empty block. Select data serialization format automatically.
     */
    serializerAuto?: outputs.DatatransferEndpointSettingsKafkaTargetSerializerSerializerAuto;
    /**
     * Serialize data in json format. The structure is documented below.
     */
    serializerDebezium?: outputs.DatatransferEndpointSettingsKafkaTargetSerializerSerializerDebezium;
    /**
     * Empty block. Serialize data in json format.
     */
    serializerJson?: outputs.DatatransferEndpointSettingsKafkaTargetSerializerSerializerJson;
}

export interface DatatransferEndpointSettingsKafkaTargetSerializerSerializerAuto {
}

export interface DatatransferEndpointSettingsKafkaTargetSerializerSerializerDebezium {
    /**
     * A list of debezium parameters set by the structure of the `key` and `value` string fields.
     */
    serializerParameters: outputs.DatatransferEndpointSettingsKafkaTargetSerializerSerializerDebeziumSerializerParameter[];
}

export interface DatatransferEndpointSettingsKafkaTargetSerializerSerializerDebeziumSerializerParameter {
    /**
     * -Mark field as Primary Key.
     */
    key: string;
    value: string;
}

export interface DatatransferEndpointSettingsKafkaTargetSerializerSerializerJson {
}

export interface DatatransferEndpointSettingsKafkaTargetTopicSettings {
    /**
     * All messages will be sent to one topic. The structure is documented below.
     */
    topic?: outputs.DatatransferEndpointSettingsKafkaTargetTopicSettingsTopic;
    /**
     * Topic name prefix. Messages will be sent to topic with name <topic_prefix>.<schema>.<table_name>.
     */
    topicPrefix?: string;
}

export interface DatatransferEndpointSettingsKafkaTargetTopicSettingsTopic {
    /**
     * Not to split events queue into separate per-table queues.
     */
    saveTxOrder: boolean;
    /**
     * Full source topic name.
     */
    topicName: string;
}

export interface DatatransferEndpointSettingsMongoSource {
    /**
     * The list of the MongoDB collections that should be transferred. If omitted, all available collections will be transferred. The structure of the list item is documented below.
     */
    collections: outputs.DatatransferEndpointSettingsMongoSourceCollection[];
    /**
     * Connection settings. The structure is documented below.
     */
    connection: outputs.DatatransferEndpointSettingsMongoSourceConnection;
    /**
     * The list of the MongoDB collections that should not be transferred.
     */
    excludedCollections: outputs.DatatransferEndpointSettingsMongoSourceExcludedCollection[];
    /**
     * whether the secondary server should be preferred to the primary when copying data.
     */
    secondaryPreferredMode: boolean;
    /**
     * List of security groups that the transfer associated with this endpoint should use.
     */
    securityGroups: string[];
    /**
     * Identifier of the Yandex Cloud VPC subnetwork to user for accessing the database. If omitted, the server has to be accessible via Internet.
     */
    subnetId: string;
}

export interface DatatransferEndpointSettingsMongoSourceCollection {
    /**
     * Collection name.
     */
    collectionName: string;
    /**
     * Database name.
     */
    databaseName: string;
}

export interface DatatransferEndpointSettingsMongoSourceConnection {
    /**
     * Connection options. The structure is documented below.
     */
    connectionOptions: outputs.DatatransferEndpointSettingsMongoSourceConnectionConnectionOptions;
}

export interface DatatransferEndpointSettingsMongoSourceConnectionConnectionOptions {
    /**
     * Name of the database associated with the credentials.
     */
    authSource: string;
    /**
     * Identifier of the Managed ClickHouse cluster.
     */
    mdbClusterId?: string;
    /**
     * Connection settings of the on-premise ClickHouse server.
     */
    onPremise?: outputs.DatatransferEndpointSettingsMongoSourceConnectionConnectionOptionsOnPremise;
    /**
     * Password for the database access. This is a block with a single field named `raw` which should contain the password.
     */
    password: outputs.DatatransferEndpointSettingsMongoSourceConnectionConnectionOptionsPassword;
    /**
     * User for database access.
     */
    user: string;
}

export interface DatatransferEndpointSettingsMongoSourceConnectionConnectionOptionsOnPremise {
    /**
     * Host names of the replica set.
     */
    hosts: string[];
    /**
     * TCP Port number.
     */
    port: number;
    /**
     * Replica set name.
     */
    replicaSet: string;
    /**
     * TLS settings for the server connection. Empty implies plaintext connection. The structure is documented below.
     */
    tlsMode: outputs.DatatransferEndpointSettingsMongoSourceConnectionConnectionOptionsOnPremiseTlsMode;
}

export interface DatatransferEndpointSettingsMongoSourceConnectionConnectionOptionsOnPremiseTlsMode {
    /**
     * Empty block designating that the connection is not secured, i.e. plaintext connection.
     */
    disabled?: outputs.DatatransferEndpointSettingsMongoSourceConnectionConnectionOptionsOnPremiseTlsModeDisabled;
    /**
     * If this attribute is not an empty block, then TLS is used for the server connection. The structure is documented below.
     */
    enabled?: outputs.DatatransferEndpointSettingsMongoSourceConnectionConnectionOptionsOnPremiseTlsModeEnabled;
}

export interface DatatransferEndpointSettingsMongoSourceConnectionConnectionOptionsOnPremiseTlsModeDisabled {
}

export interface DatatransferEndpointSettingsMongoSourceConnectionConnectionOptionsOnPremiseTlsModeEnabled {
    /**
     * X.509 certificate of the certificate authority which issued the server's certificate, in PEM format. If empty, the server's certificate must be signed by a well-known CA.
     */
    caCertificate: string;
}

export interface DatatransferEndpointSettingsMongoSourceConnectionConnectionOptionsPassword {
    raw: string;
}

export interface DatatransferEndpointSettingsMongoSourceExcludedCollection {
    /**
     * Collection name.
     */
    collectionName: string;
    /**
     * Database name.
     */
    databaseName: string;
}

export interface DatatransferEndpointSettingsMongoTarget {
    /**
     * How to clean collections when activating the transfer. One of "DISABLED", "DROP" or "TRUNCATE".
     */
    cleanupPolicy: string;
    /**
     * Connection settings. The structure is documented below.
     */
    connection: outputs.DatatransferEndpointSettingsMongoTargetConnection;
    /**
     * Name of the database to transfer.
     */
    database: string;
    /**
     * List of security groups that the transfer associated with this endpoint should use.
     */
    securityGroups: string[];
    /**
     * Identifier of the Yandex Cloud VPC subnetwork to user for accessing the database. If omitted, the server has to be accessible via Internet.
     */
    subnetId: string;
}

export interface DatatransferEndpointSettingsMongoTargetConnection {
    /**
     * Connection options. The structure is documented below.
     */
    connectionOptions: outputs.DatatransferEndpointSettingsMongoTargetConnectionConnectionOptions;
}

export interface DatatransferEndpointSettingsMongoTargetConnectionConnectionOptions {
    /**
     * Name of the database associated with the credentials.
     */
    authSource: string;
    /**
     * Identifier of the Managed ClickHouse cluster.
     */
    mdbClusterId?: string;
    /**
     * Connection settings of the on-premise ClickHouse server.
     */
    onPremise?: outputs.DatatransferEndpointSettingsMongoTargetConnectionConnectionOptionsOnPremise;
    /**
     * Password for the database access. This is a block with a single field named `raw` which should contain the password.
     */
    password: outputs.DatatransferEndpointSettingsMongoTargetConnectionConnectionOptionsPassword;
    /**
     * User for database access.
     */
    user: string;
}

export interface DatatransferEndpointSettingsMongoTargetConnectionConnectionOptionsOnPremise {
    /**
     * Host names of the replica set.
     */
    hosts: string[];
    /**
     * TCP Port number.
     */
    port: number;
    /**
     * Replica set name.
     */
    replicaSet: string;
    /**
     * TLS settings for the server connection. Empty implies plaintext connection. The structure is documented below.
     */
    tlsMode: outputs.DatatransferEndpointSettingsMongoTargetConnectionConnectionOptionsOnPremiseTlsMode;
}

export interface DatatransferEndpointSettingsMongoTargetConnectionConnectionOptionsOnPremiseTlsMode {
    /**
     * Empty block designating that the connection is not secured, i.e. plaintext connection.
     */
    disabled?: outputs.DatatransferEndpointSettingsMongoTargetConnectionConnectionOptionsOnPremiseTlsModeDisabled;
    /**
     * If this attribute is not an empty block, then TLS is used for the server connection. The structure is documented below.
     */
    enabled?: outputs.DatatransferEndpointSettingsMongoTargetConnectionConnectionOptionsOnPremiseTlsModeEnabled;
}

export interface DatatransferEndpointSettingsMongoTargetConnectionConnectionOptionsOnPremiseTlsModeDisabled {
}

export interface DatatransferEndpointSettingsMongoTargetConnectionConnectionOptionsOnPremiseTlsModeEnabled {
    /**
     * X.509 certificate of the certificate authority which issued the server's certificate, in PEM format. If empty, the server's certificate must be signed by a well-known CA.
     */
    caCertificate: string;
}

export interface DatatransferEndpointSettingsMongoTargetConnectionConnectionOptionsPassword {
    raw: string;
}

export interface DatatransferEndpointSettingsMysqlSource {
    /**
     * Connection settings. The structure is documented below.
     */
    connection: outputs.DatatransferEndpointSettingsMysqlSourceConnection;
    /**
     * Name of the database to transfer.
     */
    database: string;
    /**
     * Opposite of `includeTableRegex`. The tables matching the specified regular expressions will not be transferred.
     */
    excludeTablesRegexes: string[];
    /**
     * List of regular expressions of table names which should be transferred. A table name is formatted as schemaname.tablename. For example, a single regular expression may look like `^mydb.employees$`.
     */
    includeTablesRegexes: string[];
    /**
     * Defines which database schema objects should be transferred, e.g. views, functions, etc.
     */
    objectTransferSettings: outputs.DatatransferEndpointSettingsMysqlSourceObjectTransferSettings;
    /**
     * Password for the database access. This is a block with a single field named `raw` which should contain the password.
     */
    password: outputs.DatatransferEndpointSettingsMysqlSourcePassword;
    /**
     * List of security groups that the transfer associated with this endpoint should use.
     */
    securityGroups: string[];
    serviceDatabase: string;
    /**
     * Timezone to use for parsing timestamps for saving source timezones. Accepts values from IANA timezone database. Default: local timezone.
     */
    timezone: string;
    /**
     * User for the database access.
     */
    user: string;
}

export interface DatatransferEndpointSettingsMysqlSourceConnection {
    /**
     * Identifier of the Managed MySQL cluster.
     */
    mdbClusterId?: string;
    /**
     * Connection settings of the on-premise Kafka server.
     */
    onPremise?: outputs.DatatransferEndpointSettingsMysqlSourceConnectionOnPremise;
}

export interface DatatransferEndpointSettingsMysqlSourceConnectionOnPremise {
    /**
     * Host names of the replica set.
     */
    hosts: string[];
    /**
     * TCP Port number.
     */
    port: number;
    /**
     * Identifier of the Yandex Cloud VPC subnetwork to user for accessing the database. If omitted, the server has to be accessible via Internet.
     */
    subnetId: string;
    /**
     * TLS settings for the server connection. Empty implies plaintext connection. The structure is documented below.
     */
    tlsMode: outputs.DatatransferEndpointSettingsMysqlSourceConnectionOnPremiseTlsMode;
}

export interface DatatransferEndpointSettingsMysqlSourceConnectionOnPremiseTlsMode {
    /**
     * Empty block designating that the connection is not secured, i.e. plaintext connection.
     */
    disabled?: outputs.DatatransferEndpointSettingsMysqlSourceConnectionOnPremiseTlsModeDisabled;
    /**
     * If this attribute is not an empty block, then TLS is used for the server connection. The structure is documented below.
     */
    enabled?: outputs.DatatransferEndpointSettingsMysqlSourceConnectionOnPremiseTlsModeEnabled;
}

export interface DatatransferEndpointSettingsMysqlSourceConnectionOnPremiseTlsModeDisabled {
}

export interface DatatransferEndpointSettingsMysqlSourceConnectionOnPremiseTlsModeEnabled {
    /**
     * X.509 certificate of the certificate authority which issued the server's certificate, in PEM format. If empty, the server's certificate must be signed by a well-known CA.
     */
    caCertificate: string;
}

export interface DatatransferEndpointSettingsMysqlSourceObjectTransferSettings {
    routine: string;
    tables: string;
    trigger: string;
    view: string;
}

export interface DatatransferEndpointSettingsMysqlSourcePassword {
    raw: string;
}

export interface DatatransferEndpointSettingsMysqlTarget {
    /**
     * Connection settings. The structure is documented below.
     */
    connection: outputs.DatatransferEndpointSettingsMysqlTargetConnection;
    /**
     * Name of the database to transfer.
     */
    database: string;
    /**
     * Password for the database access. This is a block with a single field named `raw` which should contain the password.
     */
    password: outputs.DatatransferEndpointSettingsMysqlTargetPassword;
    /**
     * List of security groups that the transfer associated with this endpoint should use.
     */
    securityGroups: string[];
    /**
     * When true, disables foreign key checks. See [foreignKeyChecks](https://dev.mysql.com/doc/refman/5.7/en/server-system-variables.html#sysvar_foreign_key_checks). False by default.
     */
    skipConstraintChecks: boolean;
    /**
     * [sqlMode](https://dev.mysql.com/doc/refman/5.7/en/sql-mode.html) to use when interacting with the server. Defaults to "NO_AUTO_VALUE_ON_ZERO,NO_DIR_IN_CREATE,NO_ENGINE_SUBSTITUTION".
     */
    sqlMode: string;
    /**
     * Timezone to use for parsing timestamps for saving source timezones. Accepts values from IANA timezone database. Default: local timezone.
     */
    timezone: string;
    /**
     * User for the database access.
     */
    user: string;
}

export interface DatatransferEndpointSettingsMysqlTargetConnection {
    /**
     * Identifier of the Managed MySQL cluster.
     */
    mdbClusterId?: string;
    /**
     * Connection settings of the on-premise Kafka server.
     */
    onPremise?: outputs.DatatransferEndpointSettingsMysqlTargetConnectionOnPremise;
}

export interface DatatransferEndpointSettingsMysqlTargetConnectionOnPremise {
    /**
     * Host names of the replica set.
     */
    hosts: string[];
    /**
     * TCP Port number.
     */
    port: number;
    /**
     * Identifier of the Yandex Cloud VPC subnetwork to user for accessing the database. If omitted, the server has to be accessible via Internet.
     */
    subnetId: string;
    /**
     * TLS settings for the server connection. Empty implies plaintext connection. The structure is documented below.
     */
    tlsMode: outputs.DatatransferEndpointSettingsMysqlTargetConnectionOnPremiseTlsMode;
}

export interface DatatransferEndpointSettingsMysqlTargetConnectionOnPremiseTlsMode {
    /**
     * Empty block designating that the connection is not secured, i.e. plaintext connection.
     */
    disabled?: outputs.DatatransferEndpointSettingsMysqlTargetConnectionOnPremiseTlsModeDisabled;
    /**
     * If this attribute is not an empty block, then TLS is used for the server connection. The structure is documented below.
     */
    enabled?: outputs.DatatransferEndpointSettingsMysqlTargetConnectionOnPremiseTlsModeEnabled;
}

export interface DatatransferEndpointSettingsMysqlTargetConnectionOnPremiseTlsModeDisabled {
}

export interface DatatransferEndpointSettingsMysqlTargetConnectionOnPremiseTlsModeEnabled {
    /**
     * X.509 certificate of the certificate authority which issued the server's certificate, in PEM format. If empty, the server's certificate must be signed by a well-known CA.
     */
    caCertificate: string;
}

export interface DatatransferEndpointSettingsMysqlTargetPassword {
    raw: string;
}

export interface DatatransferEndpointSettingsPostgresSource {
    /**
     * Connection settings. The structure is documented below.
     */
    connection: outputs.DatatransferEndpointSettingsPostgresSourceConnection;
    /**
     * Name of the database to transfer.
     */
    database: string;
    /**
     * List of tables which will not be transfered, formatted as `schemaname.tablename`.
     */
    excludeTables: string[];
    /**
     * List of tables to transfer, formatted as `schemaname.tablename`. If omitted or an empty list is specified, all tables will be transferred.
     */
    includeTables: string[];
    /**
     * Defines which database schema objects should be transferred, e.g. views, functions, etc.
     */
    objectTransferSettings: outputs.DatatransferEndpointSettingsPostgresSourceObjectTransferSettings;
    /**
     * Password for the database access. This is a block with a single field named `raw` which should contain the password.
     */
    password: outputs.DatatransferEndpointSettingsPostgresSourcePassword;
    /**
     * List of security groups that the transfer associated with this endpoint should use.
     */
    securityGroups: string[];
    /**
     * Name of the database schema in which auxiliary tables needed for the transfer will be created. Empty `serviceSchema` implies schema "public".
     */
    serviceSchema: string;
    /**
     * Maximum WAL size held by the replication slot, in gigabytes. Exceeding this limit will result in a replication failure and deletion of the replication slot. Unlimited by default.
     */
    slotGigabyteLagLimit: number;
    /**
     * User for the database access.
     */
    user: string;
}

export interface DatatransferEndpointSettingsPostgresSourceConnection {
    /**
     * Identifier of the Managed MySQL cluster.
     */
    mdbClusterId?: string;
    /**
     * Connection settings of the on-premise Kafka server.
     */
    onPremise?: outputs.DatatransferEndpointSettingsPostgresSourceConnectionOnPremise;
}

export interface DatatransferEndpointSettingsPostgresSourceConnectionOnPremise {
    /**
     * Host names of the replica set.
     */
    hosts: string[];
    /**
     * TCP Port number.
     */
    port: number;
    /**
     * Identifier of the Yandex Cloud VPC subnetwork to user for accessing the database. If omitted, the server has to be accessible via Internet.
     */
    subnetId: string;
    /**
     * TLS settings for the server connection. Empty implies plaintext connection. The structure is documented below.
     */
    tlsMode: outputs.DatatransferEndpointSettingsPostgresSourceConnectionOnPremiseTlsMode;
}

export interface DatatransferEndpointSettingsPostgresSourceConnectionOnPremiseTlsMode {
    /**
     * Empty block designating that the connection is not secured, i.e. plaintext connection.
     */
    disabled?: outputs.DatatransferEndpointSettingsPostgresSourceConnectionOnPremiseTlsModeDisabled;
    /**
     * If this attribute is not an empty block, then TLS is used for the server connection. The structure is documented below.
     */
    enabled?: outputs.DatatransferEndpointSettingsPostgresSourceConnectionOnPremiseTlsModeEnabled;
}

export interface DatatransferEndpointSettingsPostgresSourceConnectionOnPremiseTlsModeDisabled {
}

export interface DatatransferEndpointSettingsPostgresSourceConnectionOnPremiseTlsModeEnabled {
    /**
     * X.509 certificate of the certificate authority which issued the server's certificate, in PEM format. If empty, the server's certificate must be signed by a well-known CA.
     */
    caCertificate: string;
}

export interface DatatransferEndpointSettingsPostgresSourceObjectTransferSettings {
    cast: string;
    collation: string;
    constraint: string;
    defaultValues: string;
    fkConstraint: string;
    function: string;
    index: string;
    materializedView: string;
    policy: string;
    primaryKey: string;
    rule: string;
    sequence: string;
    sequenceOwnedBy: string;
    sequenceSet: string;
    table: string;
    trigger: string;
    /**
     * Field type, one of: `INT64`, `INT32`, `INT16`, `INT8`, `UINT64`, `UINT32`, `UINT16`, `UINT8`, `DOUBLE`, `BOOLEAN`, `STRING`, `UTF8`, `ANY`, `DATETIME`.
     */
    type: string;
    view: string;
}

export interface DatatransferEndpointSettingsPostgresSourcePassword {
    raw: string;
}

export interface DatatransferEndpointSettingsPostgresTarget {
    /**
     * Connection settings. The structure is documented below.
     */
    connection: outputs.DatatransferEndpointSettingsPostgresTargetConnection;
    /**
     * Name of the database to transfer.
     */
    database: string;
    /**
     * Password for the database access. This is a block with a single field named `raw` which should contain the password.
     */
    password: outputs.DatatransferEndpointSettingsPostgresTargetPassword;
    /**
     * List of security groups that the transfer associated with this endpoint should use.
     */
    securityGroups: string[];
    /**
     * User for the database access.
     */
    user: string;
}

export interface DatatransferEndpointSettingsPostgresTargetConnection {
    /**
     * Identifier of the Managed MySQL cluster.
     */
    mdbClusterId?: string;
    /**
     * Connection settings of the on-premise Kafka server.
     */
    onPremise?: outputs.DatatransferEndpointSettingsPostgresTargetConnectionOnPremise;
}

export interface DatatransferEndpointSettingsPostgresTargetConnectionOnPremise {
    /**
     * Host names of the replica set.
     */
    hosts: string[];
    /**
     * TCP Port number.
     */
    port: number;
    /**
     * Identifier of the Yandex Cloud VPC subnetwork to user for accessing the database. If omitted, the server has to be accessible via Internet.
     */
    subnetId: string;
    /**
     * TLS settings for the server connection. Empty implies plaintext connection. The structure is documented below.
     */
    tlsMode: outputs.DatatransferEndpointSettingsPostgresTargetConnectionOnPremiseTlsMode;
}

export interface DatatransferEndpointSettingsPostgresTargetConnectionOnPremiseTlsMode {
    /**
     * Empty block designating that the connection is not secured, i.e. plaintext connection.
     */
    disabled?: outputs.DatatransferEndpointSettingsPostgresTargetConnectionOnPremiseTlsModeDisabled;
    /**
     * If this attribute is not an empty block, then TLS is used for the server connection. The structure is documented below.
     */
    enabled?: outputs.DatatransferEndpointSettingsPostgresTargetConnectionOnPremiseTlsModeEnabled;
}

export interface DatatransferEndpointSettingsPostgresTargetConnectionOnPremiseTlsModeDisabled {
}

export interface DatatransferEndpointSettingsPostgresTargetConnectionOnPremiseTlsModeEnabled {
    /**
     * X.509 certificate of the certificate authority which issued the server's certificate, in PEM format. If empty, the server's certificate must be signed by a well-known CA.
     */
    caCertificate: string;
}

export interface DatatransferEndpointSettingsPostgresTargetPassword {
    raw: string;
}

export interface DatatransferEndpointSettingsYdbSource {
    /**
     * Name of the database to transfer.
     */
    database: string;
    instance: string;
    paths: string[];
    saKeyContent: string;
    /**
     * List of security groups that the transfer associated with this endpoint should use.
     */
    securityGroups: string[];
    serviceAccountId: string;
    /**
     * Identifier of the Yandex Cloud VPC subnetwork to user for accessing the database. If omitted, the server has to be accessible via Internet.
     */
    subnetId: string;
}

export interface DatatransferEndpointSettingsYdbTarget {
    /**
     * How to clean collections when activating the transfer. One of "DISABLED", "DROP" or "TRUNCATE".
     */
    cleanupPolicy: string;
    /**
     * Name of the database to transfer.
     */
    database: string;
    instance: string;
    /**
     * Path to the field.
     */
    path: string;
    saKeyContent: string;
    /**
     * List of security groups that the transfer associated with this endpoint should use.
     */
    securityGroups: string[];
    serviceAccountId: string;
    /**
     * Identifier of the Yandex Cloud VPC subnetwork to user for accessing the database. If omitted, the server has to be accessible via Internet.
     */
    subnetId: string;
}

export interface FunctionConnectivity {
    networkId: string;
}

export interface FunctionContent {
    zipFilename: string;
}

export interface FunctionPackage {
    bucketName: string;
    objectName: string;
    sha256?: string;
}

export interface FunctionScalingPolicyPolicy {
    tag: string;
    zoneInstancesLimit?: number;
    zoneRequestsLimit?: number;
}

export interface FunctionSecret {
    /**
     * (Required) Function's environment variable in which secret's value will be stored.
     */
    environmentVariable: string;
    /**
     * (Required) Secret's id.
     */
    id: string;
    /**
     * (Required) Secret's entries key which value will be stored in environment variable.
     */
    key: string;
    /**
     * (Required) Secret's version id.
     */
    versionId: string;
}

export interface FunctionTriggerContainer {
    id: string;
    path?: string;
    retryAttempts?: string;
    retryInterval?: string;
    serviceAccountId?: string;
}

export interface FunctionTriggerDlq {
    queueId: string;
    serviceAccountId: string;
}

export interface FunctionTriggerFunction {
    id: string;
    retryAttempts?: string;
    retryInterval?: string;
    serviceAccountId?: string;
    tag?: string;
}

export interface FunctionTriggerIot {
    batchCutoff: string;
    batchSize?: string;
    deviceId?: string;
    registryId: string;
    topic?: string;
}

export interface FunctionTriggerLogGroup {
    batchCutoff: string;
    batchSize?: string;
    logGroupIds: string[];
}

export interface FunctionTriggerLogging {
    batchCutoff: string;
    batchSize?: string;
    groupId: string;
    levels?: string[];
    resourceIds?: string[];
    resourceTypes?: string[];
    streamNames?: string[];
}

export interface FunctionTriggerMessageQueue {
    batchCutoff: string;
    batchSize?: string;
    queueId: string;
    serviceAccountId: string;
    visibilityTimeout?: string;
}

export interface FunctionTriggerObjectStorage {
    batchCutoff: string;
    batchSize?: string;
    bucketId: string;
    create?: boolean;
    delete?: boolean;
    prefix?: string;
    suffix?: string;
    update?: boolean;
}

export interface FunctionTriggerTimer {
    cronExpression: string;
    payload?: string;
}

export interface GetAlbBackendGroupGrpcBackend {
    /**
     * Healthcheck specification that will be used by this backend. Structure is documented below.
     */
    healthcheck: outputs.GetAlbBackendGroupGrpcBackendHealthcheck;
    /**
     * Load Balancing Config specification that will be used by this backend. Structure is documented below.
     */
    loadBalancingConfig: outputs.GetAlbBackendGroupGrpcBackendLoadBalancingConfig;
    /**
     * - Name of the Backend Group.
     */
    name: string;
    /**
     * Port for incoming traffic.
     */
    port: number;
    /**
     * References target groups for the backend.
     */
    targetGroupIds: string[];
    /**
     * Tls specification that will be used by this backend. Structure is documented below.
     */
    tls: outputs.GetAlbBackendGroupGrpcBackendTls;
    /**
     * Weight of the backend. Traffic will be split between backends of the same BackendGroup according to their weights.
     */
    weight: number;
}

export interface GetAlbBackendGroupGrpcBackendHealthcheck {
    /**
     * Grpc Healthcheck specification that will be used by this healthcheck. Structure is documented below.
     */
    grpcHealthcheck: outputs.GetAlbBackendGroupGrpcBackendHealthcheckGrpcHealthcheck;
    /**
     * Optional alternative port for health checking.
     */
    healthcheckPort: number;
    /**
     * Number of consecutive successful health checks required to promote endpoint into the healthy state. 0 means 1. Note that during startup, only a single successful health check is required to mark a host healthy.
     */
    healthyThreshold: number;
    /**
     * Http Healthcheck specification that will be used by this healthcheck. Structure is documented below.
     */
    httpHealthcheck: outputs.GetAlbBackendGroupGrpcBackendHealthcheckHttpHealthcheck;
    /**
     * Interval between health checks.
     */
    interval: string;
    /**
     * An optional jitter amount as a percentage of interval. If specified, during every interval value of (interval_ms * intervalJitterPercent / 100) will be added to the wait time.
     */
    intervalJitterPercent: number;
    /**
     * Stream Healthcheck specification that will be used by this healthcheck. Structure is documented below.
     */
    streamHealthcheck: outputs.GetAlbBackendGroupGrpcBackendHealthcheckStreamHealthcheck;
    /**
     * Time to wait for a health check response.
     */
    timeout: string;
    /**
     * Number of consecutive failed health checks required to demote endpoint into the unhealthy state. 0 means 1. Note that for HTTP health checks, a single 503 immediately makes endpoint unhealthy.
     */
    unhealthyThreshold: number;
}

export interface GetAlbBackendGroupGrpcBackendHealthcheckGrpcHealthcheck {
    /**
     * Optional service name for grpc.health.v1.HealthCheckRequest message.
     */
    serviceName: string;
}

export interface GetAlbBackendGroupGrpcBackendHealthcheckHttpHealthcheck {
    /**
     * Optional "Host" HTTP header value.
     */
    host: string;
    /**
     * If set, health checks will use HTTP2.
     */
    http2: boolean;
    /**
     * HTTP path.
     */
    path: string;
}

export interface GetAlbBackendGroupGrpcBackendHealthcheckStreamHealthcheck {
    /**
     * Optional text that must be contained in the messages received from targets for a successful health check.
     */
    receive: string;
    /**
     * Optional message text sent to targets during TCP data transfer.
     */
    send: string;
}

export interface GetAlbBackendGroupGrpcBackendLoadBalancingConfig {
    /**
     * Percent of traffic to be sent to the same availability zone. The rest will be equally divided between other zones.
     */
    localityAwareRoutingPercent: number;
    /**
     * Load balancing mode for the backend.
     */
    mode: string;
    /**
     * If percentage of healthy hosts in the backend is lower than panic_threshold, traffic will be routed to all backends no matter what the health status is. This helps to avoid healthy backends overloading  when everything is bad. Zero means no panic threshold.
     */
    panicThreshold: number;
    /**
     * If set, will route requests only to the same availability zone. Balancer won't know about endpoints in other zones.
     */
    strictLocality: boolean;
}

export interface GetAlbBackendGroupGrpcBackendTls {
    /**
     * [SNI](https://en.wikipedia.org/wiki/Server_Name_Indication) string for TLS connections.
     * * `validation_context.0.trusted_ca_id` - Trusted CA certificate ID in the Certificate Manager.
     * * `validation_context.0.trusted_ca_bytes` - PEM-encoded trusted CA certificate chain.
     */
    sni: string;
    validationContext: outputs.GetAlbBackendGroupGrpcBackendTlsValidationContext;
}

export interface GetAlbBackendGroupGrpcBackendTlsValidationContext {
    trustedCaBytes: string;
    trustedCaId: string;
}

export interface GetAlbBackendGroupHttpBackend {
    /**
     * Healthcheck specification that will be used by this backend. Structure is documented below.
     */
    healthcheck: outputs.GetAlbBackendGroupHttpBackendHealthcheck;
    /**
     * If set, health checks will use HTTP2.
     */
    http2: boolean;
    /**
     * Load Balancing Config specification that will be used by this backend. Structure is documented below.
     */
    loadBalancingConfig: outputs.GetAlbBackendGroupHttpBackendLoadBalancingConfig;
    /**
     * - Name of the Backend Group.
     */
    name: string;
    /**
     * Port for incoming traffic.
     */
    port: number;
    storageBucket: string;
    /**
     * References target groups for the backend.
     */
    targetGroupIds: string[];
    /**
     * Tls specification that will be used by this backend. Structure is documented below.
     */
    tls: outputs.GetAlbBackendGroupHttpBackendTls;
    /**
     * Weight of the backend. Traffic will be split between backends of the same BackendGroup according to their weights.
     */
    weight: number;
}

export interface GetAlbBackendGroupHttpBackendHealthcheck {
    /**
     * Grpc Healthcheck specification that will be used by this healthcheck. Structure is documented below.
     */
    grpcHealthcheck: outputs.GetAlbBackendGroupHttpBackendHealthcheckGrpcHealthcheck;
    /**
     * Optional alternative port for health checking.
     */
    healthcheckPort: number;
    /**
     * Number of consecutive successful health checks required to promote endpoint into the healthy state. 0 means 1. Note that during startup, only a single successful health check is required to mark a host healthy.
     */
    healthyThreshold: number;
    /**
     * Http Healthcheck specification that will be used by this healthcheck. Structure is documented below.
     */
    httpHealthcheck: outputs.GetAlbBackendGroupHttpBackendHealthcheckHttpHealthcheck;
    /**
     * Interval between health checks.
     */
    interval: string;
    /**
     * An optional jitter amount as a percentage of interval. If specified, during every interval value of (interval_ms * intervalJitterPercent / 100) will be added to the wait time.
     */
    intervalJitterPercent: number;
    /**
     * Stream Healthcheck specification that will be used by this healthcheck. Structure is documented below.
     */
    streamHealthcheck: outputs.GetAlbBackendGroupHttpBackendHealthcheckStreamHealthcheck;
    /**
     * Time to wait for a health check response.
     */
    timeout: string;
    /**
     * Number of consecutive failed health checks required to demote endpoint into the unhealthy state. 0 means 1. Note that for HTTP health checks, a single 503 immediately makes endpoint unhealthy.
     */
    unhealthyThreshold: number;
}

export interface GetAlbBackendGroupHttpBackendHealthcheckGrpcHealthcheck {
    /**
     * Optional service name for grpc.health.v1.HealthCheckRequest message.
     */
    serviceName: string;
}

export interface GetAlbBackendGroupHttpBackendHealthcheckHttpHealthcheck {
    /**
     * Optional "Host" HTTP header value.
     */
    host: string;
    /**
     * If set, health checks will use HTTP2.
     */
    http2: boolean;
    /**
     * HTTP path.
     */
    path: string;
}

export interface GetAlbBackendGroupHttpBackendHealthcheckStreamHealthcheck {
    /**
     * Optional text that must be contained in the messages received from targets for a successful health check.
     */
    receive: string;
    /**
     * Optional message text sent to targets during TCP data transfer.
     */
    send: string;
}

export interface GetAlbBackendGroupHttpBackendLoadBalancingConfig {
    /**
     * Percent of traffic to be sent to the same availability zone. The rest will be equally divided between other zones.
     */
    localityAwareRoutingPercent: number;
    /**
     * Load balancing mode for the backend.
     */
    mode: string;
    /**
     * If percentage of healthy hosts in the backend is lower than panic_threshold, traffic will be routed to all backends no matter what the health status is. This helps to avoid healthy backends overloading  when everything is bad. Zero means no panic threshold.
     */
    panicThreshold: number;
    /**
     * If set, will route requests only to the same availability zone. Balancer won't know about endpoints in other zones.
     */
    strictLocality: boolean;
}

export interface GetAlbBackendGroupHttpBackendTls {
    /**
     * [SNI](https://en.wikipedia.org/wiki/Server_Name_Indication) string for TLS connections.
     * * `validation_context.0.trusted_ca_id` - Trusted CA certificate ID in the Certificate Manager.
     * * `validation_context.0.trusted_ca_bytes` - PEM-encoded trusted CA certificate chain.
     */
    sni: string;
    validationContext: outputs.GetAlbBackendGroupHttpBackendTlsValidationContext;
}

export interface GetAlbBackendGroupHttpBackendTlsValidationContext {
    trustedCaBytes: string;
    trustedCaId: string;
}

export interface GetAlbBackendGroupSessionAffinity {
    connection: outputs.GetAlbBackendGroupSessionAffinityConnection;
    cookie: outputs.GetAlbBackendGroupSessionAffinityCookie;
    header: outputs.GetAlbBackendGroupSessionAffinityHeader;
}

export interface GetAlbBackendGroupSessionAffinityConnection {
    sourceIp: boolean;
}

export interface GetAlbBackendGroupSessionAffinityCookie {
    /**
     * - Name of the Backend Group.
     */
    name: string;
    ttl: string;
}

export interface GetAlbBackendGroupSessionAffinityHeader {
    headerName: string;
}

export interface GetAlbBackendGroupStreamBackend {
    enableProxyProtocol: boolean;
    /**
     * Healthcheck specification that will be used by this backend. Structure is documented below.
     */
    healthcheck: outputs.GetAlbBackendGroupStreamBackendHealthcheck;
    /**
     * Load Balancing Config specification that will be used by this backend. Structure is documented below.
     */
    loadBalancingConfig: outputs.GetAlbBackendGroupStreamBackendLoadBalancingConfig;
    /**
     * - Name of the Backend Group.
     */
    name: string;
    /**
     * Port for incoming traffic.
     */
    port: number;
    /**
     * References target groups for the backend.
     */
    targetGroupIds: string[];
    /**
     * Tls specification that will be used by this backend. Structure is documented below.
     */
    tls: outputs.GetAlbBackendGroupStreamBackendTls;
    /**
     * Weight of the backend. Traffic will be split between backends of the same BackendGroup according to their weights.
     */
    weight: number;
}

export interface GetAlbBackendGroupStreamBackendHealthcheck {
    /**
     * Grpc Healthcheck specification that will be used by this healthcheck. Structure is documented below.
     */
    grpcHealthcheck: outputs.GetAlbBackendGroupStreamBackendHealthcheckGrpcHealthcheck;
    /**
     * Optional alternative port for health checking.
     */
    healthcheckPort: number;
    /**
     * Number of consecutive successful health checks required to promote endpoint into the healthy state. 0 means 1. Note that during startup, only a single successful health check is required to mark a host healthy.
     */
    healthyThreshold: number;
    /**
     * Http Healthcheck specification that will be used by this healthcheck. Structure is documented below.
     */
    httpHealthcheck: outputs.GetAlbBackendGroupStreamBackendHealthcheckHttpHealthcheck;
    /**
     * Interval between health checks.
     */
    interval: string;
    /**
     * An optional jitter amount as a percentage of interval. If specified, during every interval value of (interval_ms * intervalJitterPercent / 100) will be added to the wait time.
     */
    intervalJitterPercent: number;
    /**
     * Stream Healthcheck specification that will be used by this healthcheck. Structure is documented below.
     */
    streamHealthcheck: outputs.GetAlbBackendGroupStreamBackendHealthcheckStreamHealthcheck;
    /**
     * Time to wait for a health check response.
     */
    timeout: string;
    /**
     * Number of consecutive failed health checks required to demote endpoint into the unhealthy state. 0 means 1. Note that for HTTP health checks, a single 503 immediately makes endpoint unhealthy.
     */
    unhealthyThreshold: number;
}

export interface GetAlbBackendGroupStreamBackendHealthcheckGrpcHealthcheck {
    /**
     * Optional service name for grpc.health.v1.HealthCheckRequest message.
     */
    serviceName: string;
}

export interface GetAlbBackendGroupStreamBackendHealthcheckHttpHealthcheck {
    /**
     * Optional "Host" HTTP header value.
     */
    host: string;
    /**
     * If set, health checks will use HTTP2.
     */
    http2: boolean;
    /**
     * HTTP path.
     */
    path: string;
}

export interface GetAlbBackendGroupStreamBackendHealthcheckStreamHealthcheck {
    /**
     * Optional text that must be contained in the messages received from targets for a successful health check.
     */
    receive: string;
    /**
     * Optional message text sent to targets during TCP data transfer.
     */
    send: string;
}

export interface GetAlbBackendGroupStreamBackendLoadBalancingConfig {
    /**
     * Percent of traffic to be sent to the same availability zone. The rest will be equally divided between other zones.
     */
    localityAwareRoutingPercent: number;
    /**
     * Load balancing mode for the backend.
     */
    mode: string;
    /**
     * If percentage of healthy hosts in the backend is lower than panic_threshold, traffic will be routed to all backends no matter what the health status is. This helps to avoid healthy backends overloading  when everything is bad. Zero means no panic threshold.
     */
    panicThreshold: number;
    /**
     * If set, will route requests only to the same availability zone. Balancer won't know about endpoints in other zones.
     */
    strictLocality: boolean;
}

export interface GetAlbBackendGroupStreamBackendTls {
    /**
     * [SNI](https://en.wikipedia.org/wiki/Server_Name_Indication) string for TLS connections.
     * * `validation_context.0.trusted_ca_id` - Trusted CA certificate ID in the Certificate Manager.
     * * `validation_context.0.trusted_ca_bytes` - PEM-encoded trusted CA certificate chain.
     */
    sni: string;
    validationContext: outputs.GetAlbBackendGroupStreamBackendTlsValidationContext;
}

export interface GetAlbBackendGroupStreamBackendTlsValidationContext {
    trustedCaBytes: string;
    trustedCaId: string;
}

export interface GetAlbHttpRouterRouteOption {
    rbacs: outputs.GetAlbHttpRouterRouteOptionRbac[];
}

export interface GetAlbHttpRouterRouteOptionRbac {
    action: string;
    principals: outputs.GetAlbHttpRouterRouteOptionRbacPrincipal[];
}

export interface GetAlbHttpRouterRouteOptionRbacPrincipal {
    andPrincipals: outputs.GetAlbHttpRouterRouteOptionRbacPrincipalAndPrincipal[];
}

export interface GetAlbHttpRouterRouteOptionRbacPrincipalAndPrincipal {
    any: boolean;
    headers: outputs.GetAlbHttpRouterRouteOptionRbacPrincipalAndPrincipalHeader[];
    remoteIp: string;
}

export interface GetAlbHttpRouterRouteOptionRbacPrincipalAndPrincipalHeader {
    /**
     * - Name of the HTTP Router.
     */
    name: string;
    values: outputs.GetAlbHttpRouterRouteOptionRbacPrincipalAndPrincipalHeaderValue[];
}

export interface GetAlbHttpRouterRouteOptionRbacPrincipalAndPrincipalHeaderValue {
    exact: string;
    prefix: string;
    regex: string;
}

export interface GetAlbLoadBalancerAllocationPolicy {
    locations: outputs.GetAlbLoadBalancerAllocationPolicyLocation[];
}

export interface GetAlbLoadBalancerAllocationPolicyLocation {
    disableTraffic: boolean;
    subnetId: string;
    zoneId: string;
}

export interface GetAlbLoadBalancerListener {
    endpoints: outputs.GetAlbLoadBalancerListenerEndpoint[];
    https?: outputs.GetAlbLoadBalancerListenerHttp[];
    name: string;
    stream?: outputs.GetAlbLoadBalancerListenerStream;
    tls?: outputs.GetAlbLoadBalancerListenerTl[];
}

export interface GetAlbLoadBalancerListenerEndpoint {
    addresses: outputs.GetAlbLoadBalancerListenerEndpointAddress[];
    ports: number[];
}

export interface GetAlbLoadBalancerListenerEndpointAddress {
    externalIpv4Addresses: outputs.GetAlbLoadBalancerListenerEndpointAddressExternalIpv4Address[];
    externalIpv6Addresses: outputs.GetAlbLoadBalancerListenerEndpointAddressExternalIpv6Address[];
    internalIpv4Addresses: outputs.GetAlbLoadBalancerListenerEndpointAddressInternalIpv4Address[];
}

export interface GetAlbLoadBalancerListenerEndpointAddressExternalIpv4Address {
    address: string;
}

export interface GetAlbLoadBalancerListenerEndpointAddressExternalIpv6Address {
    address: string;
}

export interface GetAlbLoadBalancerListenerEndpointAddressInternalIpv4Address {
    address: string;
    subnetId: string;
}

export interface GetAlbLoadBalancerListenerHttp {
    handlers?: outputs.GetAlbLoadBalancerListenerHttpHandler[];
    redirects?: outputs.GetAlbLoadBalancerListenerHttpRedirect[];
}

export interface GetAlbLoadBalancerListenerHttpHandler {
    allowHttp10?: boolean;
    http2Options: outputs.GetAlbLoadBalancerListenerHttpHandlerHttp2Option[];
    httpRouterId: string;
    rewriteRequestId: boolean;
}

export interface GetAlbLoadBalancerListenerHttpHandlerHttp2Option {
    maxConcurrentStreams: number;
}

export interface GetAlbLoadBalancerListenerHttpRedirect {
    httpToHttps: boolean;
}

export interface GetAlbLoadBalancerListenerStream {
    handlers?: outputs.GetAlbLoadBalancerListenerStreamHandler[];
}

export interface GetAlbLoadBalancerListenerStreamHandler {
    backendGroupId: string;
}

export interface GetAlbLoadBalancerListenerTl {
    defaultHandlers: outputs.GetAlbLoadBalancerListenerTlDefaultHandler[];
    sniHandlers: outputs.GetAlbLoadBalancerListenerTlSniHandler[];
}

export interface GetAlbLoadBalancerListenerTlDefaultHandler {
    certificateIds: string[];
    httpHandlers?: outputs.GetAlbLoadBalancerListenerTlDefaultHandlerHttpHandler[];
    streamHandlers?: outputs.GetAlbLoadBalancerListenerTlDefaultHandlerStreamHandler[];
}

export interface GetAlbLoadBalancerListenerTlDefaultHandlerHttpHandler {
    allowHttp10?: boolean;
    http2Options: outputs.GetAlbLoadBalancerListenerTlDefaultHandlerHttpHandlerHttp2Option[];
    httpRouterId: string;
    rewriteRequestId: boolean;
}

export interface GetAlbLoadBalancerListenerTlDefaultHandlerHttpHandlerHttp2Option {
    maxConcurrentStreams: number;
}

export interface GetAlbLoadBalancerListenerTlDefaultHandlerStreamHandler {
    backendGroupId: string;
}

export interface GetAlbLoadBalancerListenerTlSniHandler {
    handlers: outputs.GetAlbLoadBalancerListenerTlSniHandlerHandler[];
    name: string;
    serverNames: string[];
}

export interface GetAlbLoadBalancerListenerTlSniHandlerHandler {
    certificateIds: string[];
    httpHandlers?: outputs.GetAlbLoadBalancerListenerTlSniHandlerHandlerHttpHandler[];
    streamHandlers?: outputs.GetAlbLoadBalancerListenerTlSniHandlerHandlerStreamHandler[];
}

export interface GetAlbLoadBalancerListenerTlSniHandlerHandlerHttpHandler {
    allowHttp10?: boolean;
    http2Options: outputs.GetAlbLoadBalancerListenerTlSniHandlerHandlerHttpHandlerHttp2Option[];
    httpRouterId: string;
    rewriteRequestId: boolean;
}

export interface GetAlbLoadBalancerListenerTlSniHandlerHandlerHttpHandlerHttp2Option {
    maxConcurrentStreams: number;
}

export interface GetAlbLoadBalancerListenerTlSniHandlerHandlerStreamHandler {
    backendGroupId: string;
}

export interface GetAlbLoadBalancerLogOption {
    disable: boolean;
    discardRules: outputs.GetAlbLoadBalancerLogOptionDiscardRule[];
    logGroupId: string;
}

export interface GetAlbLoadBalancerLogOptionDiscardRule {
    discardPercent: number;
    grpcCodes: string[];
    httpCodeIntervals: string[];
    httpCodes: number[];
}

export interface GetAlbTargetGroupTarget {
    ipAddress: string;
    privateIpv4Address?: boolean;
    subnetId?: string;
}

export interface GetAlbVirtualHostModifyRequestHeader {
    /**
     * Append string to the header value.
     */
    append: string;
    /**
     * Name of the Virtual Host.
     */
    name: string;
    /**
     * If set, remove the header.
     */
    remove: boolean;
    /**
     * New value for a header. Header values support the following
     * [formatters](https://www.envoyproxy.io/docs/envoy/latest/configuration/http/http_conn_man/headers#custom-request-response-headers).
     */
    replace: string;
}

export interface GetAlbVirtualHostModifyResponseHeader {
    /**
     * Append string to the header value.
     */
    append: string;
    /**
     * Name of the Virtual Host.
     */
    name: string;
    /**
     * If set, remove the header.
     */
    remove: boolean;
    /**
     * New value for a header. Header values support the following
     * [formatters](https://www.envoyproxy.io/docs/envoy/latest/configuration/http/http_conn_man/headers#custom-request-response-headers).
     */
    replace: string;
}

export interface GetAlbVirtualHostRoute {
    /**
     * GRPC route resource. The structure is documented below.
     */
    grpcRoutes: outputs.GetAlbVirtualHostRouteGrpcRoute[];
    /**
     * HTTP route resource. The structure is documented below.
     */
    httpRoutes: outputs.GetAlbVirtualHostRouteHttpRoute[];
    /**
     * Name of the Virtual Host.
     */
    name: string;
    routeOptions: outputs.GetAlbVirtualHostRouteRouteOption[];
}

export interface GetAlbVirtualHostRouteGrpcRoute {
    /**
     * Checks "/" prefix by default. The structure is documented below.
     */
    grpcMatches: outputs.GetAlbVirtualHostRouteGrpcRouteGrpcMatch[];
    /**
     * GRPC route action resource. The structure is documented below.
     */
    grpcRouteActions: outputs.GetAlbVirtualHostRouteGrpcRouteGrpcRouteAction[];
    /**
     * (Required) GRPC status response action resource. The structure is documented below.
     */
    grpcStatusResponseActions: outputs.GetAlbVirtualHostRouteGrpcRouteGrpcStatusResponseAction[];
}

export interface GetAlbVirtualHostRouteGrpcRouteGrpcMatch {
    /**
     * If not set, all services/methods are assumed. The structure is documented below.
     */
    fqmns: outputs.GetAlbVirtualHostRouteGrpcRouteGrpcMatchFqmn[];
}

export interface GetAlbVirtualHostRouteGrpcRouteGrpcMatchFqmn {
    exact: string;
    prefix: string;
    regex: string;
}

export interface GetAlbVirtualHostRouteGrpcRouteGrpcRouteAction {
    /**
     * If set, will automatically rewrite host.
     */
    autoHostRewrite: boolean;
    /**
     * Backend group to route requests.
     */
    backendGroupId: string;
    /**
     * Host rewrite specifier.
     */
    hostRewrite: string;
    /**
     * Specifies the idle timeout (time without any data transfer for the active request) for the route. It
     * is useful for streaming scenarios - one should set idleTimeout to something meaningful and maxTimeout to the maximum
     * time the stream is allowed to be alive. If not specified, there is no per-route idle timeout.
     */
    idleTimeout: string;
    /**
     * Lower timeout may be specified by the client (using grpc-timeout header). If not set, default is 60
     * seconds.
     */
    maxTimeout: string;
}

export interface GetAlbVirtualHostRouteGrpcRouteGrpcStatusResponseAction {
    /**
     * The status of the response. Supported values are: ok, invalid_argumet, not_found, permission_denied,
     * unauthenticated, unimplemented, internal, unavailable.
     */
    status: string;
}

export interface GetAlbVirtualHostRouteHttpRoute {
    /**
     * (Required) Direct response action resource. The structure is documented below.
     */
    directResponseActions: outputs.GetAlbVirtualHostRouteHttpRouteDirectResponseAction[];
    /**
     * Checks "/" prefix by default. The structure is documented below.
     */
    httpMatches: outputs.GetAlbVirtualHostRouteHttpRouteHttpMatch[];
    /**
     * HTTP route action resource. The structure is documented below.
     */
    httpRouteActions: outputs.GetAlbVirtualHostRouteHttpRouteHttpRouteAction[];
    /**
     * Redirect action resource. The structure is documented below.
     */
    redirectActions: outputs.GetAlbVirtualHostRouteHttpRouteRedirectAction[];
}

export interface GetAlbVirtualHostRouteHttpRouteDirectResponseAction {
    /**
     * Response body text.
     */
    body: string;
    /**
     * The status of the response. Supported values are: ok, invalid_argumet, not_found, permission_denied,
     * unauthenticated, unimplemented, internal, unavailable.
     */
    status: number;
}

export interface GetAlbVirtualHostRouteHttpRouteHttpMatch {
    /**
     * List of methods(strings).
     */
    httpMethods: string[];
    /**
     * If not set, '/' is assumed. The structure is documented below.
     */
    paths: outputs.GetAlbVirtualHostRouteHttpRouteHttpMatchPath[];
}

export interface GetAlbVirtualHostRouteHttpRouteHttpMatchPath {
    exact: string;
    prefix: string;
    regex: string;
}

export interface GetAlbVirtualHostRouteHttpRouteHttpRouteAction {
    /**
     * If set, will automatically rewrite host.
     */
    autoHostRewrite: boolean;
    /**
     * Backend group to route requests.
     */
    backendGroupId: string;
    /**
     * Host rewrite specifier.
     */
    hostRewrite: string;
    /**
     * Specifies the idle timeout (time without any data transfer for the active request) for the route. It
     * is useful for streaming scenarios - one should set idleTimeout to something meaningful and maxTimeout to the maximum
     * time the stream is allowed to be alive. If not specified, there is no per-route idle timeout.
     */
    idleTimeout: string;
    /**
     * If not empty, matched path prefix will be replaced by this value.
     */
    prefixRewrite: string;
    /**
     * Specifies the request timeout (overall time request processing is allowed to take) for the route. If not
     * set, default is 60 seconds.
     */
    timeout: string;
    /**
     * List of upgrade types. Only specified upgrade types will be allowed. For example,
     * "websocket".
     */
    upgradeTypes: string[];
}

export interface GetAlbVirtualHostRouteHttpRouteRedirectAction {
    removeQuery: boolean;
    /**
     * Replaces hostname.
     */
    replaceHost: string;
    /**
     * Replace path.
     */
    replacePath: string;
    /**
     * Replaces port.
     */
    replacePort: number;
    /**
     * Replace only matched prefix. Example:<br/> match:{ prefix_match: "/some" } <br/>
     * redirect: { replace_prefix: "/other" } <br/> will redirect "/something" to "/otherthing".
     */
    replacePrefix: string;
    /**
     * Replaces scheme. If the original scheme is `http` or `https`, will also remove the 80 or 443 port,
     * if present.
     */
    replaceScheme: string;
    /**
     * The HTTP status code to use in the redirect response. Supported values are:
     * moved_permanently, found, see_other, temporary_redirect, permanent_redirect.
     */
    responseCode: string;
}

export interface GetAlbVirtualHostRouteOption {
    rbacs: outputs.GetAlbVirtualHostRouteOptionRbac[];
}

export interface GetAlbVirtualHostRouteOptionRbac {
    action: string;
    principals: outputs.GetAlbVirtualHostRouteOptionRbacPrincipal[];
}

export interface GetAlbVirtualHostRouteOptionRbacPrincipal {
    andPrincipals: outputs.GetAlbVirtualHostRouteOptionRbacPrincipalAndPrincipal[];
}

export interface GetAlbVirtualHostRouteOptionRbacPrincipalAndPrincipal {
    any: boolean;
    headers: outputs.GetAlbVirtualHostRouteOptionRbacPrincipalAndPrincipalHeader[];
    remoteIp: string;
}

export interface GetAlbVirtualHostRouteOptionRbacPrincipalAndPrincipalHeader {
    /**
     * Name of the Virtual Host.
     */
    name: string;
    values: outputs.GetAlbVirtualHostRouteOptionRbacPrincipalAndPrincipalHeaderValue[];
}

export interface GetAlbVirtualHostRouteOptionRbacPrincipalAndPrincipalHeaderValue {
    exact: string;
    prefix: string;
    regex: string;
}

export interface GetAlbVirtualHostRouteRouteOption {
    rbacs: outputs.GetAlbVirtualHostRouteRouteOptionRbac[];
}

export interface GetAlbVirtualHostRouteRouteOptionRbac {
    action: string;
    principals: outputs.GetAlbVirtualHostRouteRouteOptionRbacPrincipal[];
}

export interface GetAlbVirtualHostRouteRouteOptionRbacPrincipal {
    andPrincipals: outputs.GetAlbVirtualHostRouteRouteOptionRbacPrincipalAndPrincipal[];
}

export interface GetAlbVirtualHostRouteRouteOptionRbacPrincipalAndPrincipal {
    any: boolean;
    headers: outputs.GetAlbVirtualHostRouteRouteOptionRbacPrincipalAndPrincipalHeader[];
    remoteIp: string;
}

export interface GetAlbVirtualHostRouteRouteOptionRbacPrincipalAndPrincipalHeader {
    /**
     * Name of the Virtual Host.
     */
    name: string;
    values: outputs.GetAlbVirtualHostRouteRouteOptionRbacPrincipalAndPrincipalHeaderValue[];
}

export interface GetAlbVirtualHostRouteRouteOptionRbacPrincipalAndPrincipalHeaderValue {
    exact: string;
    prefix: string;
    regex: string;
}

export interface GetApiGatewayCanary {
    variables?: {[key: string]: string};
    weight?: number;
}

export interface GetApiGatewayConnectivity {
    networkId: string;
}

export interface GetApiGatewayCustomDomain {
    certificateId: string;
    domainId: string;
    fqdn: string;
}

export interface GetCdnOriginGroupOrigin {
    /**
     * specifies whether the origin is used in its origin group as backup. A backup origin is used when one of active origins becomes unavailable.
     */
    backup?: boolean;
    /**
     * the origin is enabled and used as a source for the CDN. Default is enabled.
     */
    enabled?: boolean;
    /**
     * The ID of a specific origin group.
     */
    originGroupId: number;
    /**
     * IP address or Domain name of your origin and the port;
     */
    source: string;
}

export interface GetCdnResourceOptions {
    /**
     * HTTP methods for your CDN content. By default the following methods are allowed: GET, HEAD, POST, PUT, PATCH, DELETE, OPTIONS. In case some methods are not allowed to the user, they will get the 405 (Method Not Allowed) response. If the method is not supported, the user gets the 501 (Not Implemented) response.
     */
    allowedHttpMethods: string[];
    /**
     * set up a cache period for the end-users browser. Content will be cached due to origin settings. If there are no cache settings on your origin, the content will not be cached. The list of HTTP response codes that can be cached in browsers: 200, 201, 204, 206, 301, 302, 303, 304, 307, 308. Other response codes will not be cached. The default value is 4 days.
     */
    browserCacheSettings: number;
    /**
     * list HTTP headers that must be included in responses to clients.
     */
    cacheHttpHeaders: string[];
    /**
     * parameter that lets browsers get access to selected resources from a domain different to a domain from which the request is received.
     */
    cors: string[];
    /**
     * custom value for the Host header. Your server must be able to process requests with the chosen header.
     */
    customHostHeader: string;
    /**
     * wildcard additional CNAME. If a resource has a wildcard additional CNAME, you can use your own certificate for content delivery via HTTPS. Read-only.
     */
    customServerName: string;
    /**
     * setup a cache status.
     */
    disableCache: boolean;
    /**
     * disabling proxy force ranges.
     */
    disableProxyForceRanges: boolean;
    /**
     * content will be cached according to origin cache settings. The value applies for a response with codes 200, 201, 204, 206, 301, 302, 303, 304, 307, 308 if an origin server does not have caching HTTP headers. Responses with other codes will not be cached.
     */
    edgeCacheSettings: number;
    /**
     * option helps you to reduce the bandwidth between origin and CDN servers. Also, content delivery speed becomes higher because of reducing the time for compressing files in a CDN.
     */
    fetchedCompressed: boolean;
    /**
     * choose the Forward Host header option if is important to send in the request to the Origin the same Host header as was sent in the request to CDN server.
     */
    forwardHostHeader: boolean;
    /**
     * GZip compression at CDN servers reduces file size by 70% and can be as high as 90%.
     */
    gzipOn: boolean;
    /**
     * set for ignoring cookie.
     */
    ignoreCookie: boolean;
    /**
     * files with different query parameters are cached as objects with the same key regardless of the parameter value. selected by default.
     */
    ignoreQueryParams: boolean;
    /**
     * allows caching for GET, HEAD and POST requests.
     */
    proxyCacheMethodsSet: boolean;
    /**
     * files with the specified query parameters are cached as objects with the same key, files with other parameters are cached as objects with different keys.
     */
    queryParamsBlacklists: string[];
    /**
     * files with the specified query parameters are cached as objects with different keys, files with other parameters are cached as objects with the same key.
     */
    queryParamsWhitelists: string[];
    /**
     * set up a redirect from HTTPS to HTTP.
     */
    redirectHttpToHttps: boolean;
    /**
     * set up a redirect from HTTP to HTTPS.
     */
    redirectHttpsToHttp: boolean;
    /**
     * files larger than 10 MB will be requested and cached in parts (no larger than 10 MB each part). It reduces time to first byte. The origin must support HTTP Range requests.
     */
    slice: boolean;
    /**
     * set up custom headers that CDN servers send in requests to origins.
     */
    staticRequestHeaders: {[key: string]: string};
    staticResponseHeaders: {[key: string]: string};
}

export interface GetCdnResourceSslCertificate {
    certificateManagerId?: string;
    status: string;
    type: string;
}

export interface GetCmCertificateChallenge {
    createdAt: string;
    dnsName: string;
    dnsType: string;
    dnsValue: string;
    domain: string;
    httpContent: string;
    httpUrl: string;
    message: string;
    type: string;
    updatedAt: string;
}

export interface GetComputeDiskDiskPlacementPolicy {
    diskPlacementGroupId: string;
}

export interface GetComputeInstanceBootDisk {
    /**
     * Specifies whether the disk is auto-deleted when the instance is deleted.
     */
    autoDelete: boolean;
    /**
     * Name of the device.
     */
    deviceName: string;
    /**
     * ID of the disk that is attached to the instance.
     */
    diskId: string;
    /**
     * Parameters used for creating a disk alongside the instance. The structure is documented below.
     */
    initializeParams: outputs.GetComputeInstanceBootDiskInitializeParam[];
    /**
     * Access to the Disk resource. By default, a disk is attached in `READ_WRITE` mode.
     */
    mode: string;
}

export interface GetComputeInstanceBootDiskInitializeParam {
    /**
     * The block size of the disk in bytes.
     */
    blockSize: number;
    /**
     * Description of the boot disk.
     */
    description: string;
    /**
     * A disk image to initialize this disk from.
     */
    imageId: string;
    /**
     * Name of the instance.
     */
    name: string;
    /**
     * Size of the disk in GB.
     */
    size: number;
    /**
     * A snapshot to initialize this disk from.
     */
    snapshotId: string;
    /**
     * Disk type.
     */
    type: string;
}

export interface GetComputeInstanceFilesystem {
    /**
     * Name of the device.
     */
    deviceName: string;
    filesystemId: string;
    /**
     * Access to the Disk resource. By default, a disk is attached in `READ_WRITE` mode.
     */
    mode: string;
}

export interface GetComputeInstanceGroupAllocationPolicy {
    /**
     * A list of availability zones.
     */
    zones: string[];
}

export interface GetComputeInstanceGroupApplicationBalancerState {
    /**
     * The status message of the target group.
     */
    statusMessage: string;
    /**
     * The ID of the target group.
     */
    targetGroupId: string;
}

export interface GetComputeInstanceGroupApplicationLoadBalancer {
    /**
     * Timeout for waiting for the VM to be checked by the load balancer. If the timeout is exceeded, the VM will be turned off based on the deployment policy. Specified in seconds.
     */
    maxOpeningTrafficDuration: number;
    /**
     * The status message of the target group.
     */
    statusMessage: string;
    /**
     * A description of the target group.
     */
    targetGroupDescription: string;
    /**
     * The ID of the target group.
     */
    targetGroupId: string;
    /**
     * A set of key/value label pairs.
     */
    targetGroupLabels: {[key: string]: string};
    /**
     * The name of the target group.
     */
    targetGroupName: string;
}

export interface GetComputeInstanceGroupDeployPolicy {
    /**
     * The maximum number of instances that can be created at the same time.
     */
    maxCreating: number;
    /**
     * The maximum number of instances that can be deleted at the same time.
     */
    maxDeleting: number;
    /**
     * The maximum number of instances that can be temporarily allocated above the group's target size during the update process.
     */
    maxExpansion: number;
    /**
     * The maximum number of running instances that can be taken offline (stopped or deleted) at the same time
     * during the update process.
     */
    maxUnavailable: number;
    /**
     * The amount of time in seconds to allow for an instance to start.
     */
    startupDuration: number;
    /**
     * Affects the lifecycle of the instance during deployment. If set to `proactive` (default), Instance Groups
     * can forcefully stop a running instance. If `opportunistic`, Instance Groups does not stop a running instance. Instead,
     * it will wait until the instance stops itself or becomes unhealthy.
     */
    strategy: string;
}

export interface GetComputeInstanceGroupHealthCheck {
    /**
     * The number of successful health checks before the managed instance is declared healthy.
     */
    healthyThreshold: number;
    /**
     * HTTP check options. The structure is documented below.
     */
    httpOptions: outputs.GetComputeInstanceGroupHealthCheckHttpOption[];
    /**
     * The interval between health checks in seconds.
     */
    interval: number;
    /**
     * TCP check options. The structure is documented below.
     */
    tcpOptions: outputs.GetComputeInstanceGroupHealthCheckTcpOption[];
    /**
     * Timeout for the managed instance to return a response for the health check in seconds.
     */
    timeout: number;
    /**
     * The number of failed health checks before the managed instance is declared unhealthy.
     */
    unhealthyThreshold: number;
}

export interface GetComputeInstanceGroupHealthCheckHttpOption {
    /**
     * The URL path used for health check requests.
     */
    path: string;
    /**
     * The port to use for TCP health checks.
     */
    port: number;
}

export interface GetComputeInstanceGroupHealthCheckTcpOption {
    /**
     * The port to use for TCP health checks.
     */
    port: number;
}

export interface GetComputeInstanceGroupInstance {
    /**
     * The Fully Qualified Domain Name.
     */
    fqdn: string;
    /**
     * The ID of the instance.
     */
    instanceId: string;
    /**
     * The name of the managed instance.
     */
    name: string;
    /**
     * An array with the network interfaces attached to the managed instance. The structure is documented below.
     * * `statusChangedAt` -The timestamp when the status of the managed instance was last changed.
     */
    networkInterfaces: outputs.GetComputeInstanceGroupInstanceNetworkInterface[];
    /**
     * The status of the instance.
     */
    status: string;
    statusChangedAt: string;
    /**
     * The status message of the target group.
     */
    statusMessage: string;
    /**
     * The ID of the availability zone where the instance resides.
     */
    zoneId: string;
}

export interface GetComputeInstanceGroupInstanceNetworkInterface {
    /**
     * The index of the network interface as generated by the server.
     */
    index: number;
    /**
     * The private IP address to assign to the instance. If empty, the address is automatically assigned from the specified subnet.
     */
    ipAddress: string;
    /**
     * Is IPv4 address assigned.
     */
    ipv4: boolean;
    ipv6: boolean;
    /**
     * Manual set static IPv6 address.
     */
    ipv6Address: string;
    /**
     * The MAC address assigned to the network interface.
     */
    macAddress: string;
    /**
     * The instance's public address for accessing the internet over NAT.
     */
    nat: boolean;
    /**
     * The public IP address of the instance.
     */
    natIpAddress: string;
    /**
     * The IP version for the public address.
     */
    natIpVersion: string;
    /**
     * The ID of the subnet to attach this interface to. The subnet must reside in the same zone where this instance was created.
     */
    subnetId: string;
}

export interface GetComputeInstanceGroupInstanceTemplate {
    /**
     * The specifications for boot disk that will be attached to the instance. The structure is documented below.
     */
    bootDisks: outputs.GetComputeInstanceGroupInstanceTemplateBootDisk[];
    /**
     * A description of the boot disk.
     */
    description: string;
    /**
     * Hostname temaplate for the instance.
     */
    hostname: string;
    /**
     * A map of labels applied to this instance.
     * * `resources.0.memory` - The memory size allocated to the instance.
     * * `resources.0.cores` - Number of CPU cores allocated to the instance.
     * * `resources.0.core_fraction` - Baseline core performance as a percent.
     * * `resources.0.gpus` - Number of GPU cores allocated to the instance.
     */
    labels: {[key: string]: string};
    /**
     * The set of metadata `key:value` pairs assigned to this instance template. This includes custom metadata and predefined keys.
     */
    metadata: {[key: string]: string};
    /**
     * The name of the managed instance.
     */
    name: string;
    /**
     * An array with the network interfaces attached to the managed instance. The structure is documented below.
     * * `statusChangedAt` -The timestamp when the status of the managed instance was last changed.
     */
    networkInterfaces: outputs.GetComputeInstanceGroupInstanceTemplateNetworkInterface[];
    /**
     * Network acceleration settings. The structure is documented below.
     */
    networkSettings: outputs.GetComputeInstanceGroupInstanceTemplateNetworkSetting[];
    placementPolicy?: outputs.GetComputeInstanceGroupInstanceTemplatePlacementPolicy;
    /**
     * The ID of the hardware platform configuration for the instance.
     */
    platformId: string;
    resources: outputs.GetComputeInstanceGroupInstanceTemplateResource[];
    /**
     * The scheduling policy for the instance. The structure is documented below.
     */
    schedulingPolicies: outputs.GetComputeInstanceGroupInstanceTemplateSchedulingPolicy[];
    /**
     * An array with the secondary disks that will be attached to the instance. The structure is documented below.
     */
    secondaryDisks: outputs.GetComputeInstanceGroupInstanceTemplateSecondaryDisk[];
    /**
     * The service account ID for the instance.
     */
    serviceAccountId: string;
}

export interface GetComputeInstanceGroupInstanceTemplateBootDisk {
    /**
     * This value can be used to reference the device under `/dev/disk/by-id/`.
     */
    deviceName: string;
    /**
     * ID of the existing disk. To set use variables.
     */
    diskId: string;
    /**
     * The parameters used for creating a disk alongside the instance. The structure is documented below.
     */
    initializeParams: outputs.GetComputeInstanceGroupInstanceTemplateBootDiskInitializeParam[];
    /**
     * The access mode to the disk resource. By default a disk is attached in `READ_WRITE` mode.
     */
    mode: string;
}

export interface GetComputeInstanceGroupInstanceTemplateBootDiskInitializeParam {
    /**
     * A description of the boot disk.
     */
    description: string;
    /**
     * The disk image to initialize this disk from.
     */
    imageId: string;
    /**
     * The size of the disk in GB.
     */
    size: number;
    /**
     * The snapshot to initialize this disk from.
     */
    snapshotId: string;
    /**
     * Network acceleration type. By default a network is in `STANDARD` mode.
     */
    type: string;
}

export interface GetComputeInstanceGroupInstanceTemplateNetworkInterface {
    /**
     * List of dns records.  The structure is documented below.
     */
    dnsRecords: outputs.GetComputeInstanceGroupInstanceTemplateNetworkInterfaceDnsRecord[];
    /**
     * The private IP address to assign to the instance. If empty, the address is automatically assigned from the specified subnet.
     */
    ipAddress: string;
    /**
     * Is IPv4 address assigned.
     */
    ipv4: boolean;
    ipv6: boolean;
    /**
     * Manual set static IPv6 address.
     */
    ipv6Address: string;
    /**
     * List of ipv6 dns records.  The structure is documented below.
     */
    ipv6DnsRecords: outputs.GetComputeInstanceGroupInstanceTemplateNetworkInterfaceIpv6DnsRecord[];
    /**
     * The instance's public address for accessing the internet over NAT.
     */
    nat: boolean;
    /**
     * List of nat dns records.  The structure is documented below.
     */
    natDnsRecords: outputs.GetComputeInstanceGroupInstanceTemplateNetworkInterfaceNatDnsRecord[];
    /**
     * The public IP address of the instance.
     */
    natIpAddress: string;
    /**
     * The ID of the network.
     */
    networkId: string;
    /**
     * Security group ids for network interface.
     */
    securityGroupIds: string[];
    /**
     * The IDs of the subnets.
     */
    subnetIds: string[];
}

export interface GetComputeInstanceGroupInstanceTemplateNetworkInterfaceDnsRecord {
    /**
     * DNS zone id (if not set, private zone is used).
     */
    dnsZoneId: string;
    /**
     * The Fully Qualified Domain Name.
     */
    fqdn: string;
    /**
     * When set to true, also create PTR DNS record.
     */
    ptr: boolean;
    /**
     * DNS record TTL.
     */
    ttl: number;
}

export interface GetComputeInstanceGroupInstanceTemplateNetworkInterfaceIpv6DnsRecord {
    /**
     * DNS zone id (if not set, private zone is used).
     */
    dnsZoneId: string;
    /**
     * The Fully Qualified Domain Name.
     */
    fqdn: string;
    /**
     * When set to true, also create PTR DNS record.
     */
    ptr: boolean;
    /**
     * DNS record TTL.
     */
    ttl: number;
}

export interface GetComputeInstanceGroupInstanceTemplateNetworkInterfaceNatDnsRecord {
    /**
     * DNS zone id (if not set, private zone is used).
     */
    dnsZoneId: string;
    /**
     * The Fully Qualified Domain Name.
     */
    fqdn: string;
    /**
     * When set to true, also create PTR DNS record.
     */
    ptr: boolean;
    /**
     * DNS record TTL.
     */
    ttl: number;
}

export interface GetComputeInstanceGroupInstanceTemplateNetworkSetting {
    /**
     * Network acceleration type. By default a network is in `STANDARD` mode.
     */
    type: string;
}

export interface GetComputeInstanceGroupInstanceTemplatePlacementPolicy {
    placementGroupId: string;
}

export interface GetComputeInstanceGroupInstanceTemplateResource {
    coreFraction: number;
    cores: number;
    gpus: number;
    memory: number;
}

export interface GetComputeInstanceGroupInstanceTemplateSchedulingPolicy {
    /**
     * Specifies if the instance is preemptible. Defaults to false.
     */
    preemptible: boolean;
}

export interface GetComputeInstanceGroupInstanceTemplateSecondaryDisk {
    /**
     * This value can be used to reference the device under `/dev/disk/by-id/`.
     */
    deviceName: string;
    /**
     * ID of the existing disk. To set use variables.
     */
    diskId: string;
    /**
     * The parameters used for creating a disk alongside the instance. The structure is documented below.
     */
    initializeParams: outputs.GetComputeInstanceGroupInstanceTemplateSecondaryDiskInitializeParam[];
    /**
     * The access mode to the disk resource. By default a disk is attached in `READ_WRITE` mode.
     */
    mode: string;
}

export interface GetComputeInstanceGroupInstanceTemplateSecondaryDiskInitializeParam {
    /**
     * A description of the boot disk.
     */
    description: string;
    /**
     * The disk image to initialize this disk from.
     */
    imageId: string;
    /**
     * The size of the disk in GB.
     */
    size: number;
    /**
     * The snapshot to initialize this disk from.
     */
    snapshotId: string;
    /**
     * Network acceleration type. By default a network is in `STANDARD` mode.
     */
    type: string;
}

export interface GetComputeInstanceGroupLoadBalancer {
    /**
     * Timeout for waiting for the VM to be checked by the load balancer. If the timeout is exceeded, the VM will be turned off based on the deployment policy. Specified in seconds.
     */
    maxOpeningTrafficDuration: number;
    /**
     * The status message of the target group.
     */
    statusMessage: string;
    /**
     * A description of the target group.
     */
    targetGroupDescription: string;
    /**
     * The ID of the target group.
     */
    targetGroupId: string;
    /**
     * A set of key/value label pairs.
     */
    targetGroupLabels: {[key: string]: string};
    /**
     * The name of the target group.
     */
    targetGroupName: string;
}

export interface GetComputeInstanceGroupLoadBalancerState {
    /**
     * The status message of the target group.
     */
    statusMessage: string;
    /**
     * The ID of the target group.
     */
    targetGroupId: string;
}

export interface GetComputeInstanceGroupScalePolicy {
    /**
     * The auto scaling policy of the instance group. The structure is documented below.
     */
    autoScales: outputs.GetComputeInstanceGroupScalePolicyAutoScale[];
    /**
     * The fixed scaling policy of the instance group. The structure is documented below.
     */
    fixedScales: outputs.GetComputeInstanceGroupScalePolicyFixedScale[];
    /**
     * The test auto scaling policy of the instance group. Use it to test how the auto scale works. The structure is documented below.
     */
    testAutoScales: outputs.GetComputeInstanceGroupScalePolicyTestAutoScale[];
}

export interface GetComputeInstanceGroupScalePolicyAutoScale {
    /**
     * Target CPU load level.
     */
    cpuUtilizationTarget: number;
    /**
     * A list of custom rules. The structure is documented below.
     */
    customRules: outputs.GetComputeInstanceGroupScalePolicyAutoScaleCustomRule[];
    /**
     * The initial number of instances in the instance group.
     */
    initialSize: number;
    /**
     * The maximum number of virtual machines in the group.
     */
    maxSize: number;
    /**
     * The amount of time, in seconds, that metrics are averaged for.
     * If the average value at the end of the interval is higher than the `cpuUtilizationTarget`,
     * the instance group will increase the number of virtual machines in the group.
     */
    measurementDuration: number;
    /**
     * The minimum number of virtual machines in a single availability zone.
     */
    minZoneSize: number;
    /**
     * The minimum time interval, in seconds, to monitor the load before
     * an instance group can reduce the number of virtual machines in the group. During this time, the group
     * will not decrease even if the average load falls below the value of `cpuUtilizationTarget`.
     */
    stabilizationDuration: number;
    /**
     * The warm-up time of the virtual machine, in seconds. During this time,
     * traffic is fed to the virtual machine, but load metrics are not taken into account.
     */
    warmupDuration: number;
}

export interface GetComputeInstanceGroupScalePolicyAutoScaleCustomRule {
    /**
     * Folder ID of custom metric in Yandex Monitoring that should be used for scaling.
     */
    folderId: string;
    /**
     * A map of labels applied to this instance.
     * * `resources.0.memory` - The memory size allocated to the instance.
     * * `resources.0.cores` - Number of CPU cores allocated to the instance.
     * * `resources.0.core_fraction` - Baseline core performance as a percent.
     * * `resources.0.gpus` - Number of GPU cores allocated to the instance.
     */
    labels: {[key: string]: string};
    /**
     * The name of metric.
     */
    metricName: string;
    /**
     * Metric type, `GAUGE` or `COUNTER`.
     */
    metricType: string;
    /**
     * Rule type: `UTILIZATION` - This type means that the metric applies to one instance.
     * First, Instance Groups calculates the average metric value for each instance,
     * then averages the values for instances in one availability zone.
     * This type of metric must have the `instanceId` label. `WORKLOAD` - This type means that the metric applies to instances in one availability zone.
     * This type of metric must have the `zoneId` label.
     */
    ruleType: string;
    /**
     * Service of custom metric in Yandex Monitoring that should be used for scaling.
     */
    service: string;
    /**
     * Target metric value level.
     */
    target: number;
}

export interface GetComputeInstanceGroupScalePolicyFixedScale {
    /**
     * The size of the disk in GB.
     */
    size: number;
}

export interface GetComputeInstanceGroupScalePolicyTestAutoScale {
    /**
     * Target CPU load level.
     */
    cpuUtilizationTarget: number;
    /**
     * A list of custom rules. The structure is documented below.
     */
    customRules: outputs.GetComputeInstanceGroupScalePolicyTestAutoScaleCustomRule[];
    /**
     * The initial number of instances in the instance group.
     */
    initialSize: number;
    /**
     * The maximum number of virtual machines in the group.
     */
    maxSize: number;
    /**
     * The amount of time, in seconds, that metrics are averaged for.
     * If the average value at the end of the interval is higher than the `cpuUtilizationTarget`,
     * the instance group will increase the number of virtual machines in the group.
     */
    measurementDuration: number;
    /**
     * The minimum number of virtual machines in a single availability zone.
     */
    minZoneSize: number;
    /**
     * The minimum time interval, in seconds, to monitor the load before
     * an instance group can reduce the number of virtual machines in the group. During this time, the group
     * will not decrease even if the average load falls below the value of `cpuUtilizationTarget`.
     */
    stabilizationDuration: number;
    /**
     * The warm-up time of the virtual machine, in seconds. During this time,
     * traffic is fed to the virtual machine, but load metrics are not taken into account.
     */
    warmupDuration: number;
}

export interface GetComputeInstanceGroupScalePolicyTestAutoScaleCustomRule {
    /**
     * Folder ID of custom metric in Yandex Monitoring that should be used for scaling.
     */
    folderId: string;
    /**
     * A map of labels applied to this instance.
     * * `resources.0.memory` - The memory size allocated to the instance.
     * * `resources.0.cores` - Number of CPU cores allocated to the instance.
     * * `resources.0.core_fraction` - Baseline core performance as a percent.
     * * `resources.0.gpus` - Number of GPU cores allocated to the instance.
     */
    labels: {[key: string]: string};
    /**
     * The name of metric.
     */
    metricName: string;
    /**
     * Metric type, `GAUGE` or `COUNTER`.
     */
    metricType: string;
    /**
     * Rule type: `UTILIZATION` - This type means that the metric applies to one instance.
     * First, Instance Groups calculates the average metric value for each instance,
     * then averages the values for instances in one availability zone.
     * This type of metric must have the `instanceId` label. `WORKLOAD` - This type means that the metric applies to instances in one availability zone.
     * This type of metric must have the `zoneId` label.
     */
    ruleType: string;
    /**
     * Service of custom metric in Yandex Monitoring that should be used for scaling.
     */
    service: string;
    /**
     * Target metric value level.
     */
    target: number;
}

export interface GetComputeInstanceLocalDisk {
    /**
     * Name of the device.
     */
    deviceName: string;
    /**
     * Size of the disk, specified in bytes.
     */
    sizeBytes: number;
}

export interface GetComputeInstanceMetadataOptions {
    awsV1HttpEndpoint: number;
    awsV1HttpToken: number;
    gceHttpEndpoint: number;
    gceHttpToken: number;
}

export interface GetComputeInstanceNetworkInterface {
    /**
     * List of configurations for creating ipv4 DNS records. The structure is documented below.
     */
    dnsRecords: outputs.GetComputeInstanceNetworkInterfaceDnsRecord[];
    /**
     * The index of the network interface, generated by the server.
     */
    index: number;
    /**
     * The assignd private IP address to the network interface.
     */
    ipAddress: string;
    /**
     * Show if IPv4 address is assigned to the network interface.
     */
    ipv4: boolean;
    ipv6: boolean;
    ipv6Address: string;
    /**
     * List of configurations for creating ipv6 DNS records. The structure is documented below.
     */
    ipv6DnsRecords: outputs.GetComputeInstanceNetworkInterfaceIpv6DnsRecord[];
    /**
     * MAC address that is assigned to the network interface.
     */
    macAddress: string;
    /**
     * Assigned for the instance's public address that is used to access the internet over NAT.
     */
    nat: boolean;
    /**
     * List of configurations for creating ipv4 NAT DNS records. The structure is documented below.
     */
    natDnsRecords: outputs.GetComputeInstanceNetworkInterfaceNatDnsRecord[];
    /**
     * Public IP address of the instance.
     */
    natIpAddress: string;
    /**
     * IP version for the public address.
     */
    natIpVersion: string;
    /**
     * Security group ids for network interface.
     */
    securityGroupIds: string[];
    /**
     * ID of the subnet to attach this interface to. The subnet must reside in the same zone where this instance was created.
     */
    subnetId: string;
}

export interface GetComputeInstanceNetworkInterfaceDnsRecord {
    /**
     * DNS zone ID (if not set, private zone is used).
     */
    dnsZoneId: string;
    /**
     * DNS record FQDN.
     */
    fqdn: string;
    /**
     * When set to true, also create a TR DNS record.
     */
    ptr: boolean;
    /**
     * DNS record TTL. in seconds
     */
    ttl: number;
}

export interface GetComputeInstanceNetworkInterfaceIpv6DnsRecord {
    /**
     * DNS zone ID (if not set, private zone is used).
     */
    dnsZoneId: string;
    /**
     * DNS record FQDN.
     */
    fqdn: string;
    /**
     * When set to true, also create a TR DNS record.
     */
    ptr: boolean;
    /**
     * DNS record TTL. in seconds
     */
    ttl: number;
}

export interface GetComputeInstanceNetworkInterfaceNatDnsRecord {
    /**
     * DNS zone ID (if not set, private zone is used).
     */
    dnsZoneId: string;
    /**
     * DNS record FQDN.
     */
    fqdn: string;
    /**
     * When set to true, also create a TR DNS record.
     */
    ptr: boolean;
    /**
     * DNS record TTL. in seconds
     */
    ttl: number;
}

export interface GetComputeInstancePlacementPolicy {
    /**
     * List of host affinity rules. The structure is documented below.
     */
    hostAffinityRules: outputs.GetComputeInstancePlacementPolicyHostAffinityRule[];
    /**
     * Specifies the id of the Placement Group to assign to the instance.
     */
    placementGroupId?: string;
}

export interface GetComputeInstancePlacementPolicyHostAffinityRule {
    /**
     * Affinity label or one of reserved values - `yc.hostId`, `yc.hostGroupId`.
     */
    key: string;
    /**
     * Affinity action. The only value supported is `IN`.
     */
    op: string;
    values: string[];
}

export interface GetComputeInstanceResource {
    coreFraction: number;
    cores: number;
    gpus: number;
    memory: number;
}

export interface GetComputeInstanceSchedulingPolicy {
    /**
     * (Optional) Specifies if the instance is preemptible. Defaults to false.
     */
    preemptible?: boolean;
}

export interface GetComputeInstanceSecondaryDisk {
    /**
     * Specifies whether the disk is auto-deleted when the instance is deleted.
     */
    autoDelete: boolean;
    /**
     * Name of the device.
     */
    deviceName: string;
    /**
     * ID of the disk that is attached to the instance.
     */
    diskId: string;
    /**
     * Access to the Disk resource. By default, a disk is attached in `READ_WRITE` mode.
     */
    mode: string;
}

export interface GetComputeSnapshotScheduleSchedulePolicy {
    expression: string;
    startAt: string;
}

export interface GetComputeSnapshotScheduleSnapshotSpec {
    /**
     * An optional description of this snapshot schedule.
     */
    description: string;
    /**
     * A map of labels applied to this snapshot schedule.
     */
    labels: {[key: string]: string};
}

export interface GetContainerRepositoryLifecyclePolicyRule {
    /**
     * Description of the lifecycle policy.
     */
    description: string;
    /**
     * The period of time that must pass after creating a image for it to suit the automatic deletion criteria. It must be a multiple of 24 hours.
     */
    expirePeriod: string;
    /**
     * The number of images to be retained even if the expirePeriod already expired.
     */
    retainedTop: number;
    /**
     * Tag to specify a filter as a regular expression. For example `.*` - all images with tags.
     */
    tagRegexp: string;
    /**
     * If enabled, rules apply to untagged Docker images.
     */
    untagged: boolean;
}

export interface GetDataprocClusterClusterConfig {
    /**
     * Data Proc specific options. The structure is documented below.
     */
    hadoops: outputs.GetDataprocClusterClusterConfigHadoop[];
    /**
     * Configuration of the Data Proc subcluster. The structure is documented below.
     */
    subclusterSpecs: outputs.GetDataprocClusterClusterConfigSubclusterSpec[];
    /**
     * Version of Data Proc image.
     */
    versionId: string;
}

export interface GetDataprocClusterClusterConfigHadoop {
    /**
     * A set of key/value pairs used to configure cluster services.
     */
    properties: {[key: string]: string};
    /**
     * List of services launched on Data Proc cluster.
     */
    services: string[];
    /**
     * List of SSH public keys distributed to the hosts of the cluster.
     */
    sshPublicKeys: string[];
}

export interface GetDataprocClusterClusterConfigSubclusterSpec {
    /**
     * The hosts of the subclusters have public IP addresses.
     */
    assignPublicIp: boolean;
    /**
     * Optional autoscaling configuration for compute subclusters.
     */
    autoscalingConfigs: outputs.GetDataprocClusterClusterConfigSubclusterSpecAutoscalingConfig[];
    /**
     * Number of hosts within Data Proc subcluster.
     */
    hostsCount: number;
    /**
     * ID of the Data Proc subcluster.
     */
    id: string;
    /**
     * The name of the Data Proc cluster.
     */
    name: string;
    /**
     * Resources allocated to each host of the Data Proc subcluster. The structure is documented below.
     */
    resources: outputs.GetDataprocClusterClusterConfigSubclusterSpecResource[];
    /**
     * Role of the subcluster in the Data Proc cluster.
     */
    role: string;
    /**
     * The ID of the subnet, to which hosts of the subcluster belong.
     */
    subnetId: string;
}

export interface GetDataprocClusterClusterConfigSubclusterSpecAutoscalingConfig {
    /**
     * Defines an autoscaling rule based on the average CPU utilization of the instance group. If not set default autoscaling metric will be used.
     */
    cpuUtilizationTarget: number;
    /**
     * Timeout to gracefully decommission nodes during downscaling. In seconds.
     */
    decommissionTimeout: number;
    /**
     * Maximum number of nodes in autoscaling subclusters.
     */
    maxHostsCount: number;
    /**
     * Time in seconds allotted for averaging metrics.
     */
    measurementDuration: number;
    /**
     * Bool flag -- whether to use preemptible compute instances. Preemptible instances are stopped at least once every 24 hours, and can be stopped at any time if their resources are needed by Compute. For more information, see [Preemptible Virtual Machines](https://cloud.yandex.com/docs/compute/concepts/preemptible-vm).
     */
    preemptible: boolean;
    /**
     * Minimum amount of time in seconds allotted for monitoring before Instance Groups can reduce the number of instances in the group. During this time, the group size doesn't decrease, even if the new metric values indicate that it should.
     */
    stabilizationDuration: number;
    /**
     * The warmup time of the instance in seconds. During this time, traffic is sent to the instance, but instance metrics are not collected.
     */
    warmupDuration: number;
}

export interface GetDataprocClusterClusterConfigSubclusterSpecResource {
    /**
     * Volume of the storage available to a host, in gigabytes.
     */
    diskSize: number;
    /**
     * Type of the storage of a host.
     */
    diskTypeId: string;
    /**
     * The ID of the preset for computational resources available to a host. All available presets are listed in the [documentation](https://cloud.yandex.com/docs/data-proc/concepts/instance-types).
     */
    resourcePresetId: string;
}

export interface GetFunctionConnectivity {
    networkId: string;
}

export interface GetFunctionScalingPolicyPolicy {
    tag: string;
    zoneInstancesLimit?: number;
    zoneRequestsLimit?: number;
}

export interface GetFunctionSecret {
    environmentVariable: string;
    id: string;
    key: string;
    versionId: string;
}

export interface GetFunctionTriggerContainer {
    id: string;
    path: string;
    retryAttempts: string;
    retryInterval: string;
    serviceAccountId: string;
}

export interface GetFunctionTriggerDlq {
    queueId: string;
    serviceAccountId: string;
}

export interface GetFunctionTriggerFunction {
    id: string;
    retryAttempts: string;
    retryInterval: string;
    serviceAccountId: string;
    tag: string;
}

export interface GetFunctionTriggerIot {
    batchCutoff: string;
    batchSize: string;
    deviceId: string;
    registryId: string;
    topic: string;
}

export interface GetFunctionTriggerLogGroup {
    batchCutoff: string;
    batchSize: string;
    logGroupIds: string[];
}

export interface GetFunctionTriggerLogging {
    batchCutoff: string;
    batchSize: string;
    groupId: string;
    levels: string[];
    resourceIds: string[];
    resourceTypes: string[];
    streamNames: string[];
}

export interface GetFunctionTriggerMessageQueue {
    batchCutoff: string;
    batchSize: string;
    queueId: string;
    serviceAccountId: string;
    visibilityTimeout: string;
}

export interface GetFunctionTriggerObjectStorage {
    batchCutoff: string;
    batchSize: string;
    bucketId: string;
    create: boolean;
    delete: boolean;
    prefix: string;
    suffix: string;
    update: boolean;
}

export interface GetFunctionTriggerTimer {
    cronExpression: string;
    payload: string;
}

export interface GetIamPolicyBinding {
    /**
     * An array of identities that will be granted the privilege in the `role`.
     * Each entry can have one of the following values:
     * * **userAccount:{user_id}**: A unique user ID that represents a specific Yandex account.
     * * **serviceAccount:{service_account_id}**: A unique service account ID.
     * * **federatedUser:{federated_user_id}:**: A unique saml federation user account ID.
     * * **group:{group_id}**: A unique group ID.
     */
    members: string[];
    /**
     * The role/permission that will be granted to the members.
     * See the [IAM Roles] documentation for a complete list of roles.
     */
    role: string;
}

export interface GetKubernetesClusterKmsProvider {
    /**
     * KMS key ID.
     */
    keyId: string;
}

export interface GetKubernetesClusterMaster {
    /**
     * PEM-encoded public certificate that is the root of trust for the Kubernetes cluster.
     */
    clusterCaCertificate: string;
    /**
     * An IPv4 external network address that is assigned to the master.
     */
    externalV4Address: string;
    /**
     * External endpoint that can be used to access Kubernetes cluster API from the internet (outside of the cloud).
     */
    externalV4Endpoint: string;
    externalV6Address: string;
    externalV6Endpoint: string;
    /**
     * An IPv4 internal network address that is assigned to the master.
     */
    internalV4Address: string;
    /**
     * Internal endpoint that can be used to connect to the master from cloud networks.
     */
    internalV4Endpoint: string;
    /**
     * Maintenance policy for Kubernetes master. The structure is documented below.
     */
    maintenancePolicies: outputs.GetKubernetesClusterMasterMaintenancePolicy[];
    /**
     * (Optional) Master Logging options. The structure is documented below.
     */
    masterLoggings: outputs.GetKubernetesClusterMasterMasterLogging[];
    /**
     * Boolean flag. When `true`, Kubernetes master have visible ipv4 address.
     */
    publicIp: boolean;
    /**
     * Information about cluster regional master. The structure is documented below.
     */
    regionals: outputs.GetKubernetesClusterMasterRegional[];
    /**
     * A list of security groups IDs of the Kubernetes cluster.
     */
    securityGroupIds: string[];
    /**
     * Version of Kubernetes master.
     */
    version: string;
    /**
     * Information about cluster version. The structure is documented below.
     */
    versionInfos: outputs.GetKubernetesClusterMasterVersionInfo[];
    /**
     * Information about cluster zonal master. The structure is documented below.
     */
    zonals: outputs.GetKubernetesClusterMasterZonal[];
}

export interface GetKubernetesClusterMasterMaintenancePolicy {
    /**
     * Boolean flag that specifies if master can be upgraded automatically.
     */
    autoUpgrade: boolean;
    /**
     * Set of day intervals, when maintenance is allowed, when update for master is allowed.
     * When omitted, it defaults to any time.
     */
    maintenanceWindows: outputs.GetKubernetesClusterMasterMaintenancePolicyMaintenanceWindow[];
}

export interface GetKubernetesClusterMasterMaintenancePolicyMaintenanceWindow {
    day: string;
    duration: string;
    startTime: string;
}

export interface GetKubernetesClusterMasterMasterLogging {
    /**
     * (Optional) Boolean flag that specifies if kube-apiserver audit logs should be sent to Yandex Cloud Logging.
     */
    auditEnabled: boolean;
    /**
     * (Optional) Boolean flag that specifies if cluster-autoscaler logs should be sent to Yandex Cloud Logging.
     */
    clusterAutoscalerEnabled: boolean;
    /**
     * (Optional) Boolean flag that specifies if master components logs should be sent to [Yandex Cloud Logging](https://cloud.yandex.com/docs/logging/). The exact components that will send their logs must be configured via the options described below.
     */
    enabled: boolean;
    /**
     * (Optional) Boolean flag that specifies if kubernetes cluster events should be sent to Yandex Cloud Logging.
     */
    eventsEnabled: boolean;
    /**
     * Folder that the resource belongs to. If value is omitted, the default provider folder is used.
     */
    folderId: string;
    /**
     * (Optional) Boolean flag that specifies if kube-apiserver logs should be sent to Yandex Cloud Logging.
     */
    kubeApiserverEnabled: boolean;
    /**
     * (Optional) ID of the Yandex Cloud Logging [Log group](https://cloud.yandex.com/docs/logging/concepts/log-group).
     */
    logGroupId: string;
}

export interface GetKubernetesClusterMasterRegional {
    /**
     * ID of the availability region where the master compute instances resides.
     */
    region: string;
}

export interface GetKubernetesClusterMasterVersionInfo {
    /**
     * Current Kubernetes version, major.minor (e.g. 1.15).
     */
    currentVersion: string;
    /**
     * True/false flag.
     * Newer revisions may include Kubernetes patches (e.g 1.15.1 > 1.15.2) as well
     * as some internal component updates - new features or bug fixes in yandex-specific
     * components either on the master or nodes.
     */
    newRevisionAvailable: boolean;
    /**
     * Human readable description of the changes to be applied
     * when updating to the latest revision. Empty if newRevisionAvailable is false.
     */
    newRevisionSummary: string;
    /**
     * True/false flag. The current version is on the deprecation schedule,
     * component (master or node group) should be upgraded.
     */
    versionDeprecated: boolean;
}

export interface GetKubernetesClusterMasterZonal {
    /**
     * ID of the availability zone where the master compute instance resides.
     */
    zone: string;
}

export interface GetKubernetesClusterNetworkImplementation {
    /**
     * Cilium network implementation configuration. No options exist.
     */
    cilias: outputs.GetKubernetesClusterNetworkImplementationCilia[];
}

export interface GetKubernetesClusterNetworkImplementationCilia {
    routingMode: string;
}

export interface GetKubernetesNodeGroupAllocationPolicy {
    /**
     * Repeated field, that specify subnets (zones), that will be used by node group compute instances. The structure is documented below.
     */
    locations: outputs.GetKubernetesNodeGroupAllocationPolicyLocation[];
}

export interface GetKubernetesNodeGroupAllocationPolicyLocation {
    /**
     * ID of the subnet, that will be used by one compute instance in node group.
     */
    subnetId: string;
    /**
     * ID of the availability zone where for one compute instance in node group.
     */
    zone: string;
}

export interface GetKubernetesNodeGroupDeployPolicy {
    /**
     * The maximum number of instances that can be temporarily allocated above the group's target size during the update.
     */
    maxExpansion: number;
    /**
     * The maximum number of running instances that can be taken offline during update.
     */
    maxUnavailable: number;
}

export interface GetKubernetesNodeGroupInstanceTemplate {
    /**
     * The specifications for boot disks that will be attached to the instance. The structure is documented below.
     */
    bootDisks: outputs.GetKubernetesNodeGroupInstanceTemplateBootDisk[];
    /**
     * Container network configuration. The structure is documented below.
     */
    containerNetworks: outputs.GetKubernetesNodeGroupInstanceTemplateContainerNetwork[];
    /**
     * Container runtime configuration. The structure is documented below.
     */
    containerRuntime: outputs.GetKubernetesNodeGroupInstanceTemplateContainerRuntime;
    /**
     * GPU settings. The structure is documented below.
     * ---
     */
    gpuSettings: outputs.GetKubernetesNodeGroupInstanceTemplateGpuSetting[];
    /**
     * Labels assigned to compute nodes (instances), created by the Node Group.
     */
    labels: {[key: string]: string};
    /**
     * The set of metadata `key:value` pairs assigned to this instance template. This includes custom metadata and predefined keys.
     */
    metadata: {[key: string]: string};
    /**
     * Name of a specific Kubernetes node group.
     */
    name: string;
    /**
     * A public address that can be used to access the internet over NAT.
     */
    nat: boolean;
    /**
     * Type of network acceleration. Values: `standard`, `softwareAccelerated`.
     */
    networkAccelerationType: string;
    /**
     * An array with the network interfaces that will be attached to the instance. The structure is documented below.
     */
    networkInterfaces: outputs.GetKubernetesNodeGroupInstanceTemplateNetworkInterface[];
    /**
     * (Optional) The placement policy configuration. The structure is documented below.
     */
    placementPolicies?: outputs.GetKubernetesNodeGroupInstanceTemplatePlacementPolicy[];
    /**
     * The ID of the hardware platform configuration for the instance.
     */
    platformId: string;
    resources: outputs.GetKubernetesNodeGroupInstanceTemplateResource[];
    /**
     * The scheduling policy for the instances in node group. The structure is documented below.
     */
    schedulingPolicies: outputs.GetKubernetesNodeGroupInstanceTemplateSchedulingPolicy[];
}

export interface GetKubernetesNodeGroupInstanceTemplateBootDisk {
    /**
     * The number of instances in the node group.
     */
    size: number;
    /**
     * Type of container runtime. Values: `docker`, `containerd`.
     */
    type: string;
}

export interface GetKubernetesNodeGroupInstanceTemplateContainerNetwork {
    /**
     * MTU for pods.
     */
    podMtu: number;
}

export interface GetKubernetesNodeGroupInstanceTemplateContainerRuntime {
    /**
     * Type of container runtime. Values: `docker`, `containerd`.
     */
    type: string;
}

export interface GetKubernetesNodeGroupInstanceTemplateGpuSetting {
    /**
     * GPU cluster id.
     */
    gpuClusterId: string;
    /**
     * GPU environment. Values: `runc`, `runcDriversCuda`.
     */
    gpuEnvironment: string;
}

export interface GetKubernetesNodeGroupInstanceTemplateNetworkInterface {
    /**
     * Indicates whether the IPv4 address has been assigned.
     */
    ipv4: boolean;
    /**
     * List of configurations for creating ipv4 DNS records. The structure is documented below.
     */
    ipv4DnsRecords: outputs.GetKubernetesNodeGroupInstanceTemplateNetworkInterfaceIpv4DnsRecord[];
    /**
     * Indicates whether the IPv6 address has been assigned.
     */
    ipv6: boolean;
    /**
     * List of configurations for creating ipv6 DNS records. The structure is documented below.
     */
    ipv6DnsRecords: outputs.GetKubernetesNodeGroupInstanceTemplateNetworkInterfaceIpv6DnsRecord[];
    /**
     * A public address that can be used to access the internet over NAT.
     */
    nat: boolean;
    /**
     * Security group ids for network interface.
     */
    securityGroupIds: string[];
    /**
     * The IDs of the subnets.
     */
    subnetIds: string[];
}

export interface GetKubernetesNodeGroupInstanceTemplateNetworkInterfaceIpv4DnsRecord {
    /**
     * DNS zone ID (if not set, private zone is used).
     */
    dnsZoneId: string;
    /**
     * DNS record FQDN.
     */
    fqdn: string;
    /**
     * When set to true, also create a PTR DNS record.
     */
    ptr: boolean;
    /**
     * DNS record TTL (in seconds).
     */
    ttl: number;
}

export interface GetKubernetesNodeGroupInstanceTemplateNetworkInterfaceIpv6DnsRecord {
    /**
     * DNS zone ID (if not set, private zone is used).
     */
    dnsZoneId: string;
    /**
     * DNS record FQDN.
     */
    fqdn: string;
    /**
     * When set to true, also create a PTR DNS record.
     */
    ptr: boolean;
    /**
     * DNS record TTL (in seconds).
     */
    ttl: number;
}

export interface GetKubernetesNodeGroupInstanceTemplatePlacementPolicy {
    /**
     * (Optional) Specifies the id of the Placement Group to assign to the instances.
     */
    placementGroupId: string;
}

export interface GetKubernetesNodeGroupInstanceTemplateResource {
    coreFraction: number;
    cores: number;
    gpus: number;
    memory: number;
}

export interface GetKubernetesNodeGroupInstanceTemplateSchedulingPolicy {
    /**
     * Specifies if the instance is preemptible. Defaults to false.
     * ---
     */
    preemptible: boolean;
}

export interface GetKubernetesNodeGroupMaintenancePolicy {
    /**
     * Boolean flag.
     */
    autoRepair: boolean;
    /**
     * Boolean flag.
     */
    autoUpgrade: boolean;
    /**
     * Set of day intervals, when maintenance is allowed for this node group.
     * When omitted, it defaults to any time.
     */
    maintenanceWindows: outputs.GetKubernetesNodeGroupMaintenancePolicyMaintenanceWindow[];
}

export interface GetKubernetesNodeGroupMaintenancePolicyMaintenanceWindow {
    day: string;
    duration: string;
    startTime: string;
}

export interface GetKubernetesNodeGroupScalePolicy {
    /**
     * Scale policy for an autoscaled node group. The structure is documented below.
     */
    autoScales: outputs.GetKubernetesNodeGroupScalePolicyAutoScale[];
    /**
     * Scale policy for a fixed scale node group. The structure is documented below.
     */
    fixedScales: outputs.GetKubernetesNodeGroupScalePolicyFixedScale[];
}

export interface GetKubernetesNodeGroupScalePolicyAutoScale {
    /**
     * Initial number of instances in the node group.
     */
    initial: number;
    /**
     * Maximum number of instances in the node group.
     */
    max: number;
    /**
     * Minimum number of instances in the node group.
     */
    min: number;
}

export interface GetKubernetesNodeGroupScalePolicyFixedScale {
    /**
     * The number of instances in the node group.
     */
    size: number;
}

export interface GetKubernetesNodeGroupVersionInfo {
    /**
     * Current Kubernetes version, major.minor (e.g. 1.15).
     */
    currentVersion: string;
    /**
     * True/false flag.
     * Newer revisions may include Kubernetes patches (e.g 1.15.1 > 1.15.2) as well
     * as some internal component updates - new features or bug fixes in yandex-specific
     * components either on the master or nodes.
     */
    newRevisionAvailable: boolean;
    /**
     * Human readable description of the changes to be applied
     * when updating to the latest revision. Empty if newRevisionAvailable is false.
     */
    newRevisionSummary: string;
    /**
     * True/false flag. The current version is on the deprecation schedule,
     * component (master or node group) should be upgraded.
     */
    versionDeprecated: boolean;
}

export interface GetLbNetworkLoadBalancerAttachedTargetGroup {
    healthchecks: outputs.GetLbNetworkLoadBalancerAttachedTargetGroupHealthcheck[];
    /**
     * ID of the target group that attached to the network load balancer.
     * * `healthcheck.0.name` - Name of the health check.
     * * `healthcheck.0.interval` - The interval between health checks.
     * * `healthcheck.0.timeout` - Timeout for a target to return a response for the health check.
     * * `healthcheck.0.unhealthy_threshold` - Number of failed health checks before changing the status to `UNHEALTHY`.
     * * `healthcheck.0.healthy_threshold` - Number of successful health checks required in order to set the `HEALTHY` status for the target.
     * * `healthcheck.0.tcp_options.0.port` - Port to use for TCP health checks.
     * * `healthcheck.0.http_options.0.port` - Port to use for HTTP health checks.
     * * `healthcheck.0.http_options.0.path` - URL path to use for HTTP health checks.
     */
    targetGroupId: string;
}

export interface GetLbNetworkLoadBalancerAttachedTargetGroupHealthcheck {
    healthyThreshold: number;
    httpOptions: outputs.GetLbNetworkLoadBalancerAttachedTargetGroupHealthcheckHttpOption[];
    interval: number;
    /**
     * - Name of the network load balancer.
     */
    name: string;
    tcpOptions: outputs.GetLbNetworkLoadBalancerAttachedTargetGroupHealthcheckTcpOption[];
    timeout: number;
    unhealthyThreshold: number;
}

export interface GetLbNetworkLoadBalancerAttachedTargetGroupHealthcheckHttpOption {
    path: string;
    /**
     * Port for incoming traffic.
     */
    port: number;
}

export interface GetLbNetworkLoadBalancerAttachedTargetGroupHealthcheckTcpOption {
    /**
     * Port for incoming traffic.
     */
    port: number;
}

export interface GetLbNetworkLoadBalancerListener {
    externalAddressSpecs: outputs.GetLbNetworkLoadBalancerListenerExternalAddressSpec[];
    internalAddressSpecs: outputs.GetLbNetworkLoadBalancerListenerInternalAddressSpec[];
    /**
     * - Name of the network load balancer.
     */
    name: string;
    /**
     * Port for incoming traffic.
     */
    port: number;
    /**
     * Protocol for incoming traffic.
     */
    protocol: string;
    /**
     * Port of a target. 
     * * `external_address_spec.0.address` - External IP address of a listener.
     * * `external_address_spec.0.ip_version` - IP version of the external addresses.
     * * `internal_address_spec.0.subnet_id` - Subnet ID to which the internal IP address belongs
     * * `internal_address_spec.0.address` - Internal IP address of a listener.
     * * `internal_address_spec.0.ip_version` - IP version of the internal addresses.
     */
    targetPort: number;
}

export interface GetLbNetworkLoadBalancerListenerExternalAddressSpec {
    address: string;
    ipVersion: string;
}

export interface GetLbNetworkLoadBalancerListenerInternalAddressSpec {
    address: string;
    ipVersion: string;
    subnetId: string;
}

export interface GetLbTargetGroupTarget {
    address: string;
    subnetId: string;
}

export interface GetLockBoxSecretCurrentVersion {
    /**
     * The version creation timestamp.
     */
    createdAt: string;
    /**
     * The version description.
     */
    description: string;
    /**
     * The version destroy timestamp.
     */
    destroyAt: string;
    /**
     * The version ID.
     */
    id: string;
    /**
     * List of keys that the version contains (doesn't include the values).
     */
    payloadEntryKeys: string[];
    /**
     * The Yandex Cloud Lockbox secret ID.
     */
    secretId: string;
    /**
     * The version status.
     */
    status: string;
}

export interface GetLockBoxSecretVersionEntry {
    /**
     * The key of the entry.
     */
    key: string;
    /**
     * The text value of the entry.
     */
    textValue: string;
}

export interface GetMdbClickhouseClusterAccess {
    /**
     * Allow access for Web SQL.
     */
    dataLens?: boolean;
    /**
     * Allow access for DataTransfer
     */
    dataTransfer?: boolean;
    /**
     * Allow access for Yandex.Metrika.
     */
    metrika?: boolean;
    /**
     * Allow access for Serverless.
     */
    serverless?: boolean;
    /**
     * Allow access for DataLens.
     */
    webSql?: boolean;
    /**
     * Allow access for YandexQuery
     */
    yandexQuery?: boolean;
}

export interface GetMdbClickhouseClusterBackupWindowStart {
    /**
     * The hour at which backup will be started.
     */
    hours?: number;
    /**
     * The minute at which backup will be started.
     */
    minutes?: number;
}

export interface GetMdbClickhouseClusterClickhouse {
    /**
     * Main ClickHouse cluster configuration. The structure is documented below.
     */
    config: outputs.GetMdbClickhouseClusterClickhouseConfig;
    /**
     * Resources allocated to hosts of the shard. The resources specified for the shard takes precedence over the resources specified for the cluster. The structure is documented below.
     */
    resources: outputs.GetMdbClickhouseClusterClickhouseResources;
}

export interface GetMdbClickhouseClusterClickhouseConfig {
    backgroundFetchesPoolSize: number;
    backgroundMessageBrokerSchedulePoolSize: number;
    backgroundPoolSize: number;
    backgroundSchedulePoolSize: number;
    /**
     * Data compression configuration. The structure is documented below.
     */
    compressions?: outputs.GetMdbClickhouseClusterClickhouseConfigCompression[];
    defaultDatabase: string;
    geobaseUri: string;
    /**
     * Graphite rollup configuration. The structure is documented below.
     */
    graphiteRollups?: outputs.GetMdbClickhouseClusterClickhouseConfigGraphiteRollup[];
    /**
     * Kafka connection configuration. The structure is documented below.
     */
    kafka: outputs.GetMdbClickhouseClusterClickhouseConfigKafka;
    /**
     * Kafka topic connection configuration. The structure is documented below.
     */
    kafkaTopics?: outputs.GetMdbClickhouseClusterClickhouseConfigKafkaTopic[];
    keepAliveTimeout: number;
    logLevel: string;
    markCacheSize: number;
    maxConcurrentQueries: number;
    maxConnections: number;
    maxPartitionSizeToDrop: number;
    maxTableSizeToDrop: number;
    /**
     * MergeTree engine configuration. The structure is documented below.
     */
    mergeTree: outputs.GetMdbClickhouseClusterClickhouseConfigMergeTree;
    metricLogEnabled: boolean;
    metricLogRetentionSize: number;
    metricLogRetentionTime: number;
    partLogRetentionSize: number;
    partLogRetentionTime: number;
    queryLogRetentionSize: number;
    queryLogRetentionTime: number;
    queryThreadLogEnabled: boolean;
    queryThreadLogRetentionSize: number;
    queryThreadLogRetentionTime: number;
    /**
     * RabbitMQ connection configuration. The structure is documented below.
     */
    rabbitmq: outputs.GetMdbClickhouseClusterClickhouseConfigRabbitmq;
    textLogEnabled: boolean;
    textLogLevel: string;
    textLogRetentionSize: number;
    textLogRetentionTime: number;
    timezone: string;
    totalMemoryProfilerStep: number;
    traceLogEnabled: boolean;
    traceLogRetentionSize: number;
    traceLogRetentionTime: number;
    uncompressedCacheSize: number;
}

export interface GetMdbClickhouseClusterClickhouseConfigCompression {
    /**
     * Method: Compression method. Two methods are available: LZ4 and zstd.
     */
    method?: string;
    /**
     * Min part size: Minimum size (in bytes) of a data part in a table. ClickHouse only applies the rule to tables with data parts greater than or equal to the Min part size value.
     */
    minPartSize?: number;
    /**
     * Min part size ratio: Minimum table part size to total table size ratio. ClickHouse only applies the rule to tables in which this ratio is greater than or equal to the Min part size ratio value.
     */
    minPartSizeRatio?: number;
}

export interface GetMdbClickhouseClusterClickhouseConfigGraphiteRollup {
    /**
     * The name of the ClickHouse cluster.
     */
    name?: string;
    /**
     * Set of thinning rules.
     */
    patterns?: outputs.GetMdbClickhouseClusterClickhouseConfigGraphiteRollupPattern[];
}

export interface GetMdbClickhouseClusterClickhouseConfigGraphiteRollupPattern {
    /**
     * Aggregation function name.
     */
    function?: string;
    /**
     * Regular expression that the metric name must match.
     */
    regexp: string;
    /**
     * Retain parameters.
     */
    retentions?: outputs.GetMdbClickhouseClusterClickhouseConfigGraphiteRollupPatternRetention[];
}

export interface GetMdbClickhouseClusterClickhouseConfigGraphiteRollupPatternRetention {
    /**
     * Minimum data age in seconds.
     */
    age?: number;
    /**
     * Accuracy of determining the age of the data in seconds.
     */
    precision?: number;
}

export interface GetMdbClickhouseClusterClickhouseConfigKafka {
    /**
     * SASL mechanism used in kafka authentication.
     */
    saslMechanism: string;
    /**
     * User password on kafka server.
     */
    saslPassword: string;
    /**
     * Username on kafka server.
     */
    saslUsername: string;
    /**
     * Security protocol used to connect to kafka server.
     */
    securityProtocol: string;
}

export interface GetMdbClickhouseClusterClickhouseConfigKafkaTopic {
    /**
     * The name of the ClickHouse cluster.
     */
    name?: string;
    /**
     * Kafka connection settngs sanem as `kafka` block.
     */
    settings?: outputs.GetMdbClickhouseClusterClickhouseConfigKafkaTopicSettings;
}

export interface GetMdbClickhouseClusterClickhouseConfigKafkaTopicSettings {
    /**
     * SASL mechanism used in kafka authentication.
     */
    saslMechanism?: string;
    /**
     * User password on kafka server.
     */
    saslPassword?: string;
    /**
     * Username on kafka server.
     */
    saslUsername?: string;
    /**
     * Security protocol used to connect to kafka server.
     */
    securityProtocol?: string;
}

export interface GetMdbClickhouseClusterClickhouseConfigMergeTree {
    /**
     * (Optional) Minimum period to clean old queue logs, blocks hashes and parts.
     */
    cleanupDelayPeriod: number;
    /**
     * Max bytes to merge at min space in pool: Maximum total size of a data part to merge when the number of free threads in the background pool is minimum.
     */
    maxBytesToMergeAtMinSpaceInPool: number;
    /**
     * (Optional) When there is more than specified number of merges with TTL entries in pool, do not assign new merge with TTL.
     */
    maxNumberOfMergesWithTtlInPool: number;
    /**
     * (Optional) Maximum number of parts in all partitions.
     */
    maxPartsInTotal: number;
    /**
     * Max replicated merges in queue: Maximum number of merge tasks that can be in the ReplicatedMergeTree queue at the same time.
     */
    maxReplicatedMergesInQueue: number;
    /**
     * (Optional) Minimum delay in seconds before repeating a merge with recompression TTL. Default value: 14400 seconds (4 hours).
     */
    mergeWithRecompressionTtlTimeout: number;
    /**
     * (Optional) Minimum delay in seconds before repeating a merge with delete TTL. Default value: 14400 seconds (4 hours).
     */
    mergeWithTtlTimeout: number;
    /**
     * (Optional) Minimum number of bytes in a data part that can be stored in Wide format. You can set one, both or none of these settings.
     */
    minBytesForWidePart: number;
    /**
     * (Optional) Minimum number of rows in a data part that can be stored in Wide format. You can set one, both or none of these settings.
     */
    minRowsForWidePart: number;
    /**
     * Number of free entries in pool to lower max size of merge: Threshold value of free entries in the pool. If the number of entries in the pool falls below this value, ClickHouse reduces the maximum size of a data part to merge. This helps handle small merges faster, rather than filling the pool with lengthy merges.
     */
    numberOfFreeEntriesInPoolToLowerMaxSizeOfMerge: number;
    /**
     * Parts to delay insert: Number of active data parts in a table, on exceeding which ClickHouse starts artificially reduce the rate of inserting data into the table.
     */
    partsToDelayInsert: number;
    /**
     * Parts to throw insert: Threshold value of active data parts in a table, on exceeding which ClickHouse throws the 'Too many parts ...' exception.
     */
    partsToThrowInsert: number;
    /**
     * Replicated deduplication window: Number of recent hash blocks that ZooKeeper will store (the old ones will be deleted).
     */
    replicatedDeduplicationWindow: number;
    /**
     * Replicated deduplication window seconds: Time during which ZooKeeper stores the hash blocks (the old ones wil be deleted).
     */
    replicatedDeduplicationWindowSeconds: number;
    /**
     * (Optional) Enables or disables complete dropping of data parts where all rows are expired in MergeTree tables.
     */
    ttlOnlyDropParts: boolean;
}

export interface GetMdbClickhouseClusterClickhouseConfigRabbitmq {
    /**
     * RabbitMQ user password.
     */
    password: string;
    /**
     * RabbitMQ username.
     */
    username: string;
    /**
     * (Optional) RabbitMQ vhost. Default: '\'.
     */
    vhost: string;
}

export interface GetMdbClickhouseClusterClickhouseResources {
    /**
     * Volume of the storage available to a host, in gigabytes.
     */
    diskSize: number;
    /**
     * Type of the storage of hosts.
     */
    diskTypeId: string;
    resourcePresetId: string;
}

export interface GetMdbClickhouseClusterCloudStorage {
    /**
     * Enables temporary storage in the cluster repository of data requested from the object repository.
     */
    dataCacheEnabled: boolean;
    /**
     * Defines the maximum amount of memory (in bytes) allocated in the cluster storage for temporary storage of data requested from the object storage.
     */
    dataCacheMaxSize: number;
    /**
     * (Required) Whether to use Yandex Object Storage for storing ClickHouse data. Can be either `true` or `false`.
     */
    enabled?: boolean;
    /**
     * Sets the minimum free space ratio in the cluster storage. If the free space is lower than this value, the data is transferred to Yandex Object Storage. Acceptable values are 0 to 1, inclusive.
     */
    moveFactor: number;
}

export interface GetMdbClickhouseClusterDatabase {
    /**
     * The name of the ClickHouse cluster.
     */
    name?: string;
}

export interface GetMdbClickhouseClusterFormatSchema {
    /**
     * The name of the ClickHouse cluster.
     */
    name?: string;
    /**
     * Type of maintenance window. Can be either `ANYTIME` or `WEEKLY`. A day and hour of window need to be specified with weekly window.
     */
    type?: string;
    /**
     * Model file URL. You can only use models stored in Yandex Object Storage.
     */
    uri?: string;
}

export interface GetMdbClickhouseClusterHost {
    /**
     * Sets whether the host should get a public IP address on creation.
     */
    assignPublicIp?: boolean;
    /**
     * The fully qualified domain name of the host.
     */
    fqdn: string;
    /**
     * The name of the shard to which the host belongs.
     */
    shardName: string;
    /**
     * The ID of the subnet, to which the host belongs. The subnet must be a part of the network to which the cluster belongs.
     */
    subnetId: string;
    /**
     * Type of maintenance window. Can be either `ANYTIME` or `WEEKLY`. A day and hour of window need to be specified with weekly window.
     */
    type?: string;
    /**
     * The availability zone where the ClickHouse host will be created.
     */
    zone?: string;
}

export interface GetMdbClickhouseClusterMaintenanceWindow {
    /**
     * Day of week for maintenance window if window type is weekly. Possible values: `MON`, `TUE`, `WED`, `THU`, `FRI`, `SAT`, `SUN`.
     */
    day?: string;
    /**
     * Hour of day in UTC time zone (1-24) for maintenance window if window type is weekly.
     */
    hour?: number;
    /**
     * Type of maintenance window. Can be either `ANYTIME` or `WEEKLY`. A day and hour of window need to be specified with weekly window.
     */
    type?: string;
}

export interface GetMdbClickhouseClusterMlModel {
    /**
     * The name of the ClickHouse cluster.
     */
    name?: string;
    /**
     * Type of maintenance window. Can be either `ANYTIME` or `WEEKLY`. A day and hour of window need to be specified with weekly window.
     */
    type?: string;
    /**
     * Model file URL. You can only use models stored in Yandex Object Storage.
     */
    uri?: string;
}

export interface GetMdbClickhouseClusterShard {
    /**
     * The name of the ClickHouse cluster.
     */
    name?: string;
    /**
     * Resources allocated to hosts of the shard. The resources specified for the shard takes precedence over the resources specified for the cluster. The structure is documented below.
     */
    resources: outputs.GetMdbClickhouseClusterShardResources;
    /**
     * The weight of the shard.
     */
    weight: number;
}

export interface GetMdbClickhouseClusterShardGroup {
    /**
     * Description of the shard group.
     */
    description?: string;
    /**
     * The name of the ClickHouse cluster.
     */
    name?: string;
    /**
     * List of shards names that belong to the shard group.
     */
    shardNames?: string[];
}

export interface GetMdbClickhouseClusterShardResources {
    /**
     * Volume of the storage available to a host, in gigabytes.
     */
    diskSize: number;
    /**
     * Type of the storage of hosts.
     */
    diskTypeId: string;
    resourcePresetId: string;
}

export interface GetMdbClickhouseClusterUser {
    /**
     * The name of the ClickHouse cluster.
     */
    name?: string;
    /**
     * RabbitMQ user password.
     */
    password?: string;
    /**
     * Set of permissions granted to the user. The structure is documented below.
     */
    permissions: outputs.GetMdbClickhouseClusterUserPermission[];
    /**
     * Set of user quotas. The structure is documented below.
     */
    quotas: outputs.GetMdbClickhouseClusterUserQuota[];
    /**
     * Kafka connection settngs sanem as `kafka` block.
     */
    settings: outputs.GetMdbClickhouseClusterUserSettings;
}

export interface GetMdbClickhouseClusterUserPermission {
    /**
     * The name of the database that the permission grants access to.
     */
    databaseName?: string;
}

export interface GetMdbClickhouseClusterUserQuota {
    /**
     * The number of queries that threw exception.
     */
    errors: number;
    /**
     * The total query execution time, in milliseconds (wall time).
     */
    executionTime: number;
    /**
     * Duration of interval for quota in milliseconds.
     */
    intervalDuration?: number;
    /**
     * The total number of queries.
     */
    queries: number;
    /**
     * The total number of source rows read from tables for running the query, on all remote servers.
     */
    readRows: number;
    /**
     * The total number of rows given as the result.
     */
    resultRows: number;
}

export interface GetMdbClickhouseClusterUserSettings {
    /**
     * Include CORS headers in HTTP responces.
     */
    addHttpCorsHeader: boolean;
    /**
     * Allows or denies DDL queries.
     */
    allowDdl: boolean;
    /**
     * (Optional) Enables introspections functions for query profiling.
     */
    allowIntrospectionFunctions: boolean;
    /**
     * (Optional) Allows specifying LowCardinality modifier for types of small fixed size (8 or less) in CREATE TABLE statements. Enabling this may increase merge times and memory consumption.
     */
    allowSuspiciousLowCardinalityTypes: boolean;
    /**
     * (Optional) Enables asynchronous inserts. Disabled by default.
     */
    asyncInsert: boolean;
    /**
     * (Optional) The maximum timeout in milliseconds since the first INSERT query before inserting collected data. If the parameter is set to 0, the timeout is disabled. Default value: 200.
     */
    asyncInsertBusyTimeout: number;
    /**
     * (Optional) The maximum size of the unparsed data in bytes collected per query before being inserted. If the parameter is set to 0, asynchronous insertions are disabled. Default value: 100000.
     */
    asyncInsertMaxDataSize: number;
    /**
     * (Optional) The maximum timeout in milliseconds since the last INSERT query before dumping collected data. If enabled, the settings prolongs the asyncInsertBusyTimeout with every INSERT query as long as asyncInsertMaxDataSize is not exceeded.
     */
    asyncInsertStaleTimeout: number;
    /**
     * (Optional) The maximum number of threads for background data parsing and insertion. If the parameter is set to 0, asynchronous insertions are disabled. Default value: 16.
     */
    asyncInsertThreads: number;
    /**
     * (Optional) Cancels HTTP read-only queries (e.g. SELECT) when a client closes the connection without waiting for the response.
     * Default value: false.
     */
    cancelHttpReadonlyQueriesOnClientClose: boolean;
    /**
     * Enable compilation of queries.
     */
    compile: boolean;
    /**
     * Turn on expression compilation.
     */
    compileExpressions: boolean;
    /**
     * Connect timeout in milliseconds on the socket used for communicating with the client.
     */
    connectTimeout: number;
    /**
     * (Optional) The timeout in milliseconds for connecting to a remote server for a Distributed table engine, if the ‘shard’ and ‘replica’ sections are used in the cluster definition. If unsuccessful, several attempts are made to connect to various replicas. Default value: 50.
     */
    connectTimeoutWithFailover: number;
    /**
     * Specifies which of the uniq* functions should be used to perform the COUNT(DISTINCT …) construction.
     */
    countDistinctImplementation: string;
    /**
     * Sets behaviour on overflow when using DISTINCT. Possible values:
     */
    distinctOverflowMode: string;
    /**
     * Determine the behavior of distributed subqueries.
     */
    distributedAggregationMemoryEfficient: boolean;
    /**
     * Timeout for DDL queries, in milliseconds.
     */
    distributedDdlTaskTimeout: number;
    /**
     * Changes the behaviour of distributed subqueries.
     */
    distributedProductMode: string;
    /**
     * Allows to retunr empty result.
     */
    emptyResultForAggregationByEmptySet: boolean;
    /**
     * Enables or disables data compression in the response to an HTTP request.
     */
    enableHttpCompression: boolean;
    /**
     * Forces a query to an out-of-date replica if updated data is not available.
     */
    fallbackToStaleReplicasForDistributedQueries: boolean;
    /**
     * (Optional) Sets the data format of a nested columns.
     */
    flattenNested: boolean;
    /**
     * Disables query execution if the index can’t be used by date.
     */
    forceIndexByDate: boolean;
    /**
     * Disables query execution if indexing by the primary key is not possible.
     */
    forcePrimaryKey: boolean;
    /**
     * Sets behaviour on overflow while GROUP BY operation. Possible values:
     */
    groupByOverflowMode: string;
    /**
     * Sets the threshold of the number of keys, after that the two-level aggregation should be used.
     */
    groupByTwoLevelThreshold: number;
    /**
     * Sets the threshold of the number of bytes, after that the two-level aggregation should be used.
     */
    groupByTwoLevelThresholdBytes: number;
    /**
     * Timeout for HTTP connection in milliseconds.
     */
    httpConnectionTimeout: number;
    /**
     * Sets minimal interval between notifications about request process in HTTP header X-ClickHouse-Progress.
     */
    httpHeadersProgressInterval: number;
    /**
     * Timeout for HTTP connection in milliseconds.
     */
    httpReceiveTimeout: number;
    /**
     * Timeout for HTTP connection in milliseconds.
     */
    httpSendTimeout: number;
    /**
     * When performing INSERT queries, replace omitted input column values with default values of the respective columns.
     */
    inputFormatDefaultsForOmittedFields: boolean;
    /**
     * (Optional) Enables or disables the insertion of JSON data with nested objects.
     */
    inputFormatImportNestedJson: boolean;
    /**
     * (Optional) Enables or disables order-preserving parallel parsing of data formats. Supported only for TSV, TKSV, CSV and JSONEachRow formats.
     */
    inputFormatParallelParsing: boolean;
    /**
     * Enables or disables the full SQL parser if the fast stream parser can’t parse the data.
     */
    inputFormatValuesInterpretExpressions: boolean;
    /**
     * (Optional) Enables the insertion of default values instead of NULL into columns with not nullable data type. Default value: true.
     */
    insertNullAsDefault: boolean;
    /**
     * Enables the quorum writes.
     */
    insertQuorum: number;
    /**
     * Write to a quorum timeout in milliseconds.
     */
    insertQuorumTimeout: number;
    /**
     * Sets behaviour on overflow in JOIN. Possible values:
     */
    joinOverflowMode: string;
    /**
     * Sets the type of JOIN behaviour. When merging tables, empty cells may appear. ClickHouse fills them differently based on this setting.
     */
    joinUseNulls: boolean;
    /**
     * Require aliases for subselects and table functions in FROM that more than one table is present.
     */
    joinedSubqueryRequiresAlias: boolean;
    /**
     * (Optional) Method of reading data from local filesystem. Possible values:
     */
    localFilesystemReadMethod: string;
    /**
     * Allows or restricts using the LowCardinality data type with the Native format.
     */
    lowCardinalityAllowInNativeFormat: boolean;
    /**
     * Maximum abstract syntax tree depth.
     */
    maxAstDepth: number;
    /**
     * Maximum abstract syntax tree elements.
     */
    maxAstElements: number;
    /**
     * A recommendation for what size of the block (in a count of rows) to load from tables.
     */
    maxBlockSize: number;
    /**
     * Limit in bytes for using memoru for GROUP BY before using swap on disk.
     */
    maxBytesBeforeExternalGroupBy: number;
    /**
     * This setting is equivalent of the maxBytesBeforeExternalGroupBy setting, except for it is for sort operation (ORDER BY), not aggregation.
     */
    maxBytesBeforeExternalSort: number;
    /**
     * Limits the maximum size of a hash table in bytes (uncompressed data) when using DISTINCT.
     */
    maxBytesInDistinct: number;
    /**
     * Limit on maximum size of the hash table for JOIN, in bytes.
     */
    maxBytesInJoin: number;
    /**
     * Limit on the number of bytes in the set resulting from the execution of the IN section.
     */
    maxBytesInSet: number;
    /**
     * Limits the maximum number of bytes (uncompressed data) that can be read from a table when running a query.
     */
    maxBytesToRead: number;
    /**
     * Limits the maximum number of bytes (uncompressed data) that can be read from a table for sorting.
     */
    maxBytesToSort: number;
    /**
     * Limits the maximum number of bytes (uncompressed data) that can be passed to a remote server or saved in a temporary table when using GLOBAL IN.
     */
    maxBytesToTransfer: number;
    /**
     * Limits the maximum number of columns that can be read from a table in a single query.
     */
    maxColumnsToRead: number;
    /**
     * (Optional) The maximum number of concurrent requests per user. Default value: 0 (no limit).
     */
    maxConcurrentQueriesForUser: number;
    /**
     * Limits the maximum query execution time in milliseconds.
     */
    maxExecutionTime: number;
    /**
     * Maximum abstract syntax tree depth after after expansion of aliases.
     */
    maxExpandedAstElements: number;
    /**
     * (Optional) Sets the maximum number of parallel threads for the SELECT query data read phase with the FINAL modifier.
     */
    maxFinalThreads: number;
    /**
     * (Optional) Limits the maximum number of HTTP GET redirect hops for URL-engine tables.
     * If the parameter is set to 0 (default), no hops is allowed.
     */
    maxHttpGetRedirects: number;
    /**
     * The size of blocks (in a count of rows) to form for insertion into a table.
     */
    maxInsertBlockSize: number;
    /**
     * Limits the maximum memory usage (in bytes) for processing queries on a single server.
     */
    maxMemoryUsage: number;
    /**
     * Limits the maximum memory usage (in bytes) for processing of user's queries on a single server.
     */
    maxMemoryUsageForUser: number;
    /**
     * Limits the speed of the data exchange over the network in bytes per second.
     */
    maxNetworkBandwidth: number;
    /**
     * Limits the speed of the data exchange over the network in bytes per second.
     */
    maxNetworkBandwidthForUser: number;
    /**
     * The maximum part of a query that can be taken to RAM for parsing with the SQL parser.
     */
    maxQuerySize: number;
    /**
     * (Optional) The maximum size of the buffer to read from the filesystem.
     */
    maxReadBufferSize: number;
    /**
     * Disables lagging replicas for distributed queries.
     */
    maxReplicaDelayForDistributedQueries: number;
    /**
     * Limits the number of bytes in the result.
     */
    maxResultBytes: number;
    /**
     * Limits the number of rows in the result.
     */
    maxResultRows: number;
    /**
     * Limits the maximum number of different rows when using DISTINCT.
     */
    maxRowsInDistinct: number;
    /**
     * Limit on maximum size of the hash table for JOIN, in rows.
     */
    maxRowsInJoin: number;
    /**
     * Limit on the number of rows in the set resulting from the execution of the IN section.
     */
    maxRowsInSet: number;
    /**
     * Limits the maximum number of unique keys received from aggregation function.
     */
    maxRowsToGroupBy: number;
    /**
     * Limits the maximum number of rows that can be read from a table when running a query.
     */
    maxRowsToRead: number;
    /**
     * Limits the maximum number of rows that can be read from a table for sorting.
     */
    maxRowsToSort: number;
    /**
     * Limits the maximum number of rows that can be passed to a remote server or saved in a temporary table when using GLOBAL IN.
     */
    maxRowsToTransfer: number;
    /**
     * Limits the maximum number of temporary columns that must be kept in RAM at the same time when running a query, including constant columns.
     */
    maxTemporaryColumns: number;
    /**
     * Limits the maximum number of temporary columns that must be kept in RAM at the same time when running a query, excluding constant columns.
     */
    maxTemporaryNonConstColumns: number;
    /**
     * The maximum number of query processing threads, excluding threads for retrieving data from remote servers.
     */
    maxThreads: number;
    /**
     * (Optional) Collect random allocations and deallocations and write them into system.trace_log with 'MemorySample' trace_type. The probability is for every alloc/free regardless to the size of the allocation. Possible values: from 0 to 1. Default: 0.
     */
    memoryProfilerSampleProbability: number;
    /**
     * (Optional) Memory profiler step (in bytes).  If the next query step requires more memory than this parameter specifies, the memory profiler collects the allocating stack trace. Values lower than a few megabytes slow down query processing. Default value: 4194304 (4 MB). Zero means disabled memory profiler.
     */
    memoryProfilerStep: number;
    /**
     * If ClickHouse should read more than mergeTreeMaxBytesToUseCache bytes in one query, it doesn’t use the cache of uncompressed blocks.
     */
    mergeTreeMaxBytesToUseCache: number;
    /**
     * If ClickHouse should read more than mergeTreeMaxRowsToUseCache rows in one query, it doesn’t use the cache of uncompressed blocks.
     */
    mergeTreeMaxRowsToUseCache: number;
    /**
     * If the number of bytes to read from one file of a MergeTree-engine table exceeds merge_tree_min_bytes_for_concurrent_read, then ClickHouse tries to concurrently read from this file in several threads.
     */
    mergeTreeMinBytesForConcurrentRead: number;
    /**
     * If the number of rows to be read from a file of a MergeTree table exceeds mergeTreeMinRowsForConcurrentRead then ClickHouse tries to perform a concurrent reading from this file on several threads.
     */
    mergeTreeMinRowsForConcurrentRead: number;
    /**
     * The minimum data volume required for using direct I/O access to the storage disk.
     */
    minBytesToUseDirectIo: number;
    /**
     * How many times to potentially use a compiled chunk of code before running compilation.
     */
    minCountToCompile: number;
    /**
     * A query waits for expression compilation process to complete prior to continuing execution.
     */
    minCountToCompileExpression: number;
    /**
     * Minimal execution speed in rows per second.
     */
    minExecutionSpeed: number;
    /**
     * Minimal execution speed in bytes per second.
     */
    minExecutionSpeedBytes: number;
    /**
     * Sets the minimum number of bytes in the block which can be inserted into a table by an INSERT query.
     */
    minInsertBlockSizeBytes: number;
    /**
     * Sets the minimum number of rows in the block which can be inserted into a table by an INSERT query.
     */
    minInsertBlockSizeRows: number;
    /**
     * If the value is true, integers appear in quotes when using JSON* Int64 and UInt64 formats (for compatibility with most JavaScript implementations); otherwise, integers are output without the quotes.
     */
    outputFormatJsonQuote64bitIntegers: boolean;
    /**
     * Enables +nan, -nan, +inf, -inf outputs in JSON output format.
     */
    outputFormatJsonQuoteDenormals: boolean;
    /**
     * Query priority.
     */
    priority: number;
    /**
     * Quota accounting mode.
     */
    quotaMode: string;
    /**
     * Sets behaviour on overflow while read. Possible values:
     */
    readOverflowMode: string;
    /**
     * Restricts permissions for reading data, write data and change settings queries.
     */
    readonly: number;
    /**
     * Receive timeout in milliseconds on the socket used for communicating with the client.
     */
    receiveTimeout: number;
    /**
     * For ALTER ... ATTACH|DETACH|DROP queries, you can use the replicationAlterPartitionsSync setting to set up waiting.
     */
    replicationAlterPartitionsSync: number;
    /**
     * Sets behaviour on overflow in result. Possible values:
     */
    resultOverflowMode: string;
    /**
     * Enables or disables sequential consistency for SELECT queries.
     */
    selectSequentialConsistency: boolean;
    /**
     * Enables or disables X-ClickHouse-Progress HTTP response headers in clickhouse-server responses.
     */
    sendProgressInHttpHeaders: boolean;
    /**
     * Send timeout in milliseconds on the socket used for communicating with the client.
     */
    sendTimeout: number;
    /**
     * Sets behaviour on overflow in the set resulting. Possible values:
     */
    setOverflowMode: string;
    /**
     * Enables or disables silently skipping of unavailable shards.
     */
    skipUnavailableShards: boolean;
    /**
     * Sets behaviour on overflow while sort. Possible values:
     */
    sortOverflowMode: string;
    /**
     * (Optional) Timeout (in seconds) between checks of execution speed. It is checked that execution speed is not less that specified in minExecutionSpeed parameter.
     * Must be at least 1000.
     */
    timeoutBeforeCheckingExecutionSpeed: number;
    /**
     * Sets behaviour on overflow. Possible values:
     */
    timeoutOverflowMode: string;
    /**
     * Sets behaviour on overflow. Possible values:
     */
    transferOverflowMode: string;
    /**
     * Enables equality of NULL values for IN operator.
     */
    transformNullIn: boolean;
    /**
     * Whether to use a cache of uncompressed blocks.
     */
    useUncompressedCache: boolean;
    /**
     * (Optional) Enables waiting for processing of asynchronous insertion. If enabled, server returns OK only after the data is inserted.
     */
    waitForAsyncInsert: boolean;
    /**
     * (Optional) The timeout (in seconds) for waiting for processing of asynchronous insertion. Value must be at least 1000 (1 second).
     */
    waitForAsyncInsertTimeout: number;
}

export interface GetMdbClickhouseClusterZookeeper {
    /**
     * Resources allocated to hosts of the shard. The resources specified for the shard takes precedence over the resources specified for the cluster. The structure is documented below.
     */
    resources: outputs.GetMdbClickhouseClusterZookeeperResources;
}

export interface GetMdbClickhouseClusterZookeeperResources {
    /**
     * Volume of the storage available to a host, in gigabytes.
     */
    diskSize: number;
    /**
     * Type of the storage of hosts.
     */
    diskTypeId: string;
    resourcePresetId: string;
}

export interface GetMdbElasticSearchClusterConfig {
    adminPassword: string;
    /**
     * Configuration for Elasticsearch data nodes subcluster. The structure is documented below.
     */
    dataNodes: outputs.GetMdbElasticSearchClusterConfigDataNode[];
    /**
     * Edition of Elasticsearch. For more information, see [the official documentation](https://cloud.yandex.com/en-ru/docs/managed-elasticsearch/concepts/es-editions).
     */
    edition: string;
    /**
     * Configuration for Elasticsearch master nodes subcluster. The structure is documented below.
     */
    masterNode: outputs.GetMdbElasticSearchClusterConfigMasterNode;
    /**
     * A set of requested Elasticsearch plugins.
     */
    plugins: string[];
    /**
     * Version of Elasticsearch.
     */
    version: string;
}

export interface GetMdbElasticSearchClusterConfigDataNode {
    /**
     * Resources allocated to hosts of the Elasticsearch master nodes subcluster. The structure is documented below.
     */
    resources: outputs.GetMdbElasticSearchClusterConfigDataNodeResource[];
}

export interface GetMdbElasticSearchClusterConfigDataNodeResource {
    /**
     * Volume of the storage available to a Elasticsearch host, in gigabytes.
     */
    diskSize: number;
    /**
     * Type of the storage of Elasticsearch hosts.
     */
    diskTypeId: string;
    resourcePresetId: string;
}

export interface GetMdbElasticSearchClusterConfigMasterNode {
    /**
     * Resources allocated to hosts of the Elasticsearch master nodes subcluster. The structure is documented below.
     */
    resources: outputs.GetMdbElasticSearchClusterConfigMasterNodeResource[];
}

export interface GetMdbElasticSearchClusterConfigMasterNodeResource {
    /**
     * Volume of the storage available to a Elasticsearch host, in gigabytes.
     */
    diskSize: number;
    /**
     * Type of the storage of Elasticsearch hosts.
     */
    diskTypeId: string;
    resourcePresetId: string;
}

export interface GetMdbElasticSearchClusterHost {
    /**
     * Sets whether the host should get a public IP address on creation.
     */
    assignPublicIp: boolean;
    /**
     * The fully qualified domain name of the host.
     */
    fqdn: string;
    /**
     * The name of the Elasticsearch cluster.
     */
    name: string;
    /**
     * The ID of the subnet, to which the host belongs. The subnet must be a part of the network to which the cluster belongs.
     */
    subnetId: string;
    /**
     * Type of a maintenance window. Can be either `ANYTIME` or `WEEKLY`. A day and hour need to be specified with the weekly window.
     */
    type: string;
    /**
     * The availability zone where the Elasticsearch host will be created.
     */
    zone: string;
}

export interface GetMdbElasticSearchClusterMaintenanceWindow {
    /**
     * Day of the week for a maintenance window if the window type is weekly. Possible values: `MON`, `TUE`, `WED`, `THU`, `FRI`, `SAT`, `SUN`.
     */
    day: string;
    /**
     * Hour of the day in UTC time zone (1-24) for a maintenance window if the window type is weekly.
     */
    hour: number;
    /**
     * Type of a maintenance window. Can be either `ANYTIME` or `WEEKLY`. A day and hour need to be specified with the weekly window.
     */
    type: string;
}

export interface GetMdbGreenplumClusterAccess {
    dataLens: boolean;
    dataTransfer: boolean;
    webSql: boolean;
}

export interface GetMdbGreenplumClusterBackupWindowStart {
    hours: number;
    minutes: number;
}

export interface GetMdbGreenplumClusterMaintenanceWindow {
    day: string;
    hour: number;
    type: string;
}

export interface GetMdbGreenplumClusterMasterHost {
    assignPublicIp: boolean;
    fqdn: string;
}

export interface GetMdbGreenplumClusterMasterSubcluster {
    resources: outputs.GetMdbGreenplumClusterMasterSubclusterResource[];
}

export interface GetMdbGreenplumClusterMasterSubclusterResource {
    diskSize: number;
    diskTypeId: string;
    resourcePresetId: string;
}

export interface GetMdbGreenplumClusterPoolerConfig {
    poolClientIdleTimeout?: number;
    poolSize?: number;
    poolingMode?: string;
}

export interface GetMdbGreenplumClusterSegmentHost {
    fqdn: string;
}

export interface GetMdbGreenplumClusterSegmentSubcluster {
    resources: outputs.GetMdbGreenplumClusterSegmentSubclusterResource[];
}

export interface GetMdbGreenplumClusterSegmentSubclusterResource {
    diskSize: number;
    diskTypeId: string;
    resourcePresetId: string;
}

export interface GetMdbKafkaClusterAccess {
    /**
     * Allow access for [DataTransfer](https://cloud.yandex.com/services/data-transfer)
     */
    dataTransfer: boolean;
}

export interface GetMdbKafkaClusterConfig {
    /**
     * (Optional) Access policy to the Kafka cluster. The structure is documented below.
     */
    access: outputs.GetMdbKafkaClusterConfigAccess;
    /**
     * The flag that defines whether a public IP address is assigned to the node.
     */
    assignPublicIp?: boolean;
    /**
     * (Optional) Count of brokers per availability zone.
     */
    brokersCount?: number;
    /**
     * (Optional) Configuration of the Kafka subcluster. The structure is documented below.
     */
    kafka: outputs.GetMdbKafkaClusterConfigKafka;
    /**
     * (Optional) Enables managed schema registry on cluster. Can be either `true` or `false`.
     */
    schemaRegistry?: boolean;
    /**
     * (Optional) Allows to use Kafka AdminAPI to manage topics. Can be either `true` or `false`.
     */
    unmanagedTopics?: boolean;
    /**
     * (Required) Version of the Kafka server software.
     */
    version: string;
    /**
     * (Optional) List of availability zones.
     */
    zones: string[];
    /**
     * (Optional) Configuration of the ZooKeeper subcluster. The structure is documented below.
     */
    zookeeper: outputs.GetMdbKafkaClusterConfigZookeeper;
}

export interface GetMdbKafkaClusterConfigAccess {
    /**
     * Allow access for [DataTransfer](https://cloud.yandex.com/services/data-transfer)
     */
    dataTransfer?: boolean;
}

export interface GetMdbKafkaClusterConfigKafka {
    /**
     * (Optional) User-defined settings for the Kafka cluster. The structure is documented below.
     */
    kafkaConfig?: outputs.GetMdbKafkaClusterConfigKafkaKafkaConfig;
    /**
     * (Optional) Resources allocated to hosts of the ZooKeeper subcluster. The structure is documented below.
     */
    resources: outputs.GetMdbKafkaClusterConfigKafkaResources;
}

export interface GetMdbKafkaClusterConfigKafkaKafkaConfig {
    autoCreateTopicsEnable?: boolean;
    compressionType?: string;
    defaultReplicationFactor?: string;
    logFlushIntervalMessages?: string;
    logFlushIntervalMs?: string;
    logFlushSchedulerIntervalMs?: string;
    logPreallocate?: boolean;
    logRetentionBytes?: string;
    logRetentionHours?: string;
    logRetentionMinutes?: string;
    logRetentionMs?: string;
    logSegmentBytes?: string;
    messageMaxBytes?: string;
    numPartitions?: string;
    offsetsRetentionMinutes?: string;
    replicaFetchMaxBytes?: string;
    saslEnabledMechanisms?: string[];
    socketReceiveBufferBytes?: string;
    socketSendBufferBytes?: string;
    sslCipherSuites?: string[];
}

export interface GetMdbKafkaClusterConfigKafkaResources {
    /**
     * (Optional) Volume of the storage available to a ZooKeeper host, in gigabytes.
     */
    diskSize: number;
    /**
     * (Optional) Type of the storage of ZooKeeper hosts.
     * For more information see [the official documentation](https://cloud.yandex.com/docs/managed-kafka/concepts/storage).
     */
    diskTypeId: string;
    resourcePresetId: string;
}

export interface GetMdbKafkaClusterConfigZookeeper {
    /**
     * (Optional) Resources allocated to hosts of the ZooKeeper subcluster. The structure is documented below.
     */
    resources: outputs.GetMdbKafkaClusterConfigZookeeperResources;
}

export interface GetMdbKafkaClusterConfigZookeeperResources {
    /**
     * (Optional) Volume of the storage available to a ZooKeeper host, in gigabytes.
     */
    diskSize: number;
    /**
     * (Optional) Type of the storage of ZooKeeper hosts.
     * For more information see [the official documentation](https://cloud.yandex.com/docs/managed-kafka/concepts/storage).
     */
    diskTypeId: string;
    resourcePresetId: string;
}

export interface GetMdbKafkaClusterHost {
    /**
     * The flag that defines whether a public IP address is assigned to the node.
     */
    assignPublicIp: boolean;
    /**
     * Health of the host.
     */
    health: string;
    /**
     * The name of the Kafka cluster.
     */
    name: string;
    /**
     * Role of the host in the cluster.
     */
    role: string;
    /**
     * The ID of the subnet, to which the host belongs.
     */
    subnetId: string;
    /**
     * The availability zone where the Kafka host was created.
     */
    zoneId: string;
}

export interface GetMdbKafkaClusterMaintenanceWindow {
    /**
     * Day of the week (in `DDD` format). Value is one of: "MON", "TUE", "WED", "THU", "FRI", "SAT", "SUN"
     */
    day: string;
    /**
     * Hour of the day in UTC (in `HH` format). Value is between 1 and 24.
     */
    hour: number;
    /**
     * Type of maintenance window. Can be either `ANYTIME` or `WEEKLY`.
     */
    type: string;
}

export interface GetMdbKafkaClusterTopic {
    /**
     * The name of the Kafka cluster.
     */
    name: string;
    /**
     * (Required) The number of the topic's partitions.
     */
    partitions: number;
    /**
     * (Required) Amount of data copies (replicas) for the topic in the cluster.
     */
    replicationFactor: number;
    /**
     * (Required) User-defined settings for the topic. The structure is documented below.
     */
    topicConfig?: outputs.GetMdbKafkaClusterTopicTopicConfig;
}

export interface GetMdbKafkaClusterTopicTopicConfig {
    cleanupPolicy?: string;
    compressionType?: string;
    deleteRetentionMs?: string;
    fileDeleteDelayMs?: string;
    flushMessages?: string;
    flushMs?: string;
    maxMessageBytes?: string;
    minCompactionLagMs?: string;
    minInsyncReplicas?: string;
    preallocate?: boolean;
    retentionBytes?: string;
    retentionMs?: string;
    segmentBytes?: string;
}

export interface GetMdbKafkaClusterUser {
    /**
     * The name of the Kafka cluster.
     */
    name: string;
    /**
     * (Required) The password of the user.
     */
    password: string;
    /**
     * (Optional) Set of permissions granted to the user. The structure is documented below.
     */
    permissions?: outputs.GetMdbKafkaClusterUserPermission[];
}

export interface GetMdbKafkaClusterUserPermission {
    /**
     * (Optional) Set of hosts, to which this permission grants access to.
     */
    allowHosts?: string[];
    /**
     * Role of the host in the cluster.
     */
    role: string;
    /**
     * (Required) The name of the topic that the permission grants access to.
     */
    topicName: string;
}

export interface GetMdbKafkaConnectorConnectorConfigMirrormaker {
    /**
     * Replication factor for topics created in target cluster
     */
    replicationFactor: number;
    /**
     * Settings for source cluster. The structure is documented below.
     */
    sourceClusters: outputs.GetMdbKafkaConnectorConnectorConfigMirrormakerSourceCluster[];
    /**
     * Settings for target cluster. The structure is documented below.
     */
    targetClusters: outputs.GetMdbKafkaConnectorConnectorConfigMirrormakerTargetCluster[];
    /**
     * The pattern for topic names to be copied to s3 bucket.
     */
    topics: string;
}

export interface GetMdbKafkaConnectorConnectorConfigMirrormakerSourceCluster {
    /**
     * Name of the cluster. Used also as a topic prefix
     */
    alias: string;
    /**
     * Connection params for external cluster
     */
    externalClusters: outputs.GetMdbKafkaConnectorConnectorConfigMirrormakerSourceClusterExternalCluster[];
    /**
     * Using this section in the cluster definition (source or target) means it's this cluster
     */
    thisClusters: outputs.GetMdbKafkaConnectorConnectorConfigMirrormakerSourceClusterThisCluster[];
}

export interface GetMdbKafkaConnectorConnectorConfigMirrormakerSourceClusterExternalCluster {
    /**
     * List of bootstrap servers to connect to cluster
     */
    bootstrapServers: string;
    /**
     * Type of SASL authentification mechanism to use
     */
    saslMechanism: string;
    /**
     * Password to use in SASL authentification mechanism
     */
    saslPassword: string;
    /**
     * Username to use in SASL authentification mechanism
     */
    saslUsername: string;
    /**
     * Security protocol to use
     */
    securityProtocol: string;
}

export interface GetMdbKafkaConnectorConnectorConfigMirrormakerSourceClusterThisCluster {
}

export interface GetMdbKafkaConnectorConnectorConfigMirrormakerTargetCluster {
    /**
     * Name of the cluster. Used also as a topic prefix
     */
    alias: string;
    /**
     * Connection params for external cluster
     */
    externalClusters: outputs.GetMdbKafkaConnectorConnectorConfigMirrormakerTargetClusterExternalCluster[];
    /**
     * Using this section in the cluster definition (source or target) means it's this cluster
     */
    thisClusters: outputs.GetMdbKafkaConnectorConnectorConfigMirrormakerTargetClusterThisCluster[];
}

export interface GetMdbKafkaConnectorConnectorConfigMirrormakerTargetClusterExternalCluster {
    /**
     * List of bootstrap servers to connect to cluster
     */
    bootstrapServers: string;
    /**
     * Type of SASL authentification mechanism to use
     */
    saslMechanism: string;
    /**
     * Password to use in SASL authentification mechanism
     */
    saslPassword: string;
    /**
     * Username to use in SASL authentification mechanism
     */
    saslUsername: string;
    /**
     * Security protocol to use
     */
    securityProtocol: string;
}

export interface GetMdbKafkaConnectorConnectorConfigMirrormakerTargetClusterThisCluster {
}

export interface GetMdbKafkaConnectorConnectorConfigS3Sink {
    /**
     * Сompression type for messages. Cannot be changed.
     */
    fileCompressionType: string;
    /**
     * Max records per file.
     */
    fileMaxRecords: number;
    /**
     * Settings for connection to s3-compatible storage. The structure is documented below.
     */
    s3Connections: outputs.GetMdbKafkaConnectorConnectorConfigS3SinkS3Connection[];
    /**
     * The pattern for topic names to be copied to s3 bucket.
     */
    topics: string;
}

export interface GetMdbKafkaConnectorConnectorConfigS3SinkS3Connection {
    /**
     * Name of the bucket in s3-compatible storage.
     */
    bucketName: string;
    /**
     * Connection params for external s3-compatible storage. The structure is documented below.
     */
    externalS3s: outputs.GetMdbKafkaConnectorConnectorConfigS3SinkS3ConnectionExternalS3[];
}

export interface GetMdbKafkaConnectorConnectorConfigS3SinkS3ConnectionExternalS3 {
    /**
     * ID of aws-compatible static key.
     */
    accessKeyId: string;
    /**
     * URL of s3-compatible storage.
     */
    endpoint: string;
    /**
     * region of s3-compatible storage. [Available region list](https://docs.aws.amazon.com/AWSJavaSDK/latest/javadoc/com/amazonaws/regions/Regions.html).
     */
    region: string;
    /**
     * Secret key of aws-compatible static key.
     */
    secretAccessKey: string;
}

export interface GetMdbKafkaTopicTopicConfig {
    cleanupPolicy: string;
    compressionType: string;
    deleteRetentionMs: string;
    fileDeleteDelayMs: string;
    flushMessages: string;
    flushMs: string;
    maxMessageBytes: string;
    minCompactionLagMs: string;
    minInsyncReplicas: string;
    preallocate: boolean;
    retentionBytes: string;
    retentionMs: string;
    segmentBytes: string;
}

export interface GetMdbKafkaUserPermission {
    allowHosts: string[];
    role: string;
    topicName: string;
}

export interface GetMdbMongodbClusterClusterConfig {
    /**
     * Access policy to MongoDB cluster. The structure is documented below.
     */
    access: outputs.GetMdbMongodbClusterClusterConfigAccess;
    backupRetainPeriodDays: number;
    /**
     * Time to start the daily backup, in the UTC timezone. The structure is documented below.
     */
    backupWindowStart: outputs.GetMdbMongodbClusterClusterConfigBackupWindowStart;
    /**
     * Feature compatibility version of MongoDB.
     */
    featureCompatibilityVersion: string;
    mongocfg: outputs.GetMdbMongodbClusterClusterConfigMongocfg;
    /**
     * (Optional) Configuration of the mongod service. The structure is documented below.
     */
    mongod: outputs.GetMdbMongodbClusterClusterConfigMongod;
    mongos: outputs.GetMdbMongodbClusterClusterConfigMongos;
    performanceDiagnostics: outputs.GetMdbMongodbClusterClusterConfigPerformanceDiagnostics;
    /**
     * Version of MongoDB (either 6.0, 6.0-enterprise, 5.0, 5.0-enterprise, 4.4, 4.4-enterprise, 4.2).
     */
    version?: string;
}

export interface GetMdbMongodbClusterClusterConfigAccess {
    /**
     * Allow access for [Yandex DataLens](https://cloud.yandex.com/services/datalens).
     */
    dataLens?: boolean;
    /**
     * (Optional) Allow access for [DataTransfer](https://cloud.yandex.com/services/data-transfer)
     */
    dataTransfer?: boolean;
}

export interface GetMdbMongodbClusterClusterConfigBackupWindowStart {
    /**
     * The hour at which backup will be started.
     */
    hours?: number;
    /**
     * The minute at which backup will be started.
     */
    minutes?: number;
}

export interface GetMdbMongodbClusterClusterConfigMongocfg {
    net?: outputs.GetMdbMongodbClusterClusterConfigMongocfgNet;
    operationProfiling?: outputs.GetMdbMongodbClusterClusterConfigMongocfgOperationProfiling;
    storage?: outputs.GetMdbMongodbClusterClusterConfigMongocfgStorage;
}

export interface GetMdbMongodbClusterClusterConfigMongocfgNet {
    maxIncomingConnections?: number;
}

export interface GetMdbMongodbClusterClusterConfigMongocfgOperationProfiling {
    mode?: string;
    slowOpThreshold?: number;
}

export interface GetMdbMongodbClusterClusterConfigMongocfgStorage {
    wiredTiger?: outputs.GetMdbMongodbClusterClusterConfigMongocfgStorageWiredTiger;
}

export interface GetMdbMongodbClusterClusterConfigMongocfgStorageWiredTiger {
    cacheSizeGb?: number;
}

export interface GetMdbMongodbClusterClusterConfigMongod {
    /**
     * (Optional) A set of audit log settings
     * (see the [auditLog](https://www.mongodb.com/docs/manual/reference/configuration-options/#auditlog-options) option).
     * The structure is documented below. Available only in enterprise edition.
     */
    auditLog: outputs.GetMdbMongodbClusterClusterConfigMongodAuditLog;
    net?: outputs.GetMdbMongodbClusterClusterConfigMongodNet;
    operationProfiling?: outputs.GetMdbMongodbClusterClusterConfigMongodOperationProfiling;
    /**
     * (Optional) A set of MongoDB Security settings
     * (see the [security](https://www.mongodb.com/docs/manual/reference/configuration-options/#security-options) option).
     * The structure is documented below. Available only in enterprise edition.
     */
    security: outputs.GetMdbMongodbClusterClusterConfigMongodSecurity;
    /**
     * (Optional) A set of MongoDB Server Parameters
     * (see the [setParameter](https://www.mongodb.com/docs/manual/reference/configuration-options/#setparameter-option) option).
     * The structure is documented below.
     */
    setParameter: outputs.GetMdbMongodbClusterClusterConfigMongodSetParameter;
    storage?: outputs.GetMdbMongodbClusterClusterConfigMongodStorage;
}

export interface GetMdbMongodbClusterClusterConfigMongodAuditLog {
    /**
     * (Optional) Configuration of the audit log filter in JSON format.
     * For more information see [auditLog.filter](https://www.mongodb.com/docs/manual/reference/configuration-options/#mongodb-setting-auditLog.filter)
     * description in the official documentation. Available only in enterprise edition.
     */
    filter?: string;
    runtimeConfiguration?: boolean;
}

export interface GetMdbMongodbClusterClusterConfigMongodNet {
    maxIncomingConnections?: number;
}

export interface GetMdbMongodbClusterClusterConfigMongodOperationProfiling {
    mode?: string;
    slowOpThreshold?: number;
}

export interface GetMdbMongodbClusterClusterConfigMongodSecurity {
    /**
     * (Optional) Enables the encryption for the WiredTiger storage engine. Can be either true or false.
     * For more information see [security.enableEncryption](https://www.mongodb.com/docs/manual/reference/configuration-options/#mongodb-setting-security.enableEncryption)
     * description in the official documentation. Available only in enterprise edition.
     */
    enableEncryption?: boolean;
    /**
     * (Optional) Configuration of the third party key management appliance via the Key Management Interoperability Protocol (KMIP)
     * (see [Encryption tutorial](https://www.mongodb.com/docs/rapid/tutorial/configure-encryption) ). Requires `enableEncryption` to be true.
     * The structure is documented below. Available only in enterprise edition.
     */
    kmip: outputs.GetMdbMongodbClusterClusterConfigMongodSecurityKmip;
}

export interface GetMdbMongodbClusterClusterConfigMongodSecurityKmip {
    /**
     * (Required) String containing the client certificate used for authenticating MongoDB to the KMIP server.
     * For more information see [security.kmip.clientCertificateFile](https://www.mongodb.com/docs/manual/reference/configuration-options/#mongodb-setting-security.kmip.clientCertificateFile)
     * description in the official documentation.
     */
    clientCertificate?: string;
    /**
     * (Optional) Unique KMIP identifier for an existing key within the KMIP server.
     * For more information see [security.kmip.keyIdentifier](https://www.mongodb.com/docs/manual/reference/configuration-options/#mongodb-setting-security.kmip.keyIdentifier)
     * description in the official documentation.
     */
    keyIdentifier?: string;
    /**
     * (Optional) Port number to use to communicate with the KMIP server. Default: 5696
     * For more information see [security.kmip.port](https://www.mongodb.com/docs/manual/reference/configuration-options/#mongodb-setting-security.kmip.port)
     * description in the official documentation.
     */
    port?: number;
    /**
     * (Required) Path to CA File. Used for validating secure client connection to KMIP server.
     * For more information see [security.kmip.serverCAFile](https://www.mongodb.com/docs/manual/reference/configuration-options/#mongodb-setting-security.kmip.serverCAFile)
     * description in the official documentation.
     */
    serverCa?: string;
    /**
     * (Required) Hostname or IP address of the KMIP server to connect to.
     * For more information see [security.kmip.serverName](https://www.mongodb.com/docs/manual/reference/configuration-options/#mongodb-setting-security.kmip.serverName)
     * description in the official documentation.
     */
    serverName?: string;
}

export interface GetMdbMongodbClusterClusterConfigMongodSetParameter {
    /**
     * (Optional) Enables the auditing of authorization successes. Can be either true or false.
     * For more information, see the [auditAuthorizationSuccess](https://www.mongodb.com/docs/manual/reference/parameters/#mongodb-parameter-param.auditAuthorizationSuccess)
     * description in the official documentation. Available only in enterprise edition.
     */
    auditAuthorizationSuccess?: boolean;
}

export interface GetMdbMongodbClusterClusterConfigMongodStorage {
    journal?: outputs.GetMdbMongodbClusterClusterConfigMongodStorageJournal;
    wiredTiger?: outputs.GetMdbMongodbClusterClusterConfigMongodStorageWiredTiger;
}

export interface GetMdbMongodbClusterClusterConfigMongodStorageJournal {
    commitInterval?: number;
}

export interface GetMdbMongodbClusterClusterConfigMongodStorageWiredTiger {
    blockCompressor?: string;
    cacheSizeGb?: number;
}

export interface GetMdbMongodbClusterClusterConfigMongos {
    net?: outputs.GetMdbMongodbClusterClusterConfigMongosNet;
}

export interface GetMdbMongodbClusterClusterConfigMongosNet {
    maxIncomingConnections?: number;
}

export interface GetMdbMongodbClusterClusterConfigPerformanceDiagnostics {
    enabled?: boolean;
}

export interface GetMdbMongodbClusterDatabase {
    /**
     * The name of the MongoDB cluster.
     */
    name?: string;
}

export interface GetMdbMongodbClusterHost {
    /**
     * Has assigned public IP.
     */
    assignPublicIp: boolean;
    /**
     * The health of the host.
     */
    health: string;
    /**
     * The name of the MongoDB cluster.
     */
    name: string;
    /**
     * The role of the cluster (either PRIMARY or SECONDARY).
     */
    role: string;
    /**
     * The name of the shard to which the host belongs.
     */
    shardName: string;
    /**
     * The ID of the subnet, to which the host belongs. The subnet must
     * be a part of the network to which the cluster belongs.
     */
    subnetId?: string;
    /**
     * Type of maintenance window. Can be either `ANYTIME` or `WEEKLY`. A day and hour of window need to be specified with weekly window.
     */
    type?: string;
    /**
     * The availability zone where the MongoDB host will be created.
     */
    zoneId?: string;
}

export interface GetMdbMongodbClusterMaintenanceWindow {
    /**
     * Day of week for maintenance window if window type is weekly. Possible values: `MON`, `TUE`, `WED`, `THU`, `FRI`, `SAT`, `SUN`.
     */
    day?: string;
    /**
     * Hour of day in UTC time zone (1-24) for maintenance window if window type is weekly.
     */
    hour?: number;
    /**
     * Type of maintenance window. Can be either `ANYTIME` or `WEEKLY`. A day and hour of window need to be specified with weekly window.
     */
    type?: string;
}

export interface GetMdbMongodbClusterResources {
    /**
     * Volume of the storage available to a host, in gigabytes.
     */
    diskSize?: number;
    /**
     * The ID of the storage type. For more information, see [the official documentation](https://cloud.yandex.com/docs/managed-mongodb/concepts/storage)
     */
    diskTypeId?: string;
    resourcePresetId?: string;
}

export interface GetMdbMongodbClusterResourcesMongocfg {
    /**
     * Volume of the storage available to a host, in gigabytes.
     */
    diskSize?: number;
    /**
     * The ID of the storage type. For more information, see [the official documentation](https://cloud.yandex.com/docs/managed-mongodb/concepts/storage)
     */
    diskTypeId?: string;
    resourcePresetId?: string;
}

export interface GetMdbMongodbClusterResourcesMongod {
    /**
     * Volume of the storage available to a host, in gigabytes.
     */
    diskSize?: number;
    /**
     * The ID of the storage type. For more information, see [the official documentation](https://cloud.yandex.com/docs/managed-mongodb/concepts/storage)
     */
    diskTypeId?: string;
    resourcePresetId?: string;
}

export interface GetMdbMongodbClusterResourcesMongoinfra {
    /**
     * Volume of the storage available to a host, in gigabytes.
     */
    diskSize?: number;
    /**
     * The ID of the storage type. For more information, see [the official documentation](https://cloud.yandex.com/docs/managed-mongodb/concepts/storage)
     */
    diskTypeId?: string;
    resourcePresetId?: string;
}

export interface GetMdbMongodbClusterResourcesMongos {
    /**
     * Volume of the storage available to a host, in gigabytes.
     */
    diskSize?: number;
    /**
     * The ID of the storage type. For more information, see [the official documentation](https://cloud.yandex.com/docs/managed-mongodb/concepts/storage)
     */
    diskTypeId?: string;
    resourcePresetId?: string;
}

export interface GetMdbMongodbClusterRestore {
    backupId?: string;
    time?: string;
}

export interface GetMdbMongodbClusterUser {
    /**
     * The name of the MongoDB cluster.
     */
    name?: string;
    password?: string;
    /**
     * Set of permissions granted to the user. The structure is documented below.
     */
    permissions: outputs.GetMdbMongodbClusterUserPermission[];
}

export interface GetMdbMongodbClusterUserPermission {
    /**
     * The name of the database that the permission grants access to.
     */
    databaseName?: string;
    /**
     * (Optional) List of strings. The roles of the user in this database. For more information see [the official documentation](https://cloud.yandex.com/docs/managed-mongodb/concepts/users-and-roles).
     */
    roles?: string[];
}

export interface GetMdbMysqlClusterAccess {
    /**
     * Allow access for [Yandex DataLens](https://cloud.yandex.com/services/datalens).
     */
    dataLens: boolean;
    /**
     * (Optional) Allow access for [DataTransfer](https://cloud.yandex.com/services/data-transfer)
     */
    dataTransfer: boolean;
    /**
     * Allows access for [SQL queries in the management console](https://cloud.yandex.com/docs/managed-mysql/operations/web-sql-query).
     */
    webSql: boolean;
}

export interface GetMdbMysqlClusterBackupWindowStart {
    /**
     * The hour at which backup will be started.
     */
    hours?: number;
    /**
     * The minute at which backup will be started.
     */
    minutes?: number;
}

export interface GetMdbMysqlClusterDatabase {
    /**
     * The name of the MySQL cluster.
     */
    name: string;
}

export interface GetMdbMysqlClusterHost {
    /**
     * Sets whether the host should get a public IP address on creation. Changing this parameter for an existing host is not supported at the moment
     */
    assignPublicIp?: boolean;
    /**
     * Host backup priority. Value is between 0 and 100, default is 0.
     */
    backupPriority?: number;
    /**
     * The fully qualified domain name of the host.
     */
    fqdn: string;
    /**
     * Host master promotion priority. Value is between 0 and 100, default is 0.
     */
    priority?: number;
    /**
     * Host replication source (fqdn), case when replicationSource is empty then host in HA group.
     */
    replicationSource: string;
    /**
     * The ID of the subnet, to which the host belongs. The subnet must be a part of the network to which the cluster belongs.
     */
    subnetId: string;
    /**
     * The availability zone where the MySQL host will be created.
     */
    zone: string;
}

export interface GetMdbMysqlClusterMaintenanceWindow {
    /**
     * Day of the week (in `DDD` format). Value is one of: "MON", "TUE", "WED", "THU", "FRI", "SAT", "SUN"
     */
    day: string;
    /**
     * Hour of the day in UTC (in `HH` format). Value is between 1 and 24.
     */
    hour: number;
    /**
     * Type of maintenance window. Can be either `ANYTIME` or `WEEKLY`.
     */
    type: string;
}

export interface GetMdbMysqlClusterPerformanceDiagnostic {
    /**
     * Enable performance diagnostics
     */
    enabled: boolean;
    /**
     * Interval (in seconds) for myStatActivity sampling Acceptable values are 1 to 86400, inclusive.
     */
    sessionsSamplingInterval: number;
    /**
     * Interval (in seconds) for myStatStatements sampling Acceptable values are 1 to 86400, inclusive.
     */
    statementsSamplingInterval: number;
}

export interface GetMdbMysqlClusterResource {
    /**
     * Volume of the storage available to a MySQL host, in gigabytes.
     */
    diskSize: number;
    /**
     * Type of the storage for MySQL hosts.
     */
    diskTypeId: string;
    resourcePresetId: string;
}

export interface GetMdbMysqlClusterUser {
    /**
     * Authentication plugin. Allowed values: `MYSQL_NATIVE_PASSWORD`, `CACHING_SHA2_PASSWORD`, `SHA256_PASSWORD`
     */
    authenticationPlugin: string;
    /**
     * User's connection limits. The structure is documented below.
     */
    connectionLimits: outputs.GetMdbMysqlClusterUserConnectionLimit[];
    /**
     * List user's global permissions. Allowed values: `REPLICATION_CLIENT`, `REPLICATION_SLAVE`, `PROCESS` or empty list.
     */
    globalPermissions: string[];
    /**
     * The name of the MySQL cluster.
     */
    name: string;
    /**
     * The password of the user.
     */
    password: string;
    /**
     * Set of permissions granted to the user. The structure is documented below.
     */
    permissions: outputs.GetMdbMysqlClusterUserPermission[];
}

export interface GetMdbMysqlClusterUserConnectionLimit {
    /**
     * Max connections per hour.
     */
    maxConnectionsPerHour: number;
    /**
     * Max questions per hour.
     */
    maxQuestionsPerHour: number;
    /**
     * Max updates per hour.
     */
    maxUpdatesPerHour: number;
    /**
     * Max user connections.
     */
    maxUserConnections: number;
}

export interface GetMdbMysqlClusterUserPermission {
    /**
     * The name of the database that the permission grants access to.
     */
    databaseName: string;
    /**
     * List user's roles in the database.
     * Allowed roles: `ALL`,`ALTER`,`ALTER_ROUTINE`,`CREATE`,`CREATE_ROUTINE`,`CREATE_TEMPORARY_TABLES`,
     * `CREATE_VIEW`,`DELETE`,`DROP`,`EVENT`,`EXECUTE`,`INDEX`,`INSERT`,`LOCK_TABLES`,`SELECT`,`SHOW_VIEW`,`TRIGGER`,`UPDATE`.
     */
    roles?: string[];
}

export interface GetMdbMysqlUserConnectionLimit {
    /**
     * Max connections per hour.
     */
    maxConnectionsPerHour: number;
    /**
     * Max questions per hour.
     */
    maxQuestionsPerHour: number;
    /**
     * Max updates per hour.
     */
    maxUpdatesPerHour: number;
    /**
     * Max user connections.
     */
    maxUserConnections: number;
}

export interface GetMdbMysqlUserPermission {
    /**
     * The name of the database that the permission grants access to.
     */
    databaseName: string;
    /**
     * List user's roles in the database.
     * Allowed roles: `ALL`,`ALTER`,`ALTER_ROUTINE`,`CREATE`,`CREATE_ROUTINE`,`CREATE_TEMPORARY_TABLES`,
     * `CREATE_VIEW`,`DELETE`,`DROP`,`EVENT`,`EXECUTE`,`INDEX`,`INSERT`,`LOCK_TABLES`,`SELECT`,`SHOW_VIEW`,`TRIGGER`,`UPDATE`.
     */
    roles?: string[];
}

export interface GetMdbPostgresqlClusterConfig {
    /**
     * Access policy to the PostgreSQL cluster. The structure is documented below.
     */
    accesses: outputs.GetMdbPostgresqlClusterConfigAccess[];
    /**
     * Configuration setting which enables/disables autofailover in cluster.
     */
    autofailover: boolean;
    /**
     * The period in days during which backups are stored.
     */
    backupRetainPeriodDays: number;
    /**
     * Time to start the daily backup, in the UTC timezone. The structure is documented below.
     */
    backupWindowStarts: outputs.GetMdbPostgresqlClusterConfigBackupWindowStart[];
    /**
     * Cluster performance diagnostics settings. The structure is documented below. [YC Documentation](https://cloud.yandex.com/docs/managed-postgresql/api-ref/grpc/cluster_service#PerformanceDiagnostics)
     */
    performanceDiagnostics: outputs.GetMdbPostgresqlClusterConfigPerformanceDiagnostic[];
    /**
     * Configuration of the connection pooler. The structure is documented below.
     */
    poolerConfigs: outputs.GetMdbPostgresqlClusterConfigPoolerConfig[];
    /**
     * PostgreSQL cluster config.
     */
    postgresqlConfig: {[key: string]: string};
    /**
     * Resources allocated to hosts of the PostgreSQL cluster. The structure is documented below.
     */
    resources: outputs.GetMdbPostgresqlClusterConfigResource[];
    /**
     * Version of the extension.
     */
    version: string;
}

export interface GetMdbPostgresqlClusterConfigAccess {
    /**
     * Allow access for [Yandex DataLens](https://cloud.yandex.com/services/datalens).
     */
    dataLens: boolean;
    /**
     * (Optional) Allow access for [DataTransfer](https://cloud.yandex.com/services/data-transfer)
     */
    dataTransfer: boolean;
    /**
     * Allow access for [connection to managed databases from functions](https://cloud.yandex.com/docs/functions/operations/database-connection)
     */
    serverless: boolean;
    /**
     * Allow access for [SQL queries in the management console](https://cloud.yandex.com/docs/managed-postgresql/operations/web-sql-query)
     */
    webSql: boolean;
}

export interface GetMdbPostgresqlClusterConfigBackupWindowStart {
    /**
     * The hour at which backup will be started.
     */
    hours: number;
    /**
     * The minute at which backup will be started.
     */
    minutes: number;
}

export interface GetMdbPostgresqlClusterConfigPerformanceDiagnostic {
    /**
     * Flag, when true, performance diagnostics is enabled
     */
    enabled: boolean;
    /**
     * Interval (in seconds) for pgStatActivity sampling Acceptable values are 1 to 86400, inclusive.
     */
    sessionsSamplingInterval: number;
    /**
     * Interval (in seconds) for pgStatStatements sampling Acceptable values are 1 to 86400, inclusive.
     */
    statementsSamplingInterval: number;
}

export interface GetMdbPostgresqlClusterConfigPoolerConfig {
    /**
     * Value for `poolDiscard` [parameter in Odyssey](https://github.com/yandex/odyssey/blob/master/documentation/configuration.md#pool_discard-yesno).
     */
    poolDiscard: boolean;
    /**
     * Mode that the connection pooler is working in. See descriptions of all modes in the [documentation for Odyssey](https://github.com/yandex/odyssey/blob/master/documentation/configuration.md#pool-string.
     */
    poolingMode: string;
}

export interface GetMdbPostgresqlClusterConfigResource {
    /**
     * Volume of the storage available to a PostgreSQL host, in gigabytes.
     */
    diskSize: number;
    /**
     * Type of the storage for PostgreSQL hosts.
     */
    diskTypeId: string;
    resourcePresetId: string;
}

export interface GetMdbPostgresqlClusterDatabase {
    /**
     * Set of database extensions. The structure is documented below
     */
    extensions?: outputs.GetMdbPostgresqlClusterDatabaseExtension[];
    /**
     * POSIX locale for string sorting order. Forbidden to change in an existing database.
     */
    lcCollate?: string;
    /**
     * POSIX locale for character classification. Forbidden to change in an existing database.
     */
    lcType?: string;
    /**
     * The name of the PostgreSQL cluster.
     */
    name: string;
    /**
     * Name of the user assigned as the owner of the database.
     */
    owner: string;
    /**
     * Name of the template database.
     */
    templateDb?: string;
}

export interface GetMdbPostgresqlClusterDatabaseExtension {
    /**
     * The name of the PostgreSQL cluster.
     */
    name: string;
    /**
     * Version of the extension.
     */
    version?: string;
}

export interface GetMdbPostgresqlClusterHost {
    /**
     * Sets whether the host should get a public IP address on creation. Changing this parameter for an existing host is not supported at the moment.
     */
    assignPublicIp: boolean;
    /**
     * The fully qualified domain name of the host.
     */
    fqdn: string;
    /**
     * Host priority in HA group.
     */
    priority: number;
    /**
     * Host replication source (fqdn), case when replicationSource is empty then host in HA group.
     */
    replicationSource: string;
    /**
     * Role of the host in the cluster.
     */
    role: string;
    /**
     * The ID of the subnet, to which the host belongs. The subnet must be a part of the network to which the cluster belongs.
     */
    subnetId: string;
    /**
     * The availability zone where the PostgreSQL host will be created.
     */
    zone: string;
}

export interface GetMdbPostgresqlClusterMaintenanceWindow {
    /**
     * Day of the week (in `DDD` format). Value is one of: "MON", "TUE", "WED", "THU", "FRI", "SAT", "SUN"
     */
    day: string;
    /**
     * Hour of the day in UTC (in `HH` format). Value is between 1 and 24.
     */
    hour: number;
    /**
     * Type of maintenance window. Can be either `ANYTIME` or `WEEKLY`.
     */
    type: string;
}

export interface GetMdbPostgresqlClusterUser {
    /**
     * The maximum number of connections per user.
     */
    connLimit: number;
    /**
     * List of the user's grants.
     */
    grants: string[];
    /**
     * User's ability to login.
     */
    login?: boolean;
    /**
     * The name of the PostgreSQL cluster.
     */
    name: string;
    /**
     * Set of permissions granted to the user. The structure is documented below.
     */
    permissions: outputs.GetMdbPostgresqlClusterUserPermission[];
    /**
     * Map of user settings. The structure is documented below.
     */
    settings: {[key: string]: string};
}

export interface GetMdbPostgresqlClusterUserPermission {
    /**
     * The name of the database that the permission grants access to.
     */
    databaseName: string;
}

export interface GetMdbPostgresqlDatabaseExtension {
    /**
     * The name of the PostgreSQL cluster.
     */
    name: string;
    /**
     * Version of the extension.
     */
    version?: string;
}

export interface GetMdbPostgresqlUserPermission {
    /**
     * The name of the database that the permission grants access to.
     */
    databaseName: string;
}

export interface GetMdbRedisClusterConfig {
    /**
     * Normal clients output buffer limits.
     */
    clientOutputBufferLimitNormal: string;
    /**
     * Pubsub clients output buffer limits.
     */
    clientOutputBufferLimitPubsub: string;
    /**
     * Number of databases (changing requires redis-server restart).
     */
    databases: number;
    /**
     * Redis maxmemory usage in percent
     */
    maxmemoryPercent: number;
    /**
     * Redis key eviction policy for a dataset that reaches maximum memory.
     */
    maxmemoryPolicy: string;
    /**
     * Select the events that Redis will notify among a set of classes.
     */
    notifyKeyspaceEvents: string;
    /**
     * Log slow queries below this number in microseconds.
     */
    slowlogLogSlowerThan: number;
    /**
     * Slow queries log length.
     */
    slowlogMaxLen: number;
    /**
     * Close the connection after a client is idle for N seconds.
     */
    timeout: number;
    /**
     * Version of Redis (6.2).
     */
    version: string;
}

export interface GetMdbRedisClusterHost {
    /**
     * Sets whether the host should get a public IP address or not.
     */
    assignPublicIp?: boolean;
    /**
     * The fully qualified domain name of the host.
     */
    fqdn: string;
    /**
     * Replica priority of a current replica (usable for non-sharded only).
     */
    replicaPriority?: number;
    /**
     * The name of the shard to which the host belongs.
     */
    shardName: string;
    /**
     * The ID of the subnet, to which the host belongs. The subnet must
     * be a part of the network to which the cluster belongs.
     */
    subnetId: string;
    /**
     * The availability zone where the Redis host will be created.
     */
    zone: string;
}

export interface GetMdbRedisClusterMaintenanceWindow {
    /**
     * Day of week for maintenance window if window type is weekly. Possible values: `MON`, `TUE`, `WED`, `THU`, `FRI`, `SAT`, `SUN`.
     */
    day: string;
    /**
     * Hour of day in UTC time zone (1-24) for maintenance window if window type is weekly.
     */
    hour: number;
    /**
     * Type of maintenance window. Can be either `ANYTIME` or `WEEKLY`. A day and hour of window need to be specified with weekly window.
     */
    type: string;
}

export interface GetMdbRedisClusterResource {
    /**
     * Volume of the storage available to a host, in gigabytes.
     */
    diskSize: number;
    /**
     * Type of the storage of a host.
     */
    diskTypeId: string;
    resourcePresetId: string;
}

export interface GetMdbSqlserverClusterBackupWindowStart {
    /**
     * The hour at which backup will be started.
     */
    hours: number;
    /**
     * The minute at which backup will be started.
     */
    minutes: number;
}

export interface GetMdbSqlserverClusterDatabase {
    /**
     * The name of the SQLServer cluster.
     */
    name: string;
}

export interface GetMdbSqlserverClusterHost {
    /**
     * Sets whether the host should get a public IP address on creation. Changing this parameter for an existing host is not supported at the moment
     */
    assignPublicIp: boolean;
    /**
     * The fully qualified domain name of the host.
     */
    fqdn: string;
    /**
     * The ID of the subnet, to which the host belongs. The subnet must be a part of the network to which the cluster belongs.
     */
    subnetId: string;
    /**
     * The availability zone where the SQLServer host will be created.
     */
    zone: string;
}

export interface GetMdbSqlserverClusterResource {
    /**
     * Volume of the storage available to a SQLServer host, in gigabytes.
     */
    diskSize: number;
    /**
     * Type of the storage for SQLServer hosts.
     */
    diskTypeId: string;
    resourcePresetId: string;
}

export interface GetMdbSqlserverClusterUser {
    /**
     * The name of the SQLServer cluster.
     */
    name: string;
    /**
     * The password of the user.
     */
    password: string;
    /**
     * Set of permissions granted to the user. The structure is documented below.
     */
    permissions: outputs.GetMdbSqlserverClusterUserPermission[];
}

export interface GetMdbSqlserverClusterUserPermission {
    /**
     * The name of the database that the permission grants access to.
     */
    databaseName: string;
    /**
     * List user's roles in the database.
     * Allowed roles: `OWNER`, `SECURITYADMIN`, `ACCESSADMIN`, `BACKUPOPERATOR`, `DDLADMIN`, `DATAWRITER`, `DATAREADER`, `DENYDATAWRITER`, `DENYDATAREADER`.
     */
    roles: string[];
}

export interface GetMonitoringDashboardParametrization {
    /**
     * parameters list.
     */
    parameters: outputs.GetMonitoringDashboardParametrizationParameter[];
    /**
     * Selectors to select metric label values.
     */
    selectors: string;
}

export interface GetMonitoringDashboardParametrizationParameter {
    /**
     * Custom values parameter.
     */
    customs: outputs.GetMonitoringDashboardParametrizationParameterCustom[];
    /**
     * Chart description in dashboard (not enabled in UI).
     */
    description: string;
    /**
     * Checks that target is visible or invisible.
     */
    hidden: boolean;
    /**
     * Parameter identifier
     */
    id: string;
    /**
     * Label values parameter.
     */
    labelValues: outputs.GetMonitoringDashboardParametrizationParameterLabelValue[];
    /**
     * Title text.
     */
    texts: outputs.GetMonitoringDashboardParametrizationParameterText[];
    /**
     * Inside chart title.
     */
    title: string;
}

export interface GetMonitoringDashboardParametrizationParameterCustom {
    /**
     * Default value.
     */
    defaultValues: string[];
    /**
     * Specifies the multiselectable values of parameter.
     */
    multiselectable: boolean;
    /**
     * Parameter values.
     */
    values: string[];
}

export interface GetMonitoringDashboardParametrizationParameterLabelValue {
    /**
     * Default value.
     */
    defaultValues: string[];
    /**
     * Folder that the resource belongs to. If value is omitted, the default provider folder is used.
     */
    folderId: string;
    /**
     * Label key to list label values.
     */
    labelKey: string;
    /**
     * Specifies the multiselectable values of parameter.
     */
    multiselectable: boolean;
    /**
     * Selectors to select metric label values.
     */
    selectors: string;
}

export interface GetMonitoringDashboardParametrizationParameterText {
    /**
     * Default value.
     */
    defaultValue: string;
}

export interface GetMonitoringDashboardWidget {
    /**
     * Chart widget settings.
     */
    charts: outputs.GetMonitoringDashboardWidgetChart[];
    /**
     * Widget position.
     */
    positions: outputs.GetMonitoringDashboardWidgetPosition[];
    /**
     * Title text.
     */
    texts: outputs.GetMonitoringDashboardWidgetText[];
    /**
     * Inside chart title.
     */
    titles: outputs.GetMonitoringDashboardWidgetTitle[];
}

export interface GetMonitoringDashboardWidgetChart {
    /**
     * Chart ID.
     */
    chartId: string;
    /**
     * Chart description in dashboard (not enabled in UI).
     */
    description: string;
    /**
     * Enable legend under chart.
     */
    displayLegend: boolean;
    /**
     * Fixed time interval for chart.
     */
    freeze: string;
    /**
     * Names settings.
     */
    nameHidingSettings: outputs.GetMonitoringDashboardWidgetChartNameHidingSetting[];
    /**
     * Queries settings.
     * * `seriesOverrides` Time series settings.
     */
    queries: outputs.GetMonitoringDashboardWidgetChartQuery[];
    seriesOverrides: outputs.GetMonitoringDashboardWidgetChartSeriesOverride[];
    /**
     * Inside chart title.
     */
    title: string;
    /**
     * Visualization settings.
     */
    visualizationSettings: outputs.GetMonitoringDashboardWidgetChartVisualizationSetting[];
}

export interface GetMonitoringDashboardWidgetChartNameHidingSetting {
    /**
     * Series name.
     */
    names: string[];
    /**
     * True if we want to show concrete series names only, false if we want to hide concrete series names.
     */
    positive: boolean;
}

export interface GetMonitoringDashboardWidgetChartQuery {
    /**
     * Downsamplang settings.
     */
    downsamplings: outputs.GetMonitoringDashboardWidgetChartQueryDownsampling[];
    /**
     * Query targets.
     */
    targets: outputs.GetMonitoringDashboardWidgetChartQueryTarget[];
}

export interface GetMonitoringDashboardWidgetChartQueryDownsampling {
    /**
     * Disable downsampling.
     */
    disabled: boolean;
    /**
     * Parameters for filling gaps in data.
     */
    gapFilling: string;
    /**
     * Function that is used for downsampling.
     */
    gridAggregation: string;
    /**
     * Time interval (grid) for downsampling in milliseconds. Points in the specified range are aggregated into one time point
     */
    gridInterval: number;
    /**
     * Maximum number of points to be returned.
     */
    maxPoints: number;
}

export interface GetMonitoringDashboardWidgetChartQueryTarget {
    /**
     * Checks that target is visible or invisible.
     */
    hidden: boolean;
    /**
     * Query.
     */
    query: string;
    /**
     * Text mode enabled.
     */
    textMode: boolean;
}

export interface GetMonitoringDashboardWidgetChartSeriesOverride {
    /**
     * - Name of the Dashboard.
     */
    name: string;
    /**
     * Override settings.
     */
    settings: outputs.GetMonitoringDashboardWidgetChartSeriesOverrideSetting[];
    /**
     * Series index.
     */
    targetIndex: string;
}

export interface GetMonitoringDashboardWidgetChartSeriesOverrideSetting {
    /**
     * Series color or empty.
     */
    color: string;
    /**
     * Stack grow down.
     */
    growDown: boolean;
    /**
     * - Name of the Dashboard.
     */
    name: string;
    /**
     * Stack name or empty.
     */
    stackName: string;
    /**
     * Type.
     */
    type: string;
    /**
     * Yaxis positio
     */
    yaxisPosition: string;
}

export interface GetMonitoringDashboardWidgetChartVisualizationSetting {
    /**
     * Aggregation.
     */
    aggregation: string;
    /**
     * Color settings.
     */
    colorSchemeSettings: outputs.GetMonitoringDashboardWidgetChartVisualizationSettingColorSchemeSetting[];
    /**
     * Heatmap settings.
     */
    heatmapSettings: outputs.GetMonitoringDashboardWidgetChartVisualizationSettingHeatmapSetting[];
    /**
     * Interpolate values.
     */
    interpolate: string;
    /**
     * Normalize values.
     */
    normalize: boolean;
    /**
     * Show chart labels.
     */
    showLabels: boolean;
    /**
     * Inside chart title.
     */
    title: string;
    /**
     * Type.
     */
    type: string;
    /**
     * Y axis settings.
     */
    yaxisSettings: outputs.GetMonitoringDashboardWidgetChartVisualizationSettingYaxisSetting[];
}

export interface GetMonitoringDashboardWidgetChartVisualizationSettingColorSchemeSetting {
    /**
     * Automatic color scheme.
     */
    automatics: outputs.GetMonitoringDashboardWidgetChartVisualizationSettingColorSchemeSettingAutomatic[];
    /**
     * Gradient color scheme.
     */
    gradients: outputs.GetMonitoringDashboardWidgetChartVisualizationSettingColorSchemeSettingGradient[];
    /**
     * Standard color scheme.
     */
    standards: outputs.GetMonitoringDashboardWidgetChartVisualizationSettingColorSchemeSettingStandard[];
}

export interface GetMonitoringDashboardWidgetChartVisualizationSettingColorSchemeSettingAutomatic {
}

export interface GetMonitoringDashboardWidgetChartVisualizationSettingColorSchemeSettingGradient {
    /**
     * Heatmap green value.
     */
    greenValue: string;
    /**
     * Heatmap red value.
     */
    redValue: string;
    /**
     * Heatmap violet value.
     */
    violetValue: string;
    /**
     * Heatmap yellow value.
     */
    yellowValue: string;
}

export interface GetMonitoringDashboardWidgetChartVisualizationSettingColorSchemeSettingStandard {
}

export interface GetMonitoringDashboardWidgetChartVisualizationSettingHeatmapSetting {
    /**
     * Heatmap green value.
     */
    greenValue: string;
    /**
     * Heatmap red value.
     */
    redValue: string;
    /**
     * Heatmap violet value.
     */
    violetValue: string;
    /**
     * Heatmap yellow value.
     */
    yellowValue: string;
}

export interface GetMonitoringDashboardWidgetChartVisualizationSettingYaxisSetting {
    /**
     * Left yaxis config.
     * * `right` Right yaxis config.
     */
    lefts: outputs.GetMonitoringDashboardWidgetChartVisualizationSettingYaxisSettingLeft[];
    rights: outputs.GetMonitoringDashboardWidgetChartVisualizationSettingYaxisSettingRight[];
}

export interface GetMonitoringDashboardWidgetChartVisualizationSettingYaxisSettingLeft {
    /**
     * Max value in extended number format or empty.
     */
    max: string;
    /**
     * Min value in extended number format or empty.
     */
    min: string;
    /**
     * Tick value precision (null as default, 0-7 in other cases).
     * * `title` -Title or empty.
     */
    precision: number;
    /**
     * Inside chart title.
     */
    title: string;
    /**
     * Type.
     */
    type: string;
    /**
     * Unit format.
     */
    unitFormat: string;
}

export interface GetMonitoringDashboardWidgetChartVisualizationSettingYaxisSettingRight {
    /**
     * Max value in extended number format or empty.
     */
    max: string;
    /**
     * Min value in extended number format or empty.
     */
    min: string;
    /**
     * Tick value precision (null as default, 0-7 in other cases).
     * * `title` -Title or empty.
     */
    precision: number;
    /**
     * Inside chart title.
     */
    title: string;
    /**
     * Type.
     */
    type: string;
    /**
     * Unit format.
     */
    unitFormat: string;
}

export interface GetMonitoringDashboardWidgetPosition {
    /**
     * Height.
     */
    h: number;
    /**
     * Width.
     */
    w: number;
    /**
     * X-axis top-left corner coordinate.
     */
    x: number;
    /**
     * Y-axis top-left corner coordinate.
     */
    y: number;
}

export interface GetMonitoringDashboardWidgetText {
    /**
     * Title text.
     */
    text: string;
}

export interface GetMonitoringDashboardWidgetTitle {
    /**
     * Title size.
     */
    size: string;
    /**
     * Title text.
     */
    text: string;
}

export interface GetOrganizationmanagerGroupMember {
    /**
     * The ID of the member.
     */
    id: string;
    /**
     * The type of the member.
     */
    type: string;
}

export interface GetOrganizationmanagerSamlFederationSecuritySetting {
    /**
     * Indicates whether encrypted assertions are enabled.
     */
    encryptedAssertions: boolean;
}

export interface GetServerlessContainerConnectivity {
    networkId: string;
}

export interface GetServerlessContainerImage {
    args: string[];
    commands: string[];
    digest: string;
    environment: {[key: string]: string};
    /**
     * Invoke URL of the Yandex Cloud Serverless Container
     */
    url: string;
    workDir: string;
}

export interface GetServerlessContainerSecret {
    environmentVariable: string;
    id: string;
    key: string;
    versionId: string;
}

export interface GetVpcAddressExternalIpv4Address {
    /**
     * IP address.
     */
    address: string;
    /**
     * DDOS protection provider.
     */
    ddosProtectionProvider: string;
    /**
     * Outgoing smtp capability.
     */
    outgoingSmtpCapability: string;
    /**
     * Zone for allocating address.
     */
    zoneId: string;
}

export interface GetVpcGatewaySharedEgressGateway {
}

export interface GetVpcRouteTableStaticRoute {
    /**
     * Route prefix in CIDR notation.
     */
    destinationPrefix: string;
    /**
     * ID of the gateway used as next hop.
     */
    gatewayId: string;
    /**
     * Address of the next hop.
     */
    nextHopAddress: string;
}

export interface GetVpcSecurityGroupEgress {
    /**
     * Description of the rule.
     */
    description: string;
    /**
     * Minimum port number.
     */
    fromPort: number;
    /**
     * Id of the rule.
     */
    id: string;
    /**
     * Labels to assign to this rule.
     */
    labels: {[key: string]: string};
    /**
     * Port number (if applied to a single port).
     */
    port: number;
    /**
     * Special-purpose targets. `selfSecurityGroup` refers to this particular security group. `loadbalancerHealthchecks` represents [loadbalancer health check nodes](https://cloud.yandex.com/docs/network-load-balancer/concepts/health-check).
     */
    predefinedTarget: string;
    /**
     * One of `ANY`, `TCP`, `UDP`, `ICMP`, `IPV6_ICMP`.
     */
    protocol: string;
    /**
     * Security Group ID.
     */
    securityGroupId: string;
    /**
     * Maximum port number.
     */
    toPort: number;
    /**
     * The blocks of  IPv4 addresses for this rule.
     */
    v4CidrBlocks: string[];
    /**
     * The blocks of  IPv6 addresses for this rule.
     */
    v6CidrBlocks: string[];
}

export interface GetVpcSecurityGroupIngress {
    /**
     * Description of the rule.
     */
    description: string;
    /**
     * Minimum port number.
     */
    fromPort: number;
    /**
     * Id of the rule.
     */
    id: string;
    /**
     * Labels to assign to this rule.
     */
    labels: {[key: string]: string};
    /**
     * Port number (if applied to a single port).
     */
    port: number;
    /**
     * Special-purpose targets. `selfSecurityGroup` refers to this particular security group. `loadbalancerHealthchecks` represents [loadbalancer health check nodes](https://cloud.yandex.com/docs/network-load-balancer/concepts/health-check).
     */
    predefinedTarget: string;
    /**
     * One of `ANY`, `TCP`, `UDP`, `ICMP`, `IPV6_ICMP`.
     */
    protocol: string;
    /**
     * Security Group ID.
     */
    securityGroupId: string;
    /**
     * Maximum port number.
     */
    toPort: number;
    /**
     * The blocks of  IPv4 addresses for this rule.
     */
    v4CidrBlocks: string[];
    /**
     * The blocks of  IPv6 addresses for this rule.
     */
    v6CidrBlocks: string[];
}

export interface GetVpcSubnetDhcpOption {
    /**
     * Domain name.
     */
    domainName: string;
    /**
     * Domain name server IP addresses.
     */
    domainNameServers: string[];
    /**
     * NTP server IP addresses.
     */
    ntpServers: string[];
}

export interface GetYdbDatabaseDedicatedLocation {
    /**
     * Region of the Yandex Database cluster.
     * The structure is documented below.
     */
    regions: outputs.GetYdbDatabaseDedicatedLocationRegion[];
    zones: outputs.GetYdbDatabaseDedicatedLocationZone[];
}

export interface GetYdbDatabaseDedicatedLocationRegion {
    /**
     * Region ID of the Yandex Database cluster.
     */
    id: string;
}

export interface GetYdbDatabaseDedicatedLocationZone {
    /**
     * Region ID of the Yandex Database cluster.
     */
    id: string;
}

export interface GetYdbDatabaseDedicatedScalePolicy {
    /**
     * Fixed scaling policy of the Yandex Database cluster.
     * The structure is documented below.
     */
    fixedScales: outputs.GetYdbDatabaseDedicatedScalePolicyFixedScale[];
}

export interface GetYdbDatabaseDedicatedScalePolicyFixedScale {
    /**
     * Number of instances in the Yandex Database cluster.
     */
    size: number;
}

export interface GetYdbDatabaseDedicatedStorageConfig {
    /**
     * Amount of storage groups of selected type in the Yandex Database cluster.
     */
    groupCount: number;
    /**
     * Storage type ID of the Yandex Database cluster.
     */
    storageTypeId: string;
}

export interface GetYdbDatabaseServerlessServerlessDatabase {
    enableThrottlingRcuLimit: boolean;
    provisionedRcuLimit: number;
    storageSizeLimit: number;
    throttlingRcuLimit: number;
}

export interface KubernetesClusterKmsProvider {
    /**
     * KMS key ID.
     */
    keyId?: string;
}

export interface KubernetesClusterMaster {
    /**
     * (Computed) PEM-encoded public certificate that is the root of trust for the Kubernetes cluster.
     */
    clusterCaCertificate: string;
    /**
     * (Computed) An IPv4 external network address that is assigned to the master.
     */
    externalV4Address: string;
    /**
     * (Computed) External endpoint that can be used to access Kubernetes cluster API from the internet (outside of the cloud).
     */
    externalV4Endpoint: string;
    externalV6Address?: string;
    externalV6Endpoint: string;
    /**
     * (Computed) An IPv4 internal network address that is assigned to the master.
     */
    internalV4Address: string;
    /**
     * (Computed) Internal endpoint that can be used to connect to the master from cloud networks.
     */
    internalV4Endpoint: string;
    /**
     * (Optional) (Computed) Maintenance policy for Kubernetes master.
     * If policy is omitted, automatic revision upgrades of the kubernetes master are enabled and could happen at any time.
     * Revision upgrades are performed only within the same minor version, e.g. 1.13.
     * Minor version upgrades (e.g. 1.13->1.14) should be performed manually. The structure is documented below.
     */
    maintenancePolicy: outputs.KubernetesClusterMasterMaintenancePolicy;
    /**
     * (Optional) Master Logging options. The structure is documented below.
     */
    masterLogging?: outputs.KubernetesClusterMasterMasterLogging;
    /**
     * (Optional) (Computed) Boolean flag. When `true`, Kubernetes master will have visible ipv4 address.
     */
    publicIp: boolean;
    /**
     * (Optional) Initialize parameters for Regional Master (highly available master). The structure is documented below.
     */
    regional: outputs.KubernetesClusterMasterRegional;
    /**
     * (Optional) List of security group IDs to which the Kubernetes cluster belongs.
     */
    securityGroupIds?: string[];
    /**
     * (Optional) (Computed) Version of Kubernetes that will be used for master.
     */
    version: string;
    /**
     * (Computed) Information about cluster version. The structure is documented below.
     */
    versionInfos: outputs.KubernetesClusterMasterVersionInfo[];
    /**
     * (Optional) Initialize parameters for Zonal Master (single node master). The structure is documented below.
     */
    zonal: outputs.KubernetesClusterMasterZonal;
}

export interface KubernetesClusterMasterMaintenancePolicy {
    /**
     * (Required) Boolean flag that specifies if master can be upgraded automatically. When omitted, default value is TRUE.
     */
    autoUpgrade: boolean;
    /**
     * (Optional) (Computed) This structure specifies maintenance window, when update for master is allowed. When omitted, it defaults to any time.
     * To specify time of day interval, for all days, one element should be provided, with two fields set, `startTime` and `duration`.
     * Please see `zonalClusterResourceName` config example.
     */
    maintenanceWindows?: outputs.KubernetesClusterMasterMaintenancePolicyMaintenanceWindow[];
}

export interface KubernetesClusterMasterMaintenancePolicyMaintenanceWindow {
    day: string;
    duration: string;
    startTime: string;
}

export interface KubernetesClusterMasterMasterLogging {
    /**
     * (Optional) Boolean flag that specifies if kube-apiserver audit logs should be sent to Yandex Cloud Logging.
     */
    auditEnabled?: boolean;
    /**
     * (Optional) Boolean flag that specifies if cluster-autoscaler logs should be sent to Yandex Cloud Logging.
     */
    clusterAutoscalerEnabled?: boolean;
    /**
     * (Optional) Boolean flag that specifies if master components logs should be sent to [Yandex Cloud Logging](https://cloud.yandex.com/docs/logging/). The exact components that will send their logs must be configured via the options described below.
     */
    enabled?: boolean;
    /**
     * (Optional) Boolean flag that specifies if kubernetes cluster events should be sent to Yandex Cloud Logging.
     */
    eventsEnabled?: boolean;
    /**
     * The ID of the folder that the Kubernetes cluster belongs to.
     * If it is not provided, the default provider folder is used.
     */
    folderId?: string;
    /**
     * (Optional) Boolean flag that specifies if kube-apiserver logs should be sent to Yandex Cloud Logging.
     */
    kubeApiserverEnabled?: boolean;
    /**
     * (Optional) ID of the Yandex Cloud Logging [Log group](https://cloud.yandex.com/docs/logging/concepts/log-group).
     */
    logGroupId?: string;
}

export interface KubernetesClusterMasterRegional {
    /**
     * Array of locations, where master instances will be allocated. The structure is documented below.
     */
    locations: outputs.KubernetesClusterMasterRegionalLocation[];
    /**
     * (Required) Name of availability region (e.g. "ru-central1"), where master instances will be allocated.
     */
    region: string;
}

export interface KubernetesClusterMasterRegionalLocation {
    /**
     * (Optional) ID of the subnet.
     */
    subnetId?: string;
    /**
     * (Optional) ID of the availability zone.
     */
    zone?: string;
}

export interface KubernetesClusterMasterVersionInfo {
    /**
     * Current Kubernetes version, major.minor (e.g. 1.15).
     */
    currentVersion: string;
    /**
     * Boolean flag.
     * Newer revisions may include Kubernetes patches (e.g 1.15.1 > 1.15.2) as well
     * as some internal component updates - new features or bug fixes in yandex-specific
     * components either on the master or nodes.
     */
    newRevisionAvailable: boolean;
    /**
     * Human readable description of the changes to be applied
     * when updating to the latest revision. Empty if newRevisionAvailable is false.
     */
    newRevisionSummary: string;
    /**
     * Boolean flag. The current version is on the deprecation schedule,
     * component (master or node group) should be upgraded.
     */
    versionDeprecated: boolean;
}

export interface KubernetesClusterMasterZonal {
    /**
     * (Optional) ID of the subnet.
     */
    subnetId?: string;
    /**
     * (Optional) ID of the availability zone.
     */
    zone: string;
}

export interface KubernetesClusterNetworkImplementation {
    /**
     * (Optional) Cilium network implementation configuration. No options exist.
     */
    cilium?: outputs.KubernetesClusterNetworkImplementationCilium;
}

export interface KubernetesClusterNetworkImplementationCilium {
}

export interface KubernetesNodeGroupAllocationPolicy {
    /**
     * Repeated field, that specify subnets (zones), that will be used by node group compute instances. The structure is documented below.
     */
    locations: outputs.KubernetesNodeGroupAllocationPolicyLocation[];
}

export interface KubernetesNodeGroupAllocationPolicyLocation {
    /**
     * ID of the subnet, that will be used by one compute instance in node group.
     *
     * @deprecated The 'subnet_id' field has been deprecated. Please use 'subnet_ids under network_interface' instead.
     */
    subnetId: string;
    /**
     * ID of the availability zone where for one compute instance in node group.
     */
    zone: string;
}

export interface KubernetesNodeGroupDeployPolicy {
    /**
     * The maximum number of instances that can be temporarily allocated above the group's target size during the update.
     */
    maxExpansion: number;
    /**
     * The maximum number of running instances that can be taken offline during update.
     */
    maxUnavailable: number;
}

export interface KubernetesNodeGroupInstanceTemplate {
    /**
     * The specifications for boot disks that will be attached to the instance. The structure is documented below.
     */
    bootDisk: outputs.KubernetesNodeGroupInstanceTemplateBootDisk;
    /**
     * Container network configuration. The structure is documented below.
     */
    containerNetwork: outputs.KubernetesNodeGroupInstanceTemplateContainerNetwork;
    /**
     * Container runtime configuration. The structure is documented below.
     */
    containerRuntime: outputs.KubernetesNodeGroupInstanceTemplateContainerRuntime;
    /**
     * GPU settings. The structure is documented below.
     * ---
     */
    gpuSettings: outputs.KubernetesNodeGroupInstanceTemplateGpuSettings;
    /**
     * Labels that will be assigned to compute nodes (instances), created by the Node Group.
     */
    labels?: {[key: string]: string};
    /**
     * The set of metadata `key:value` pairs assigned to this instance template. This includes custom metadata and predefined keys. **Note**: key "user-data" won't be provided into instances. It reserved for internal activity in `kubernetesNodeGroup` resource.
     */
    metadata: {[key: string]: string};
    /**
     * Name template of the instance.
     * In order to be unique it must contain at least one of instance unique placeholders:
     * {instance.short_id}
     * {instance.index}
     * combination of {instance.zone_id} and {instance.index_in_zone}
     * Example: my-instance-{instance.index}
     * If not set, default is used: {instance_group.id}-{instance.short_id}
     * It may also contain another placeholders, see [Compute Instance group metadata doc](https://cloud.yandex.com/en-ru/docs/compute/api-ref/grpc/instance_group_service) for full list.
     */
    name?: string;
    /**
     * A public address that can be used to access the internet over NAT.
     *
     * @deprecated The 'nat' field has been deprecated. Please use 'nat under network_interface' instead.
     */
    nat: boolean;
    /**
     * Type of network acceleration. Values: `standard`, `softwareAccelerated`.
     */
    networkAccelerationType: string;
    /**
     * An array with the network interfaces that will be attached to the instance. The structure is documented below.
     */
    networkInterfaces: outputs.KubernetesNodeGroupInstanceTemplateNetworkInterface[];
    /**
     * The placement policy configuration. The structure is documented below.
     */
    placementPolicy?: outputs.KubernetesNodeGroupInstanceTemplatePlacementPolicy;
    /**
     * The ID of the hardware platform configuration for the node group compute instances.
     */
    platformId: string;
    resources: outputs.KubernetesNodeGroupInstanceTemplateResources;
    /**
     * The scheduling policy for the instances in node group. The structure is documented below.
     */
    schedulingPolicy: outputs.KubernetesNodeGroupInstanceTemplateSchedulingPolicy;
}

export interface KubernetesNodeGroupInstanceTemplateBootDisk {
    /**
     * The number of instances in the node group.
     */
    size: number;
    /**
     * Type of container runtime. Values: `docker`, `containerd`.
     */
    type: string;
}

export interface KubernetesNodeGroupInstanceTemplateContainerNetwork {
    /**
     * MTU for pods.
     */
    podMtu: number;
}

export interface KubernetesNodeGroupInstanceTemplateContainerRuntime {
    /**
     * Type of container runtime. Values: `docker`, `containerd`.
     */
    type: string;
}

export interface KubernetesNodeGroupInstanceTemplateGpuSettings {
    /**
     * GPU cluster id.
     */
    gpuClusterId?: string;
    /**
     * GPU environment. Values: `runc`, `runcDriversCuda`.
     */
    gpuEnvironment: string;
}

export interface KubernetesNodeGroupInstanceTemplateNetworkInterface {
    /**
     * Allocate an IPv4 address for the interface. The default value is `true`.
     */
    ipv4?: boolean;
    /**
     * List of configurations for creating ipv4 DNS records. The structure is documented below.
     */
    ipv4DnsRecords?: outputs.KubernetesNodeGroupInstanceTemplateNetworkInterfaceIpv4DnsRecord[];
    /**
     * If true, allocate an IPv6 address for the interface. The address will be automatically assigned from the specified subnet.
     */
    ipv6: boolean;
    /**
     * List of configurations for creating ipv6 DNS records. The structure is documented below.
     */
    ipv6DnsRecords?: outputs.KubernetesNodeGroupInstanceTemplateNetworkInterfaceIpv6DnsRecord[];
    /**
     * A public address that can be used to access the internet over NAT.
     */
    nat: boolean;
    /**
     * Security group ids for network interface.
     */
    securityGroupIds?: string[];
    /**
     * The IDs of the subnets.
     */
    subnetIds: string[];
}

export interface KubernetesNodeGroupInstanceTemplateNetworkInterfaceIpv4DnsRecord {
    /**
     * DNS zone ID (if not set, private zone is used).
     */
    dnsZoneId?: string;
    /**
     * DNS record FQDN.
     */
    fqdn: string;
    /**
     * When set to true, also create a PTR DNS record.
     */
    ptr?: boolean;
    /**
     * DNS record TTL (in seconds).
     */
    ttl?: number;
}

export interface KubernetesNodeGroupInstanceTemplateNetworkInterfaceIpv6DnsRecord {
    /**
     * DNS zone ID (if not set, private zone is used).
     */
    dnsZoneId?: string;
    /**
     * DNS record FQDN.
     */
    fqdn: string;
    /**
     * When set to true, also create a PTR DNS record.
     */
    ptr?: boolean;
    /**
     * DNS record TTL (in seconds).
     */
    ttl?: number;
}

export interface KubernetesNodeGroupInstanceTemplatePlacementPolicy {
    /**
     * Specifies the id of the Placement Group to assign to the instances.
     */
    placementGroupId: string;
}

export interface KubernetesNodeGroupInstanceTemplateResources {
    coreFraction: number;
    cores: number;
    gpus?: number;
    memory: number;
}

export interface KubernetesNodeGroupInstanceTemplateSchedulingPolicy {
    /**
     * Specifies if the instance is preemptible. Defaults to false.
     * ---
     */
    preemptible: boolean;
}

export interface KubernetesNodeGroupMaintenancePolicy {
    /**
     * Boolean flag that specifies if node group can be repaired automatically. When omitted, default value is TRUE.
     */
    autoRepair: boolean;
    /**
     * Boolean flag that specifies if node group can be upgraded automatically. When omitted, default value is TRUE.
     */
    autoUpgrade: boolean;
    /**
     * (Computed) Set of day intervals, when maintenance is allowed for this node group. When omitted, it defaults to any time.
     */
    maintenanceWindows?: outputs.KubernetesNodeGroupMaintenancePolicyMaintenanceWindow[];
}

export interface KubernetesNodeGroupMaintenancePolicyMaintenanceWindow {
    day: string;
    duration: string;
    startTime: string;
}

export interface KubernetesNodeGroupScalePolicy {
    /**
     * Scale policy for an autoscaled node group. The structure is documented below.
     */
    autoScale?: outputs.KubernetesNodeGroupScalePolicyAutoScale;
    /**
     * Scale policy for a fixed scale node group. The structure is documented below.
     */
    fixedScale?: outputs.KubernetesNodeGroupScalePolicyFixedScale;
}

export interface KubernetesNodeGroupScalePolicyAutoScale {
    /**
     * Initial number of instances in the node group.
     */
    initial: number;
    /**
     * Maximum number of instances in the node group.
     */
    max: number;
    /**
     * Minimum number of instances in the node group.
     */
    min: number;
}

export interface KubernetesNodeGroupScalePolicyFixedScale {
    /**
     * The number of instances in the node group.
     */
    size: number;
}

export interface KubernetesNodeGroupVersionInfo {
    /**
     * Current Kubernetes version, major.minor (e.g. 1.15).
     */
    currentVersion: string;
    /**
     * True/false flag.
     * Newer revisions may include Kubernetes patches (e.g 1.15.1 > 1.15.2) as well
     * as some internal component updates - new features or bug fixes in yandex-specific
     * components either on the master or nodes.
     */
    newRevisionAvailable: boolean;
    /**
     * Human readable description of the changes to be applied
     * when updating to the latest revision. Empty if newRevisionAvailable is false.
     */
    newRevisionSummary: string;
    /**
     * True/false flag. The current version is on the deprecation schedule,
     * component (master or node group) should be upgraded.
     */
    versionDeprecated: boolean;
}

export interface LbNetworkLoadBalancerAttachedTargetGroup {
    /**
     * A HealthCheck resource. The structure is documented below.
     */
    healthchecks: outputs.LbNetworkLoadBalancerAttachedTargetGroupHealthcheck[];
    /**
     * ID of the target group.
     */
    targetGroupId: string;
}

export interface LbNetworkLoadBalancerAttachedTargetGroupHealthcheck {
    /**
     * Number of successful health checks required in order to set the `HEALTHY` status for the target.
     */
    healthyThreshold?: number;
    /**
     * Options for HTTP health check. The structure is documented below.
     */
    httpOptions?: outputs.LbNetworkLoadBalancerAttachedTargetGroupHealthcheckHttpOptions;
    /**
     * The interval between health checks. The default is 2 seconds.
     */
    interval?: number;
    /**
     * Name of the listener. The name must be unique for each listener on a single load balancer.
     */
    name: string;
    /**
     * Options for TCP health check. The structure is documented below.
     */
    tcpOptions?: outputs.LbNetworkLoadBalancerAttachedTargetGroupHealthcheckTcpOptions;
    /**
     * Timeout for a target to return a response for the health check. The default is 1 second.
     */
    timeout?: number;
    /**
     * Number of failed health checks before changing the status to `UNHEALTHY`. The default is 2.
     */
    unhealthyThreshold?: number;
}

export interface LbNetworkLoadBalancerAttachedTargetGroupHealthcheckHttpOptions {
    /**
     * URL path to set for health checking requests for every target in the target group. For example `/ping`. The default path is `/`.
     */
    path?: string;
    /**
     * Port for incoming traffic.
     */
    port: number;
}

export interface LbNetworkLoadBalancerAttachedTargetGroupHealthcheckTcpOptions {
    /**
     * Port for incoming traffic.
     */
    port: number;
}

export interface LbNetworkLoadBalancerListener {
    /**
     * External IP address specification. The structure is documented below.
     */
    externalAddressSpec?: outputs.LbNetworkLoadBalancerListenerExternalAddressSpec;
    /**
     * Internal IP address specification. The structure is documented below.
     */
    internalAddressSpec?: outputs.LbNetworkLoadBalancerListenerInternalAddressSpec;
    /**
     * Name of the listener. The name must be unique for each listener on a single load balancer.
     */
    name: string;
    /**
     * Port for incoming traffic.
     */
    port: number;
    /**
     * Protocol for incoming traffic. TCP or UDP and the default is TCP.
     */
    protocol: string;
    /**
     * Port of a target. The default is the same as listener's port.
     */
    targetPort: number;
}

export interface LbNetworkLoadBalancerListenerExternalAddressSpec {
    /**
     * Internal IP address for a listener. Must belong to the subnet that is referenced in subnet_id. IP address will be allocated if it wasn't been set.
     */
    address: string;
    /**
     * IP version of the internal addresses that the load balancer works with. Must be one of ipv4 or ipv6. The default is ipv4.
     */
    ipVersion?: string;
}

export interface LbNetworkLoadBalancerListenerInternalAddressSpec {
    /**
     * Internal IP address for a listener. Must belong to the subnet that is referenced in subnet_id. IP address will be allocated if it wasn't been set.
     */
    address: string;
    /**
     * IP version of the internal addresses that the load balancer works with. Must be one of ipv4 or ipv6. The default is ipv4.
     */
    ipVersion?: string;
    /**
     * ID of the subnet to which the internal IP address belongs.
     */
    subnetId: string;
}

export interface LbTargetGroupTarget {
    /**
     * IP address of the target.
     */
    address: string;
    /**
     * ID of the subnet that targets are connected to. 
     * All targets in the target group must be connected to the same subnet within a single availability zone.
     */
    subnetId: string;
}

export interface LockboxSecretVersionEntry {
    /**
     * The command that generates the text value of the entry.
     */
    command?: outputs.LockboxSecretVersionEntryCommand;
    /**
     * The key of the entry.
     */
    key: string;
    /**
     * The text value of the entry.
     */
    textValue?: string;
}

export interface LockboxSecretVersionEntryCommand {
    /**
     * List of arguments to be passed to the script/command.
     */
    args?: string[];
    /**
     * Map of environment variables to set before calling the script/command.
     */
    env?: {[key: string]: string};
    /**
     * The path to the script or command to execute.
     */
    path: string;
}

export interface MdbClickhouseClusterAccess {
    /**
     * Allow access for DataLens. Can be either `true` or `false`.
     */
    dataLens?: boolean;
    /**
     * Allow access for DataTransfer. Can be either `true` or `false`.
     */
    dataTransfer?: boolean;
    /**
     * Allow access for Yandex.Metrika. Can be either `true` or `false`.
     */
    metrika?: boolean;
    /**
     * Allow access for Serverless. Can be either `true` or `false`.
     */
    serverless?: boolean;
    /**
     * Allow access for Web SQL. Can be either `true` or `false`.
     */
    webSql?: boolean;
    /**
     * Allow access for YandexQuery. Can be either `true` or `false`.
     */
    yandexQuery?: boolean;
}

export interface MdbClickhouseClusterBackupWindowStart {
    /**
     * The hour at which backup will be started.
     */
    hours?: number;
    /**
     * The minute at which backup will be started.
     */
    minutes?: number;
}

export interface MdbClickhouseClusterClickhouse {
    /**
     * Main ClickHouse cluster configuration.
     */
    config: outputs.MdbClickhouseClusterClickhouseConfig;
    /**
     * Resources allocated to host of the shard. The resources specified for the shard takes precedence over the resources specified for the cluster. The structure is documented below.
     */
    resources: outputs.MdbClickhouseClusterClickhouseResources;
}

export interface MdbClickhouseClusterClickhouseConfig {
    backgroundFetchesPoolSize: number;
    backgroundMessageBrokerSchedulePoolSize: number;
    backgroundPoolSize: number;
    backgroundSchedulePoolSize: number;
    /**
     * Data compression configuration. The structure is documented below.
     */
    compressions?: outputs.MdbClickhouseClusterClickhouseConfigCompression[];
    defaultDatabase: string;
    geobaseUri: string;
    /**
     * Graphite rollup configuration. The structure is documented below.
     */
    graphiteRollups?: outputs.MdbClickhouseClusterClickhouseConfigGraphiteRollup[];
    /**
     * Kafka connection configuration. The structure is documented below.
     */
    kafka: outputs.MdbClickhouseClusterClickhouseConfigKafka;
    /**
     * Kafka topic connection configuration. The structure is documented below.
     */
    kafkaTopics?: outputs.MdbClickhouseClusterClickhouseConfigKafkaTopic[];
    keepAliveTimeout: number;
    logLevel: string;
    markCacheSize: number;
    maxConcurrentQueries: number;
    maxConnections: number;
    maxPartitionSizeToDrop: number;
    maxTableSizeToDrop: number;
    /**
     * MergeTree engine configuration. The structure is documented below.
     */
    mergeTree: outputs.MdbClickhouseClusterClickhouseConfigMergeTree;
    metricLogEnabled: boolean;
    metricLogRetentionSize: number;
    metricLogRetentionTime: number;
    partLogRetentionSize: number;
    partLogRetentionTime: number;
    queryLogRetentionSize: number;
    queryLogRetentionTime: number;
    queryThreadLogEnabled: boolean;
    queryThreadLogRetentionSize: number;
    queryThreadLogRetentionTime: number;
    /**
     * RabbitMQ connection configuration. The structure is documented below.
     */
    rabbitmq: outputs.MdbClickhouseClusterClickhouseConfigRabbitmq;
    textLogEnabled: boolean;
    textLogLevel: string;
    textLogRetentionSize: number;
    textLogRetentionTime: number;
    timezone: string;
    totalMemoryProfilerStep: number;
    traceLogEnabled: boolean;
    traceLogRetentionSize: number;
    traceLogRetentionTime: number;
    uncompressedCacheSize: number;
}

export interface MdbClickhouseClusterClickhouseConfigCompression {
    /**
     * Method: Compression method. Two methods are available: LZ4 and zstd.
     */
    method: string;
    /**
     * Min part size: Minimum size (in bytes) of a data part in a table. ClickHouse only applies the rule to tables with data parts greater than or equal to the Min part size value.
     */
    minPartSize: number;
    /**
     * Min part size ratio: Minimum table part size to total table size ratio. ClickHouse only applies the rule to tables in which this ratio is greater than or equal to the Min part size ratio value.
     */
    minPartSizeRatio: number;
}

export interface MdbClickhouseClusterClickhouseConfigGraphiteRollup {
    /**
     * Graphite rollup configuration name.
     */
    name: string;
    /**
     * Set of thinning rules.
     */
    patterns?: outputs.MdbClickhouseClusterClickhouseConfigGraphiteRollupPattern[];
}

export interface MdbClickhouseClusterClickhouseConfigGraphiteRollupPattern {
    /**
     * Aggregation function name.
     */
    function: string;
    /**
     * Regular expression that the metric name must match.
     */
    regexp: string;
    /**
     * Retain parameters.
     */
    retentions?: outputs.MdbClickhouseClusterClickhouseConfigGraphiteRollupPatternRetention[];
}

export interface MdbClickhouseClusterClickhouseConfigGraphiteRollupPatternRetention {
    /**
     * Minimum data age in seconds.
     */
    age: number;
    /**
     * Accuracy of determining the age of the data in seconds.
     */
    precision: number;
}

export interface MdbClickhouseClusterClickhouseConfigKafka {
    /**
     * SASL mechanism used in kafka authentication.
     */
    saslMechanism: string;
    /**
     * User password on kafka server.
     */
    saslPassword: string;
    /**
     * Username on kafka server.
     */
    saslUsername: string;
    /**
     * Security protocol used to connect to kafka server.
     */
    securityProtocol: string;
}

export interface MdbClickhouseClusterClickhouseConfigKafkaTopic {
    /**
     * Graphite rollup configuration name.
     */
    name: string;
    /**
     * Kafka connection settngs sanem as `kafka` block.
     */
    settings?: outputs.MdbClickhouseClusterClickhouseConfigKafkaTopicSettings;
}

export interface MdbClickhouseClusterClickhouseConfigKafkaTopicSettings {
    /**
     * SASL mechanism used in kafka authentication.
     */
    saslMechanism?: string;
    /**
     * User password on kafka server.
     */
    saslPassword?: string;
    /**
     * Username on kafka server.
     */
    saslUsername?: string;
    /**
     * Security protocol used to connect to kafka server.
     */
    securityProtocol?: string;
}

export interface MdbClickhouseClusterClickhouseConfigMergeTree {
    /**
     * Minimum period to clean old queue logs, blocks hashes and parts.
     */
    cleanupDelayPeriod: number;
    /**
     * Max bytes to merge at min space in pool: Maximum total size of a data part to merge when the number of free threads in the background pool is minimum.
     */
    maxBytesToMergeAtMinSpaceInPool: number;
    /**
     * When there is more than specified number of merges with TTL entries in pool, do not assign new merge with TTL.
     */
    maxNumberOfMergesWithTtlInPool: number;
    /**
     * Maximum number of parts in all partitions.
     */
    maxPartsInTotal: number;
    /**
     * Max replicated merges in queue: Maximum number of merge tasks that can be in the ReplicatedMergeTree queue at the same time.
     */
    maxReplicatedMergesInQueue: number;
    /**
     * Minimum delay in seconds before repeating a merge with recompression TTL. Default value: 14400 seconds (4 hours).
     */
    mergeWithRecompressionTtlTimeout: number;
    /**
     * Minimum delay in seconds before repeating a merge with delete TTL. Default value: 14400 seconds (4 hours).
     */
    mergeWithTtlTimeout: number;
    /**
     * Minimum number of bytes in a data part that can be stored in Wide format. You can set one, both or none of these settings.
     */
    minBytesForWidePart: number;
    /**
     * Minimum number of rows in a data part that can be stored in Wide format. You can set one, both or none of these settings.
     */
    minRowsForWidePart: number;
    /**
     * Number of free entries in pool to lower max size of merge: Threshold value of free entries in the pool. If the number of entries in the pool falls below this value, ClickHouse reduces the maximum size of a data part to merge. This helps handle small merges faster, rather than filling the pool with lengthy merges.
     */
    numberOfFreeEntriesInPoolToLowerMaxSizeOfMerge: number;
    /**
     * Parts to delay insert: Number of active data parts in a table, on exceeding which ClickHouse starts artificially reduce the rate of inserting data into the table.
     */
    partsToDelayInsert: number;
    /**
     * Parts to throw insert: Threshold value of active data parts in a table, on exceeding which ClickHouse throws the 'Too many parts ...' exception.
     */
    partsToThrowInsert: number;
    /**
     * Replicated deduplication window: Number of recent hash blocks that ZooKeeper will store (the old ones will be deleted).
     */
    replicatedDeduplicationWindow: number;
    /**
     * Replicated deduplication window seconds: Time during which ZooKeeper stores the hash blocks (the old ones wil be deleted).
     */
    replicatedDeduplicationWindowSeconds: number;
    /**
     * Enables or disables complete dropping of data parts where all rows are expired in MergeTree tables.
     */
    ttlOnlyDropParts: boolean;
}

export interface MdbClickhouseClusterClickhouseConfigRabbitmq {
    /**
     * RabbitMQ user password.
     */
    password: string;
    /**
     * RabbitMQ username.
     */
    username: string;
    /**
     * RabbitMQ vhost. Default: '\'.
     */
    vhost: string;
}

export interface MdbClickhouseClusterClickhouseResources {
    /**
     * Volume of the storage available to a host, in gigabytes.
     */
    diskSize: number;
    /**
     * Type of the storage of hosts.
     */
    diskTypeId: string;
    resourcePresetId: string;
}

export interface MdbClickhouseClusterCloudStorage {
    /**
     * Enables temporary storage in the cluster repository of data requested from the object repository.
     */
    dataCacheEnabled: boolean;
    /**
     * Defines the maximum amount of memory (in bytes) allocated in the cluster storage for temporary storage of data requested from the object storage.
     */
    dataCacheMaxSize: number;
    /**
     * Whether to use Yandex Object Storage for storing ClickHouse data. Can be either `true` or `false`.
     */
    enabled: boolean;
    /**
     * Sets the minimum free space ratio in the cluster storage. If the free space is lower than this value, the data is transferred to Yandex Object Storage. Acceptable values are 0 to 1, inclusive.
     */
    moveFactor: number;
}

export interface MdbClickhouseClusterDatabase {
    /**
     * Graphite rollup configuration name.
     */
    name: string;
}

export interface MdbClickhouseClusterFormatSchema {
    /**
     * Graphite rollup configuration name.
     */
    name: string;
    /**
     * Type of maintenance window. Can be either `ANYTIME` or `WEEKLY`. A day and hour of window need to be specified with weekly window.
     */
    type: string;
    /**
     * Model file URL. You can only use models stored in Yandex Object Storage.
     */
    uri: string;
}

export interface MdbClickhouseClusterHost {
    /**
     * Sets whether the host should get a public IP address on creation. Can be either `true` or `false`.
     */
    assignPublicIp?: boolean;
    /**
     * The fully qualified domain name of the host.
     */
    fqdn: string;
    /**
     * The name of the shard to which the host belongs.
     */
    shardName: string;
    /**
     * The ID of the subnet, to which the host belongs. The subnet must be a part of the network to which the cluster belongs.
     */
    subnetId: string;
    /**
     * Type of maintenance window. Can be either `ANYTIME` or `WEEKLY`. A day and hour of window need to be specified with weekly window.
     */
    type: string;
    /**
     * The availability zone where the ClickHouse host will be created.
     * For more information see [the official documentation](https://cloud.yandex.com/docs/overview/concepts/geo-scope).
     */
    zone: string;
}

export interface MdbClickhouseClusterMaintenanceWindow {
    /**
     * Day of week for maintenance window if window type is weekly. Possible values: `MON`, `TUE`, `WED`, `THU`, `FRI`, `SAT`, `SUN`.
     */
    day?: string;
    /**
     * Hour of day in UTC time zone (1-24) for maintenance window if window type is weekly.
     */
    hour?: number;
    /**
     * Type of maintenance window. Can be either `ANYTIME` or `WEEKLY`. A day and hour of window need to be specified with weekly window.
     */
    type: string;
}

export interface MdbClickhouseClusterMlModel {
    /**
     * Graphite rollup configuration name.
     */
    name: string;
    /**
     * Type of maintenance window. Can be either `ANYTIME` or `WEEKLY`. A day and hour of window need to be specified with weekly window.
     */
    type: string;
    /**
     * Model file URL. You can only use models stored in Yandex Object Storage.
     */
    uri: string;
}

export interface MdbClickhouseClusterShard {
    /**
     * Graphite rollup configuration name.
     */
    name: string;
    /**
     * Resources allocated to host of the shard. The resources specified for the shard takes precedence over the resources specified for the cluster. The structure is documented below.
     */
    resources: outputs.MdbClickhouseClusterShardResources;
    /**
     * The weight of shard.
     */
    weight: number;
}

export interface MdbClickhouseClusterShardGroup {
    /**
     * Description of the shard group.
     */
    description?: string;
    /**
     * Graphite rollup configuration name.
     */
    name: string;
    /**
     * List of shards names that belong to the shard group.
     */
    shardNames: string[];
}

export interface MdbClickhouseClusterShardResources {
    /**
     * Volume of the storage available to a host, in gigabytes.
     */
    diskSize: number;
    /**
     * Type of the storage of hosts.
     */
    diskTypeId: string;
    resourcePresetId: string;
}

export interface MdbClickhouseClusterUser {
    /**
     * Graphite rollup configuration name.
     */
    name: string;
    /**
     * RabbitMQ user password.
     */
    password: string;
    /**
     * Set of permissions granted to the user. The structure is documented below.
     */
    permissions: outputs.MdbClickhouseClusterUserPermission[];
    /**
     * Set of user quotas. The structure is documented below.
     */
    quotas: outputs.MdbClickhouseClusterUserQuota[];
    /**
     * Kafka connection settngs sanem as `kafka` block.
     */
    settings: outputs.MdbClickhouseClusterUserSettings;
}

export interface MdbClickhouseClusterUserPermission {
    /**
     * The name of the database that the permission grants access to.
     */
    databaseName: string;
}

export interface MdbClickhouseClusterUserQuota {
    /**
     * The number of queries that threw exception.
     */
    errors: number;
    /**
     * The total query execution time, in milliseconds (wall time).
     */
    executionTime: number;
    /**
     * Duration of interval for quota in milliseconds.
     */
    intervalDuration: number;
    /**
     * The total number of queries.
     */
    queries: number;
    /**
     * The total number of source rows read from tables for running the query, on all remote servers.
     */
    readRows: number;
    /**
     * The total number of rows given as the result.
     */
    resultRows: number;
}

export interface MdbClickhouseClusterUserSettings {
    /**
     * Include CORS headers in HTTP responces.
     */
    addHttpCorsHeader: boolean;
    /**
     * Allows or denies DDL queries.
     */
    allowDdl: boolean;
    /**
     * Enables introspections functions for query profiling.
     */
    allowIntrospectionFunctions: boolean;
    /**
     * Allows specifying LowCardinality modifier for types of small fixed size (8 or less) in CREATE TABLE statements. Enabling this may increase merge times and memory consumption.
     */
    allowSuspiciousLowCardinalityTypes: boolean;
    /**
     * Enables asynchronous inserts. Disabled by default.
     */
    asyncInsert: boolean;
    /**
     * The maximum timeout in milliseconds since the first INSERT query before inserting collected data. If the parameter is set to 0, the timeout is disabled. Default value: 200.
     */
    asyncInsertBusyTimeout: number;
    /**
     * The maximum size of the unparsed data in bytes collected per query before being inserted. If the parameter is set to 0, asynchronous insertions are disabled. Default value: 100000.
     */
    asyncInsertMaxDataSize: number;
    /**
     * The maximum timeout in milliseconds since the last INSERT query before dumping collected data. If enabled, the settings prolongs the asyncInsertBusyTimeout with every INSERT query as long as asyncInsertMaxDataSize is not exceeded.
     */
    asyncInsertStaleTimeout: number;
    /**
     * The maximum number of threads for background data parsing and insertion. If the parameter is set to 0, asynchronous insertions are disabled. Default value: 16.
     */
    asyncInsertThreads: number;
    /**
     * Cancels HTTP read-only queries (e.g. SELECT) when a client closes the connection without waiting for the response.
     * Default value: false.
     */
    cancelHttpReadonlyQueriesOnClientClose: boolean;
    /**
     * Enable compilation of queries.
     */
    compile: boolean;
    /**
     * Turn on expression compilation.
     */
    compileExpressions: boolean;
    /**
     * Connect timeout in milliseconds on the socket used for communicating with the client.
     */
    connectTimeout: number;
    /**
     * The timeout in milliseconds for connecting to a remote server for a Distributed table engine, if the ‘shard’ and ‘replica’ sections are used in the cluster definition. If unsuccessful, several attempts are made to connect to various replicas. Default value: 50.
     */
    connectTimeoutWithFailover: number;
    /**
     * Specifies which of the uniq* functions should be used to perform the COUNT(DISTINCT …) construction.
     */
    countDistinctImplementation: string;
    /**
     * Sets behaviour on overflow when using DISTINCT. Possible values:
     */
    distinctOverflowMode: string;
    /**
     * Determine the behavior of distributed subqueries.
     */
    distributedAggregationMemoryEfficient: boolean;
    /**
     * Timeout for DDL queries, in milliseconds.
     */
    distributedDdlTaskTimeout: number;
    /**
     * Changes the behaviour of distributed subqueries.
     */
    distributedProductMode: string;
    /**
     * Allows to retunr empty result.
     */
    emptyResultForAggregationByEmptySet: boolean;
    /**
     * Enables or disables data compression in the response to an HTTP request.
     */
    enableHttpCompression: boolean;
    /**
     * Forces a query to an out-of-date replica if updated data is not available.
     */
    fallbackToStaleReplicasForDistributedQueries: boolean;
    /**
     * Sets the data format of a nested columns.
     */
    flattenNested: boolean;
    /**
     * Disables query execution if the index can’t be used by date.
     */
    forceIndexByDate: boolean;
    /**
     * Disables query execution if indexing by the primary key is not possible.
     */
    forcePrimaryKey: boolean;
    /**
     * Sets behaviour on overflow while GROUP BY operation. Possible values:
     */
    groupByOverflowMode: string;
    /**
     * Sets the threshold of the number of keys, after that the two-level aggregation should be used.
     */
    groupByTwoLevelThreshold: number;
    /**
     * Sets the threshold of the number of bytes, after that the two-level aggregation should be used.
     */
    groupByTwoLevelThresholdBytes: number;
    /**
     * Timeout for HTTP connection in milliseconds.
     */
    httpConnectionTimeout: number;
    /**
     * Sets minimal interval between notifications about request process in HTTP header X-ClickHouse-Progress.
     */
    httpHeadersProgressInterval: number;
    /**
     * Timeout for HTTP connection in milliseconds.
     */
    httpReceiveTimeout: number;
    /**
     * Timeout for HTTP connection in milliseconds.
     */
    httpSendTimeout: number;
    /**
     * When performing INSERT queries, replace omitted input column values with default values of the respective columns.
     */
    inputFormatDefaultsForOmittedFields: boolean;
    /**
     * Enables or disables the insertion of JSON data with nested objects.
     */
    inputFormatImportNestedJson: boolean;
    /**
     * Enables or disables order-preserving parallel parsing of data formats. Supported only for TSV, TKSV, CSV and JSONEachRow formats.
     */
    inputFormatParallelParsing: boolean;
    /**
     * Enables or disables the full SQL parser if the fast stream parser can’t parse the data.
     */
    inputFormatValuesInterpretExpressions: boolean;
    /**
     * Enables the insertion of default values instead of NULL into columns with not nullable data type. Default value: true.
     */
    insertNullAsDefault: boolean;
    /**
     * Enables the quorum writes.
     */
    insertQuorum: number;
    /**
     * Write to a quorum timeout in milliseconds.
     */
    insertQuorumTimeout: number;
    /**
     * Sets behaviour on overflow in JOIN. Possible values:
     */
    joinOverflowMode: string;
    /**
     * Sets the type of JOIN behaviour. When merging tables, empty cells may appear. ClickHouse fills them differently based on this setting.
     */
    joinUseNulls: boolean;
    /**
     * Require aliases for subselects and table functions in FROM that more than one table is present.
     */
    joinedSubqueryRequiresAlias: boolean;
    /**
     * Method of reading data from local filesystem. Possible values:
     */
    localFilesystemReadMethod: string;
    /**
     * Allows or restricts using the LowCardinality data type with the Native format.
     */
    lowCardinalityAllowInNativeFormat: boolean;
    /**
     * Maximum abstract syntax tree depth.
     */
    maxAstDepth: number;
    /**
     * Maximum abstract syntax tree elements.
     */
    maxAstElements: number;
    /**
     * A recommendation for what size of the block (in a count of rows) to load from tables.
     */
    maxBlockSize: number;
    /**
     * Limit in bytes for using memoru for GROUP BY before using swap on disk.
     */
    maxBytesBeforeExternalGroupBy: number;
    /**
     * This setting is equivalent of the maxBytesBeforeExternalGroupBy setting, except for it is for sort operation (ORDER BY), not aggregation.
     */
    maxBytesBeforeExternalSort: number;
    /**
     * Limits the maximum size of a hash table in bytes (uncompressed data) when using DISTINCT.
     */
    maxBytesInDistinct: number;
    /**
     * Limit on maximum size of the hash table for JOIN, in bytes.
     */
    maxBytesInJoin: number;
    /**
     * Limit on the number of bytes in the set resulting from the execution of the IN section.
     */
    maxBytesInSet: number;
    /**
     * Limits the maximum number of bytes (uncompressed data) that can be read from a table when running a query.
     */
    maxBytesToRead: number;
    /**
     * Limits the maximum number of bytes (uncompressed data) that can be read from a table for sorting.
     */
    maxBytesToSort: number;
    /**
     * Limits the maximum number of bytes (uncompressed data) that can be passed to a remote server or saved in a temporary table when using GLOBAL IN.
     */
    maxBytesToTransfer: number;
    /**
     * Limits the maximum number of columns that can be read from a table in a single query.
     */
    maxColumnsToRead: number;
    /**
     * The maximum number of concurrent requests per user. Default value: 0 (no limit).
     */
    maxConcurrentQueriesForUser: number;
    /**
     * Limits the maximum query execution time in milliseconds.
     */
    maxExecutionTime: number;
    /**
     * Maximum abstract syntax tree depth after after expansion of aliases.
     */
    maxExpandedAstElements: number;
    /**
     * Sets the maximum number of parallel threads for the SELECT query data read phase with the FINAL modifier.
     */
    maxFinalThreads: number;
    /**
     * Limits the maximum number of HTTP GET redirect hops for URL-engine tables.
     */
    maxHttpGetRedirects: number;
    /**
     * The size of blocks (in a count of rows) to form for insertion into a table.
     */
    maxInsertBlockSize: number;
    /**
     * Limits the maximum memory usage (in bytes) for processing queries on a single server.
     */
    maxMemoryUsage: number;
    /**
     * Limits the maximum memory usage (in bytes) for processing of user's queries on a single server.
     */
    maxMemoryUsageForUser: number;
    /**
     * Limits the speed of the data exchange over the network in bytes per second.
     */
    maxNetworkBandwidth: number;
    /**
     * Limits the speed of the data exchange over the network in bytes per second.
     */
    maxNetworkBandwidthForUser: number;
    /**
     * The maximum part of a query that can be taken to RAM for parsing with the SQL parser.
     */
    maxQuerySize: number;
    /**
     * The maximum size of the buffer to read from the filesystem.
     */
    maxReadBufferSize: number;
    /**
     * Disables lagging replicas for distributed queries.
     */
    maxReplicaDelayForDistributedQueries: number;
    /**
     * Limits the number of bytes in the result.
     */
    maxResultBytes: number;
    /**
     * Limits the number of rows in the result.
     */
    maxResultRows: number;
    /**
     * Limits the maximum number of different rows when using DISTINCT.
     */
    maxRowsInDistinct: number;
    /**
     * Limit on maximum size of the hash table for JOIN, in rows.
     */
    maxRowsInJoin: number;
    /**
     * Limit on the number of rows in the set resulting from the execution of the IN section.
     */
    maxRowsInSet: number;
    /**
     * Limits the maximum number of unique keys received from aggregation function.
     */
    maxRowsToGroupBy: number;
    /**
     * Limits the maximum number of rows that can be read from a table when running a query.
     */
    maxRowsToRead: number;
    /**
     * Limits the maximum number of rows that can be read from a table for sorting.
     */
    maxRowsToSort: number;
    /**
     * Limits the maximum number of rows that can be passed to a remote server or saved in a temporary table when using GLOBAL IN.
     */
    maxRowsToTransfer: number;
    /**
     * Limits the maximum number of temporary columns that must be kept in RAM at the same time when running a query, including constant columns.
     */
    maxTemporaryColumns: number;
    /**
     * Limits the maximum number of temporary columns that must be kept in RAM at the same time when running a query, excluding constant columns.
     */
    maxTemporaryNonConstColumns: number;
    /**
     * The maximum number of query processing threads, excluding threads for retrieving data from remote servers.
     */
    maxThreads: number;
    /**
     * Collect random allocations and deallocations and write them into system.trace_log with 'MemorySample' trace_type. The probability is for every alloc/free regardless to the size of the allocation. Possible values: from 0 to 1. Default: 0.
     */
    memoryProfilerSampleProbability: number;
    /**
     * Memory profiler step (in bytes).  If the next query step requires more memory than this parameter specifies, the memory profiler collects the allocating stack trace. Values lower than a few megabytes slow down query processing. Default value: 4194304 (4 MB). Zero means disabled memory profiler.
     */
    memoryProfilerStep: number;
    /**
     * If ClickHouse should read more than mergeTreeMaxBytesToUseCache bytes in one query, it doesn’t use the cache of uncompressed blocks.
     */
    mergeTreeMaxBytesToUseCache: number;
    /**
     * If ClickHouse should read more than mergeTreeMaxRowsToUseCache rows in one query, it doesn’t use the cache of uncompressed blocks.
     */
    mergeTreeMaxRowsToUseCache: number;
    /**
     * If the number of bytes to read from one file of a MergeTree-engine table exceeds merge_tree_min_bytes_for_concurrent_read, then ClickHouse tries to concurrently read from this file in several threads.
     */
    mergeTreeMinBytesForConcurrentRead: number;
    /**
     * If the number of rows to be read from a file of a MergeTree table exceeds mergeTreeMinRowsForConcurrentRead then ClickHouse tries to perform a concurrent reading from this file on several threads.
     */
    mergeTreeMinRowsForConcurrentRead: number;
    /**
     * The minimum data volume required for using direct I/O access to the storage disk.
     */
    minBytesToUseDirectIo: number;
    /**
     * How many times to potentially use a compiled chunk of code before running compilation.
     */
    minCountToCompile: number;
    /**
     * A query waits for expression compilation process to complete prior to continuing execution.
     */
    minCountToCompileExpression: number;
    /**
     * Minimal execution speed in rows per second.
     */
    minExecutionSpeed: number;
    /**
     * Minimal execution speed in bytes per second.
     */
    minExecutionSpeedBytes: number;
    /**
     * Sets the minimum number of bytes in the block which can be inserted into a table by an INSERT query.
     */
    minInsertBlockSizeBytes: number;
    /**
     * Sets the minimum number of rows in the block which can be inserted into a table by an INSERT query.
     */
    minInsertBlockSizeRows: number;
    /**
     * If the value is true, integers appear in quotes when using JSON* Int64 and UInt64 formats (for compatibility with most JavaScript implementations); otherwise, integers are output without the quotes.
     */
    outputFormatJsonQuote64bitIntegers: boolean;
    /**
     * Enables +nan, -nan, +inf, -inf outputs in JSON output format.
     */
    outputFormatJsonQuoteDenormals: boolean;
    /**
     * Query priority.
     */
    priority: number;
    /**
     * Quota accounting mode.
     */
    quotaMode: string;
    /**
     * Sets behaviour on overflow while read. Possible values:
     */
    readOverflowMode: string;
    /**
     * Restricts permissions for reading data, write data and change settings queries.
     */
    readonly: number;
    /**
     * Receive timeout in milliseconds on the socket used for communicating with the client.
     */
    receiveTimeout: number;
    /**
     * For ALTER ... ATTACH|DETACH|DROP queries, you can use the replicationAlterPartitionsSync setting to set up waiting.
     */
    replicationAlterPartitionsSync: number;
    /**
     * Sets behaviour on overflow in result. Possible values:
     */
    resultOverflowMode: string;
    /**
     * Enables or disables sequential consistency for SELECT queries.
     */
    selectSequentialConsistency: boolean;
    /**
     * Enables or disables X-ClickHouse-Progress HTTP response headers in clickhouse-server responses.
     */
    sendProgressInHttpHeaders: boolean;
    /**
     * Send timeout in milliseconds on the socket used for communicating with the client.
     */
    sendTimeout: number;
    /**
     * Sets behaviour on overflow in the set resulting. Possible values:
     */
    setOverflowMode: string;
    /**
     * Enables or disables silently skipping of unavailable shards.
     */
    skipUnavailableShards: boolean;
    /**
     * Sets behaviour on overflow while sort. Possible values:
     */
    sortOverflowMode: string;
    /**
     * Timeout (in seconds) between checks of execution speed. It is checked that execution speed is not less that specified in minExecutionSpeed parameter.
     * Must be at least 1000.
     */
    timeoutBeforeCheckingExecutionSpeed: number;
    /**
     * Sets behaviour on overflow. Possible values:
     */
    timeoutOverflowMode: string;
    /**
     * Sets behaviour on overflow. Possible values:
     */
    transferOverflowMode: string;
    /**
     * Enables equality of NULL values for IN operator.
     */
    transformNullIn: boolean;
    /**
     * Whether to use a cache of uncompressed blocks.
     */
    useUncompressedCache: boolean;
    /**
     * Enables waiting for processing of asynchronous insertion. If enabled, server returns OK only after the data is inserted.
     */
    waitForAsyncInsert: boolean;
    /**
     * The timeout (in seconds) for waiting for processing of asynchronous insertion. Value must be at least 1000 (1 second).
     */
    waitForAsyncInsertTimeout: number;
}

export interface MdbClickhouseClusterZookeeper {
    /**
     * Resources allocated to host of the shard. The resources specified for the shard takes precedence over the resources specified for the cluster. The structure is documented below.
     */
    resources: outputs.MdbClickhouseClusterZookeeperResources;
}

export interface MdbClickhouseClusterZookeeperResources {
    /**
     * Volume of the storage available to a host, in gigabytes.
     */
    diskSize: number;
    /**
     * Type of the storage of hosts.
     */
    diskTypeId: string;
    resourcePresetId: string;
}

export interface MdbElasticSearchClusterConfig {
    /**
     * Password for admin user of Elasticsearch.
     */
    adminPassword: string;
    /**
     * Configuration for Elasticsearch data nodes subcluster. The structure is documented below.
     */
    dataNode: outputs.MdbElasticSearchClusterConfigDataNode;
    /**
     * Edition of Elasticsearch. For more information, see [the official documentation](https://cloud.yandex.com/en-ru/docs/managed-elasticsearch/concepts/es-editions).
     */
    edition: string;
    /**
     * Configuration for Elasticsearch master nodes subcluster. The structure is documented below.
     */
    masterNode?: outputs.MdbElasticSearchClusterConfigMasterNode;
    /**
     * A set of Elasticsearch plugins to install.
     */
    plugins?: string[];
    /**
     * Version of Elasticsearch.
     */
    version: string;
}

export interface MdbElasticSearchClusterConfigDataNode {
    /**
     * Resources allocated to hosts of the Elasticsearch master nodes subcluster. The structure is documented below.
     */
    resources: outputs.MdbElasticSearchClusterConfigDataNodeResources;
}

export interface MdbElasticSearchClusterConfigDataNodeResources {
    /**
     * Volume of the storage available to a host, in gigabytes.
     */
    diskSize: number;
    /**
     * Type of the storage of Elasticsearch hosts.
     */
    diskTypeId: string;
    resourcePresetId: string;
}

export interface MdbElasticSearchClusterConfigMasterNode {
    /**
     * Resources allocated to hosts of the Elasticsearch master nodes subcluster. The structure is documented below.
     */
    resources: outputs.MdbElasticSearchClusterConfigMasterNodeResources;
}

export interface MdbElasticSearchClusterConfigMasterNodeResources {
    /**
     * Volume of the storage available to a host, in gigabytes.
     */
    diskSize: number;
    /**
     * Type of the storage of Elasticsearch hosts.
     */
    diskTypeId: string;
    resourcePresetId: string;
}

export interface MdbElasticSearchClusterHost {
    /**
     * Sets whether the host should get a public IP address on creation. Can be either `true` or `false`.
     */
    assignPublicIp?: boolean;
    /**
     * The fully qualified domain name of the host.
     */
    fqdn: string;
    /**
     * User defined host name.
     */
    name: string;
    /**
     * The ID of the subnet, to which the host belongs. The subnet must
     * be a part of the network to which the cluster belongs.
     */
    subnetId: string;
    /**
     * Type of maintenance window. Can be either `ANYTIME` or `WEEKLY`. A day and hour of window need to be specified with weekly window.
     */
    type: string;
    /**
     * The availability zone where the Elasticsearch host will be created.
     * For more information see [the official documentation](https://cloud.yandex.com/docs/overview/concepts/geo-scope).
     */
    zone: string;
}

export interface MdbElasticSearchClusterMaintenanceWindow {
    /**
     * Day of week for maintenance window if window type is weekly. Possible values: `MON`, `TUE`, `WED`, `THU`, `FRI`, `SAT`, `SUN`.
     */
    day?: string;
    /**
     * Hour of day in UTC time zone (1-24) for maintenance window if window type is weekly.
     */
    hour?: number;
    /**
     * Type of maintenance window. Can be either `ANYTIME` or `WEEKLY`. A day and hour of window need to be specified with weekly window.
     */
    type: string;
}

export interface MdbGreenplumClusterAccess {
    /**
     * Allow access for [Yandex DataLens](https://cloud.yandex.com/services/datalens).
     */
    dataLens?: boolean;
    /**
     * Allow access for [DataTransfer](https://cloud.yandex.com/services/data-transfer)
     */
    dataTransfer?: boolean;
    /**
     * Allows access for [SQL queries in the management console](https://cloud.yandex.com/docs/managed-mysql/operations/web-sql-query).
     */
    webSql?: boolean;
}

export interface MdbGreenplumClusterBackupWindowStart {
    /**
     * The hour at which backup will be started (UTC).
     */
    hours?: number;
    /**
     * The minute at which backup will be started (UTC).
     */
    minutes?: number;
}

export interface MdbGreenplumClusterMaintenanceWindow {
    /**
     * Day of the week (in `DDD` format). Allowed values: "MON", "TUE", "WED", "THU", "FRI", "SAT", "SUN"
     */
    day?: string;
    /**
     * Hour of the day in UTC (in `HH` format). Allowed value is between 0 and 23.
     */
    hour?: number;
    /**
     * Type of maintenance window. Can be either `ANYTIME` or `WEEKLY`. A day and hour of window need to be specified with weekly window.
     */
    type: string;
}

export interface MdbGreenplumClusterMasterHost {
    /**
     * Sets whether the master hosts should get a public IP address on creation. Changing this parameter for an existing host is not supported at the moment.
     */
    assignPublicIp: boolean;
    /**
     * (Computed) The fully qualified domain name of the host.
     */
    fqdn: string;
}

export interface MdbGreenplumClusterMasterSubcluster {
    /**
     * Resources allocated to hosts for segment subcluster of the Greenplum cluster. The structure is documented below.
     */
    resources: outputs.MdbGreenplumClusterMasterSubclusterResources;
}

export interface MdbGreenplumClusterMasterSubclusterResources {
    diskSize: number;
    diskTypeId: string;
    resourcePresetId: string;
}

export interface MdbGreenplumClusterPoolerConfig {
    /**
     * Value for `poolClientIdleTimeout` [parameter in Odyssey](https://github.com/yandex/odyssey/blob/master/documentation/configuration.md#pool_ttl-integer).
     */
    poolClientIdleTimeout?: number;
    /**
     * Value for `poolSize` [parameter in Odyssey](https://github.com/yandex/odyssey/blob/master/documentation/configuration.md#pool_size-integer).
     */
    poolSize?: number;
    /**
     * Mode that the connection pooler is working in. See descriptions of all modes in the [documentation for Odyssey](https://github.com/yandex/odyssey/blob/master/documentation/configuration.md#pool-string.
     */
    poolingMode?: string;
}

export interface MdbGreenplumClusterSegmentHost {
    /**
     * (Computed) The fully qualified domain name of the host.
     */
    fqdn: string;
}

export interface MdbGreenplumClusterSegmentSubcluster {
    /**
     * Resources allocated to hosts for segment subcluster of the Greenplum cluster. The structure is documented below.
     */
    resources: outputs.MdbGreenplumClusterSegmentSubclusterResources;
}

export interface MdbGreenplumClusterSegmentSubclusterResources {
    diskSize: number;
    diskTypeId: string;
    resourcePresetId: string;
}

export interface MdbKafkaClusterConfig {
    /**
     * Access policy to the Kafka cluster. The structure is documented below.
     */
    access: outputs.MdbKafkaClusterConfigAccess;
    /**
     * Determines whether each broker will be assigned a public IP address. The default is `false`.
     */
    assignPublicIp?: boolean;
    /**
     * Count of brokers per availability zone. The default is `1`.
     */
    brokersCount?: number;
    /**
     * Configuration of the Kafka subcluster. The structure is documented below.
     */
    kafka: outputs.MdbKafkaClusterConfigKafka;
    /**
     * Enables managed schema registry on cluster. The default is `false`.
     */
    schemaRegistry?: boolean;
    /**
     * Allows to use Kafka AdminAPI to manage topics. The default is `false`.
     */
    unmanagedTopics?: boolean;
    /**
     * Version of the Kafka server software.
     */
    version: string;
    /**
     * List of availability zones.
     */
    zones: string[];
    /**
     * Configuration of the ZooKeeper subcluster. The structure is documented below.
     */
    zookeeper: outputs.MdbKafkaClusterConfigZookeeper;
}

export interface MdbKafkaClusterConfigAccess {
    /**
     * Allow access for [DataTransfer](https://cloud.yandex.com/services/data-transfer)
     */
    dataTransfer?: boolean;
}

export interface MdbKafkaClusterConfigKafka {
    /**
     * User-defined settings for the Kafka cluster. The structure is documented below.
     */
    kafkaConfig?: outputs.MdbKafkaClusterConfigKafkaKafkaConfig;
    /**
     * Resources allocated to hosts of the ZooKeeper subcluster. The structure is documented below.
     */
    resources: outputs.MdbKafkaClusterConfigKafkaResources;
}

export interface MdbKafkaClusterConfigKafkaKafkaConfig {
    autoCreateTopicsEnable?: boolean;
    compressionType?: string;
    defaultReplicationFactor?: string;
    logFlushIntervalMessages?: string;
    logFlushIntervalMs?: string;
    logFlushSchedulerIntervalMs?: string;
    logPreallocate?: boolean;
    logRetentionBytes?: string;
    logRetentionHours?: string;
    logRetentionMinutes?: string;
    logRetentionMs?: string;
    logSegmentBytes?: string;
    messageMaxBytes?: string;
    numPartitions?: string;
    offsetsRetentionMinutes?: string;
    replicaFetchMaxBytes?: string;
    saslEnabledMechanisms?: string[];
    socketReceiveBufferBytes?: string;
    socketSendBufferBytes?: string;
    sslCipherSuites?: string[];
}

export interface MdbKafkaClusterConfigKafkaResources {
    /**
     * Volume of the storage available to a ZooKeeper host, in gigabytes.
     */
    diskSize: number;
    /**
     * Type of the storage of ZooKeeper hosts.
     * For more information see [the official documentation](https://cloud.yandex.com/docs/managed-kafka/concepts/storage).
     */
    diskTypeId: string;
    resourcePresetId: string;
}

export interface MdbKafkaClusterConfigZookeeper {
    /**
     * Resources allocated to hosts of the ZooKeeper subcluster. The structure is documented below.
     */
    resources: outputs.MdbKafkaClusterConfigZookeeperResources;
}

export interface MdbKafkaClusterConfigZookeeperResources {
    /**
     * Volume of the storage available to a ZooKeeper host, in gigabytes.
     */
    diskSize: number;
    /**
     * Type of the storage of ZooKeeper hosts.
     * For more information see [the official documentation](https://cloud.yandex.com/docs/managed-kafka/concepts/storage).
     */
    diskTypeId: string;
    resourcePresetId: string;
}

export interface MdbKafkaClusterHost {
    /**
     * Determines whether each broker will be assigned a public IP address. The default is `false`.
     */
    assignPublicIp: boolean;
    /**
     * Health of the host.
     */
    health: string;
    /**
     * The name of the topic.
     */
    name: string;
    /**
     * The role type to grant to the topic.
     */
    role: string;
    /**
     * The ID of the subnet, to which the host belongs.
     */
    subnetId: string;
    /**
     * The availability zone where the Kafka host was created.
     */
    zoneId: string;
}

export interface MdbKafkaClusterMaintenanceWindow {
    /**
     * Day of the week (in `DDD` format). Allowed values: "MON", "TUE", "WED", "THU", "FRI", "SAT", "SUN"
     */
    day?: string;
    /**
     * Hour of the day in UTC (in `HH` format). Allowed value is between 1 and 24.
     */
    hour?: number;
    /**
     * Type of maintenance window. Can be either `ANYTIME` or `WEEKLY`. A day and hour of window need to be specified with weekly window.
     */
    type: string;
}

export interface MdbKafkaClusterTopic {
    /**
     * The name of the topic.
     */
    name: string;
    /**
     * The number of the topic's partitions.
     */
    partitions: number;
    /**
     * Amount of data copies (replicas) for the topic in the cluster.
     */
    replicationFactor: number;
    /**
     * User-defined settings for the topic. The structure is documented below.
     */
    topicConfig?: outputs.MdbKafkaClusterTopicTopicConfig;
}

export interface MdbKafkaClusterTopicTopicConfig {
    cleanupPolicy?: string;
    compressionType?: string;
    deleteRetentionMs?: string;
    fileDeleteDelayMs?: string;
    flushMessages?: string;
    flushMs?: string;
    maxMessageBytes?: string;
    minCompactionLagMs?: string;
    minInsyncReplicas?: string;
    preallocate?: boolean;
    retentionBytes?: string;
    retentionMs?: string;
    segmentBytes?: string;
}

export interface MdbKafkaClusterUser {
    /**
     * The name of the topic.
     */
    name: string;
    /**
     * The password of the user.
     */
    password: string;
    /**
     * Set of permissions granted to the user. The structure is documented below.
     */
    permissions?: outputs.MdbKafkaClusterUserPermission[];
}

export interface MdbKafkaClusterUserPermission {
    /**
     * Set of hosts, to which this permission grants access to.
     */
    allowHosts?: string[];
    /**
     * The role type to grant to the topic.
     */
    role: string;
    /**
     * The name of the topic that the permission grants access to.
     */
    topicName: string;
}

export interface MdbKafkaConnectorConnectorConfigMirrormaker {
    replicationFactor: number;
    sourceCluster: outputs.MdbKafkaConnectorConnectorConfigMirrormakerSourceCluster;
    targetCluster: outputs.MdbKafkaConnectorConnectorConfigMirrormakerTargetCluster;
    topics: string;
}

export interface MdbKafkaConnectorConnectorConfigMirrormakerSourceCluster {
    alias?: string;
    externalClusters?: outputs.MdbKafkaConnectorConnectorConfigMirrormakerSourceClusterExternalCluster[];
    thisClusters?: outputs.MdbKafkaConnectorConnectorConfigMirrormakerSourceClusterThisCluster[];
}

export interface MdbKafkaConnectorConnectorConfigMirrormakerSourceClusterExternalCluster {
    bootstrapServers: string;
    saslMechanism?: string;
    saslPassword?: string;
    saslUsername?: string;
    securityProtocol?: string;
}

export interface MdbKafkaConnectorConnectorConfigMirrormakerSourceClusterThisCluster {
}

export interface MdbKafkaConnectorConnectorConfigMirrormakerTargetCluster {
    alias?: string;
    externalClusters?: outputs.MdbKafkaConnectorConnectorConfigMirrormakerTargetClusterExternalCluster[];
    thisClusters?: outputs.MdbKafkaConnectorConnectorConfigMirrormakerTargetClusterThisCluster[];
}

export interface MdbKafkaConnectorConnectorConfigMirrormakerTargetClusterExternalCluster {
    bootstrapServers: string;
    saslMechanism?: string;
    saslPassword?: string;
    saslUsername?: string;
    securityProtocol?: string;
}

export interface MdbKafkaConnectorConnectorConfigMirrormakerTargetClusterThisCluster {
}

export interface MdbKafkaConnectorConnectorConfigS3Sink {
    fileCompressionType: string;
    fileMaxRecords?: number;
    s3Connection: outputs.MdbKafkaConnectorConnectorConfigS3SinkS3Connection;
    topics: string;
}

export interface MdbKafkaConnectorConnectorConfigS3SinkS3Connection {
    bucketName: string;
    externalS3s: outputs.MdbKafkaConnectorConnectorConfigS3SinkS3ConnectionExternalS3[];
}

export interface MdbKafkaConnectorConnectorConfigS3SinkS3ConnectionExternalS3 {
    accessKeyId?: string;
    endpoint: string;
    region?: string;
    secretAccessKey?: string;
}

export interface MdbKafkaTopicTopicConfig {
    cleanupPolicy?: string;
    compressionType?: string;
    deleteRetentionMs?: string;
    fileDeleteDelayMs?: string;
    flushMessages?: string;
    flushMs?: string;
    maxMessageBytes?: string;
    minCompactionLagMs?: string;
    minInsyncReplicas?: string;
    preallocate?: boolean;
    retentionBytes?: string;
    retentionMs?: string;
    segmentBytes?: string;
}

export interface MdbKafkaUserPermission {
    /**
     * Set of hosts, to which this permission grants access to.
     */
    allowHosts?: string[];
    /**
     * The role type to grant to the topic.
     */
    role: string;
    /**
     * The name of the topic that the permission grants access to.
     */
    topicName: string;
}

export interface MdbMongodbClusterClusterConfig {
    /**
     * Access policy to the MongoDB cluster. The structure is documented below.
     */
    access: outputs.MdbMongodbClusterClusterConfigAccess;
    backupRetainPeriodDays: number;
    /**
     * Time to start the daily backup, in the UTC timezone. The structure is documented below.
     */
    backupWindowStart: outputs.MdbMongodbClusterClusterConfigBackupWindowStart;
    /**
     * Feature compatibility version of MongoDB. If not provided version is taken. Can be either `6.0`, `5.0`, `4.4` and `4.2`.
     */
    featureCompatibilityVersion: string;
    /**
     * Configuration of the mongocfg service. The structure is documented below.
     */
    mongocfg: outputs.MdbMongodbClusterClusterConfigMongocfg;
    /**
     * Configuration of the mongod service. The structure is documented below.
     */
    mongod: outputs.MdbMongodbClusterClusterConfigMongod;
    /**
     * Configuration of the mongos service. The structure is documented below.
     */
    mongos: outputs.MdbMongodbClusterClusterConfigMongos;
    performanceDiagnostics: outputs.MdbMongodbClusterClusterConfigPerformanceDiagnostics;
    /**
     * Version of the MongoDB server software. Can be either `4.2`, `4.4`, `4.4-enterprise`, `5.0`, `5.0-enterprise`, `6.0` and `6.0-enterprise`.
     */
    version: string;
}

export interface MdbMongodbClusterClusterConfigAccess {
    /**
     * Allow access for [Yandex DataLens](https://cloud.yandex.com/services/datalens).
     */
    dataLens?: boolean;
    /**
     * Allow access for [DataTransfer](https://cloud.yandex.com/services/data-transfer)
     */
    dataTransfer?: boolean;
}

export interface MdbMongodbClusterClusterConfigBackupWindowStart {
    /**
     * The hour at which backup will be started.
     */
    hours?: number;
    /**
     * The minute at which backup will be started.
     */
    minutes?: number;
}

export interface MdbMongodbClusterClusterConfigMongocfg {
    /**
     * A set of network settings
     * (see the [net](https://www.mongodb.com/docs/manual/reference/configuration-options/#net-options) option).
     * The structure is documented below.
     */
    net?: outputs.MdbMongodbClusterClusterConfigMongocfgNet;
    /**
     * A set of profiling settings
     * (see the [operationProfiling](https://www.mongodb.com/docs/manual/reference/configuration-options/#operationprofiling-options) option).
     * The structure is documented below.
     */
    operationProfiling?: outputs.MdbMongodbClusterClusterConfigMongocfgOperationProfiling;
    /**
     * A set of storage settings
     * (see the [storage](https://www.mongodb.com/docs/manual/reference/configuration-options/#storage-options) option).
     * The structure is documented below.
     */
    storage?: outputs.MdbMongodbClusterClusterConfigMongocfgStorage;
}

export interface MdbMongodbClusterClusterConfigMongocfgNet {
    /**
     * The maximum number of simultaneous connections that host will accept.
     * For more information, see the [net.maxIncomingConnections](https://www.mongodb.com/docs/manual/reference/configuration-options/#mongodb-setting-net.maxIncomingConnections)
     * description in the official documentation.
     */
    maxIncomingConnections?: number;
}

export interface MdbMongodbClusterClusterConfigMongocfgOperationProfiling {
    /**
     * Specifies which operations should be profiled. The following profiler levels are available: off, slow_op, all.
     * For more information, see the [operationProfiling.mode](https://www.mongodb.com/docs/manual/reference/configuration-options/#mongodb-setting-operationProfiling.mode)
     * description in the official documentation.
     */
    mode?: string;
    /**
     * The slow operation time threshold, in milliseconds. Operations that run for longer than this threshold are considered slow.
     * For more information, see the [operationProfiling.slowOpThresholdMs](https://www.mongodb.com/docs/manual/reference/configuration-options/#mongodb-setting-operationProfiling.slowOpThresholdMs)
     * description in the official documentation.
     */
    slowOpThreshold?: number;
}

export interface MdbMongodbClusterClusterConfigMongocfgStorage {
    /**
     * The WiredTiger engine settings.
     * (see the [storage.wiredTiger](https://www.mongodb.com/docs/manual/reference/configuration-options/#storage.wiredtiger-options) option).
     * These settings available only on `mongod` hosts. The structure is documented below.
     */
    wiredTiger?: outputs.MdbMongodbClusterClusterConfigMongocfgStorageWiredTiger;
}

export interface MdbMongodbClusterClusterConfigMongocfgStorageWiredTiger {
    /**
     * Defines the maximum size of the internal cache that WiredTiger will use for all data.
     * For more information, see the [storage.wiredTiger.engineConfig.cacheSizeGB](https://www.mongodb.com/docs/manual/reference/configuration-options/#mongodb-setting-storage.wiredTiger.engineConfig.cacheSizeGB)
     * description in the official documentation.
     */
    cacheSizeGb?: number;
}

export interface MdbMongodbClusterClusterConfigMongod {
    /**
     * A set of audit log settings 
     * (see the [auditLog](https://www.mongodb.com/docs/manual/reference/configuration-options/#auditlog-options) option).
     * The structure is documented below. Available only in enterprise edition.
     */
    auditLog: outputs.MdbMongodbClusterClusterConfigMongodAuditLog;
    /**
     * A set of network settings
     * (see the [net](https://www.mongodb.com/docs/manual/reference/configuration-options/#net-options) option).
     * The structure is documented below.
     */
    net?: outputs.MdbMongodbClusterClusterConfigMongodNet;
    /**
     * A set of profiling settings
     * (see the [operationProfiling](https://www.mongodb.com/docs/manual/reference/configuration-options/#operationprofiling-options) option).
     * The structure is documented below.
     */
    operationProfiling?: outputs.MdbMongodbClusterClusterConfigMongodOperationProfiling;
    /**
     * A set of MongoDB Security settings
     * (see the [security](https://www.mongodb.com/docs/manual/reference/configuration-options/#security-options) option).
     * The structure is documented below. Available only in enterprise edition.
     */
    security: outputs.MdbMongodbClusterClusterConfigMongodSecurity;
    /**
     * A set of MongoDB Server Parameters 
     * (see the [setParameter](https://www.mongodb.com/docs/manual/reference/configuration-options/#setparameter-option) option).
     * The structure is documented below.
     */
    setParameter: outputs.MdbMongodbClusterClusterConfigMongodSetParameter;
    /**
     * A set of storage settings
     * (see the [storage](https://www.mongodb.com/docs/manual/reference/configuration-options/#storage-options) option).
     * The structure is documented below.
     */
    storage?: outputs.MdbMongodbClusterClusterConfigMongodStorage;
}

export interface MdbMongodbClusterClusterConfigMongodAuditLog {
    /**
     * Configuration of the audit log filter in JSON format.
     * For more information see [auditLog.filter](https://www.mongodb.com/docs/manual/reference/configuration-options/#mongodb-setting-auditLog.filter)
     * description in the official documentation. Available only in enterprise edition.
     */
    filter?: string;
    /**
     * Specifies if a node allows runtime configuration of audit filters and the auditAuthorizationSuccess variable.
     * For more information see [auditLog.runtimeConfiguration](https://www.mongodb.com/docs/manual/reference/configuration-options/#mongodb-setting-auditLog.runtimeConfiguration)
     * description in the official documentation. Available only in enterprise edition.
     */
    runtimeConfiguration?: boolean;
}

export interface MdbMongodbClusterClusterConfigMongodNet {
    /**
     * The maximum number of simultaneous connections that host will accept.
     * For more information, see the [net.maxIncomingConnections](https://www.mongodb.com/docs/manual/reference/configuration-options/#mongodb-setting-net.maxIncomingConnections)
     * description in the official documentation.
     */
    maxIncomingConnections?: number;
}

export interface MdbMongodbClusterClusterConfigMongodOperationProfiling {
    /**
     * Specifies which operations should be profiled. The following profiler levels are available: off, slow_op, all.
     * For more information, see the [operationProfiling.mode](https://www.mongodb.com/docs/manual/reference/configuration-options/#mongodb-setting-operationProfiling.mode)
     * description in the official documentation.
     */
    mode?: string;
    /**
     * The slow operation time threshold, in milliseconds. Operations that run for longer than this threshold are considered slow.
     * For more information, see the [operationProfiling.slowOpThresholdMs](https://www.mongodb.com/docs/manual/reference/configuration-options/#mongodb-setting-operationProfiling.slowOpThresholdMs)
     * description in the official documentation.
     */
    slowOpThreshold?: number;
}

export interface MdbMongodbClusterClusterConfigMongodSecurity {
    /**
     * Enables the encryption for the WiredTiger storage engine. Can be either true or false.
     * For more information see [security.enableEncryption](https://www.mongodb.com/docs/manual/reference/configuration-options/#mongodb-setting-security.enableEncryption)
     * description in the official documentation. Available only in enterprise edition.
     */
    enableEncryption?: boolean;
    /**
     * Configuration of the third party key management appliance via the Key Management Interoperability Protocol (KMIP)
     * (see [Encryption tutorial](https://www.mongodb.com/docs/rapid/tutorial/configure-encryption) ). Requires `enableEncryption` to be true.
     * The structure is documented below. Available only in enterprise edition.
     */
    kmip: outputs.MdbMongodbClusterClusterConfigMongodSecurityKmip;
}

export interface MdbMongodbClusterClusterConfigMongodSecurityKmip {
    /**
     * String containing the client certificate used for authenticating MongoDB to the KMIP server.
     * For more information see [security.kmip.clientCertificateFile](https://www.mongodb.com/docs/manual/reference/configuration-options/#mongodb-setting-security.kmip.clientCertificateFile)
     * description in the official documentation.
     */
    clientCertificate?: string;
    /**
     * Unique KMIP identifier for an existing key within the KMIP server.
     * For more information see [security.kmip.keyIdentifier](https://www.mongodb.com/docs/manual/reference/configuration-options/#mongodb-setting-security.kmip.keyIdentifier)
     * description in the official documentation.
     */
    keyIdentifier?: string;
    /**
     * Port number to use to communicate with the KMIP server. Default: 5696
     * For more information see [security.kmip.port](https://www.mongodb.com/docs/manual/reference/configuration-options/#mongodb-setting-security.kmip.port)
     * description in the official documentation.
     */
    port?: number;
    /**
     * Path to CA File. Used for validating secure client connection to KMIP server.
     * For more information see [security.kmip.serverCAFile](https://www.mongodb.com/docs/manual/reference/configuration-options/#mongodb-setting-security.kmip.serverCAFile)
     * description in the official documentation.
     */
    serverCa?: string;
    /**
     * Hostname or IP address of the KMIP server to connect to.
     * For more information see [security.kmip.serverName](https://www.mongodb.com/docs/manual/reference/configuration-options/#mongodb-setting-security.kmip.serverName)
     * description in the official documentation.
     */
    serverName?: string;
}

export interface MdbMongodbClusterClusterConfigMongodSetParameter {
    /**
     * Enables the auditing of authorization successes. Can be either true or false.
     * For more information, see the [auditAuthorizationSuccess](https://www.mongodb.com/docs/manual/reference/parameters/#mongodb-parameter-param.auditAuthorizationSuccess)
     * description in the official documentation. Available only in enterprise edition.
     */
    auditAuthorizationSuccess?: boolean;
}

export interface MdbMongodbClusterClusterConfigMongodStorage {
    /**
     * The durability journal to ensure data files remain valid and recoverable.
     * The structure is documented below.
     */
    journal?: outputs.MdbMongodbClusterClusterConfigMongodStorageJournal;
    /**
     * The WiredTiger engine settings.
     * (see the [storage.wiredTiger](https://www.mongodb.com/docs/manual/reference/configuration-options/#storage.wiredtiger-options) option).
     * These settings available only on `mongod` hosts. The structure is documented below.
     */
    wiredTiger?: outputs.MdbMongodbClusterClusterConfigMongodStorageWiredTiger;
}

export interface MdbMongodbClusterClusterConfigMongodStorageJournal {
    /**
     * The maximum amount of time in milliseconds that the mongod process allows between journal operations.
     * For more information, see the [storage.journal.commitIntervalMs](https://www.mongodb.com/docs/manual/reference/configuration-options/#mongodb-setting-storage.journal.commitIntervalMs)
     * description in the official documentation.
     */
    commitInterval?: number;
}

export interface MdbMongodbClusterClusterConfigMongodStorageWiredTiger {
    /**
     * Specifies the default compression for collection data. You can override this on a per-collection basis when creating collections.
     * Available compressors are: none, snappy, zlib, zstd. This setting available only on `mongod` hosts.
     * For more information, see the [storage.wiredTiger.collectionConfig.blockCompressor](https://www.mongodb.com/docs/manual/reference/configuration-options/#mongodb-setting-storage.wiredTiger.collectionConfig.blockCompressor)
     * description in the official documentation.
     */
    blockCompressor?: string;
    /**
     * Defines the maximum size of the internal cache that WiredTiger will use for all data.
     * For more information, see the [storage.wiredTiger.engineConfig.cacheSizeGB](https://www.mongodb.com/docs/manual/reference/configuration-options/#mongodb-setting-storage.wiredTiger.engineConfig.cacheSizeGB)
     * description in the official documentation.
     */
    cacheSizeGb?: number;
}

export interface MdbMongodbClusterClusterConfigMongos {
    /**
     * A set of network settings
     * (see the [net](https://www.mongodb.com/docs/manual/reference/configuration-options/#net-options) option).
     * The structure is documented below.
     */
    net?: outputs.MdbMongodbClusterClusterConfigMongosNet;
}

export interface MdbMongodbClusterClusterConfigMongosNet {
    /**
     * The maximum number of simultaneous connections that host will accept.
     * For more information, see the [net.maxIncomingConnections](https://www.mongodb.com/docs/manual/reference/configuration-options/#mongodb-setting-net.maxIncomingConnections)
     * description in the official documentation.
     */
    maxIncomingConnections?: number;
}

export interface MdbMongodbClusterClusterConfigPerformanceDiagnostics {
    enabled?: boolean;
}

export interface MdbMongodbClusterDatabase {
    /**
     * The fully qualified domain name of the host. Computed on server side.
     */
    name: string;
}

export interface MdbMongodbClusterHost {
    /**
     * -(Optional)  Should this host have assigned public IP assigned. Can be either `true` or `false`.
     */
    assignPublicIp: boolean;
    /**
     * The health of the host.
     */
    health: string;
    /**
     * The fully qualified domain name of the host. Computed on server side.
     */
    name: string;
    /**
     * The role of the cluster (either PRIMARY or SECONDARY).
     */
    role: string;
    /**
     * The name of the shard to which the host belongs. Only for sharded cluster.
     */
    shardName: string;
    /**
     * The ID of the subnet, to which the host belongs. The subnet must
     * be a part of the network to which the cluster belongs.
     */
    subnetId: string;
    /**
     * Type of maintenance window. Can be either `ANYTIME` or `WEEKLY`. A day and hour of window need to be specified with weekly window.
     */
    type?: string;
    /**
     * The availability zone where the MongoDB host will be created.
     * For more information see [the official documentation](https://cloud.yandex.com/docs/overview/concepts/geo-scope).
     */
    zoneId: string;
}

export interface MdbMongodbClusterMaintenanceWindow {
    /**
     * Day of week for maintenance window if window type is weekly. Possible values: `MON`, `TUE`, `WED`, `THU`, `FRI`, `SAT`, `SUN`.
     */
    day?: string;
    /**
     * Hour of day in UTC time zone (1-24) for maintenance window if window type is weekly.
     */
    hour?: number;
    /**
     * Type of maintenance window. Can be either `ANYTIME` or `WEEKLY`. A day and hour of window need to be specified with weekly window.
     */
    type: string;
}

export interface MdbMongodbClusterResources {
    /**
     * Volume of the storage available to a MongoDB host, in gigabytes.
     */
    diskSize: number;
    /**
     * Type of the storage of MongoDB hosts.
     * For more information see [the official documentation](https://cloud.yandex.com/docs/managed-clickhouse/concepts/storage).
     */
    diskTypeId: string;
    resourcePresetId: string;
}

export interface MdbMongodbClusterResourcesMongocfg {
    /**
     * Volume of the storage available to a MongoDB host, in gigabytes.
     */
    diskSize: number;
    /**
     * Type of the storage of MongoDB hosts.
     * For more information see [the official documentation](https://cloud.yandex.com/docs/managed-clickhouse/concepts/storage).
     */
    diskTypeId: string;
    resourcePresetId: string;
}

export interface MdbMongodbClusterResourcesMongod {
    /**
     * Volume of the storage available to a MongoDB host, in gigabytes.
     */
    diskSize: number;
    /**
     * Type of the storage of MongoDB hosts.
     * For more information see [the official documentation](https://cloud.yandex.com/docs/managed-clickhouse/concepts/storage).
     */
    diskTypeId: string;
    resourcePresetId: string;
}

export interface MdbMongodbClusterResourcesMongoinfra {
    /**
     * Volume of the storage available to a MongoDB host, in gigabytes.
     */
    diskSize: number;
    /**
     * Type of the storage of MongoDB hosts.
     * For more information see [the official documentation](https://cloud.yandex.com/docs/managed-clickhouse/concepts/storage).
     */
    diskTypeId: string;
    resourcePresetId: string;
}

export interface MdbMongodbClusterResourcesMongos {
    /**
     * Volume of the storage available to a MongoDB host, in gigabytes.
     */
    diskSize: number;
    /**
     * Type of the storage of MongoDB hosts.
     * For more information see [the official documentation](https://cloud.yandex.com/docs/managed-clickhouse/concepts/storage).
     */
    diskTypeId: string;
    resourcePresetId: string;
}

export interface MdbMongodbClusterRestore {
    /**
     * Backup ID. The cluster will be created from the specified backup. [How to get a list of PostgreSQL backups](https://cloud.yandex.com/en-ru/docs/managed-mongodb/operations/cluster-backups)
     */
    backupId: string;
    /**
     * Timestamp of the moment to which the MongoDB cluster should be restored. (Format: "2006-01-02T15:04:05" - UTC). When not set, current time is used.
     */
    time?: string;
}

export interface MdbMongodbClusterUser {
    /**
     * The fully qualified domain name of the host. Computed on server side.
     */
    name: string;
    /**
     * The password of the user.
     */
    password: string;
    /**
     * Set of permissions granted to the user. The structure is documented below.
     */
    permissions: outputs.MdbMongodbClusterUserPermission[];
}

export interface MdbMongodbClusterUserPermission {
    /**
     * The name of the database that the permission grants access to.
     */
    databaseName: string;
    /**
     * The roles of the user in this database. For more information see [the official documentation](https://cloud.yandex.com/docs/managed-mongodb/concepts/users-and-roles).
     */
    roles?: string[];
}

export interface MdbMysqlClusterAccess {
    /**
     * Allow access for [Yandex DataLens](https://cloud.yandex.com/services/datalens).
     */
    dataLens?: boolean;
    /**
     * Allow access for [DataTransfer](https://cloud.yandex.com/services/data-transfer)
     */
    dataTransfer?: boolean;
    /**
     * Allows access for [SQL queries in the management console](https://cloud.yandex.com/docs/managed-mysql/operations/web-sql-query).
     */
    webSql?: boolean;
}

export interface MdbMysqlClusterBackupWindowStart {
    /**
     * The hour at which backup will be started.
     */
    hours?: number;
    /**
     * The minute at which backup will be started.
     */
    minutes?: number;
}

export interface MdbMysqlClusterDatabase {
    /**
     * Host state name. It should be set for all hosts or unset for all hosts. This field can be used by another host, to select which host will be its replication source. Please refer to `replicationSourceName` parameter.
     */
    name: string;
}

export interface MdbMysqlClusterHost {
    /**
     * Sets whether the host should get a public IP address. It can be changed on the fly only when `name` is set.
     */
    assignPublicIp?: boolean;
    /**
     * Host backup priority. Value is between 0 and 100, default is 0.
     */
    backupPriority?: number;
    /**
     * The fully qualified domain name of the host.
     */
    fqdn: string;
    /**
     * Host state name. It should be set for all hosts or unset for all hosts. This field can be used by another host, to select which host will be its replication source. Please refer to `replicationSourceName` parameter.
     */
    name?: string;
    /**
     * Host master promotion priority. Value is between 0 and 100, default is 0.
     */
    priority?: number;
    /**
     * Host replication source (fqdn), when replicationSource is empty then host is in HA group.
     */
    replicationSource: string;
    /**
     * Host replication source name points to host's `name` from which this host should replicate. When not set then host in HA group. It works only when `name` is set.
     */
    replicationSourceName?: string;
    /**
     * The ID of the subnet, to which the host belongs. The subnet must be a part of the network to which the cluster belongs.
     */
    subnetId: string;
    /**
     * The availability zone where the MySQL host will be created.
     */
    zone: string;
}

export interface MdbMysqlClusterMaintenanceWindow {
    /**
     * Day of the week (in `DDD` format). Allowed values: "MON", "TUE", "WED", "THU", "FRI", "SAT", "SUN"
     */
    day?: string;
    /**
     * Hour of the day in UTC (in `HH` format). Allowed value is between 0 and 23.
     */
    hour?: number;
    /**
     * Type of maintenance window. Can be either `ANYTIME` or `WEEKLY`. A day and hour of window need to be specified with weekly window.
     */
    type: string;
}

export interface MdbMysqlClusterPerformanceDiagnostics {
    /**
     * Enable performance diagnostics
     */
    enabled: boolean;
    /**
     * Interval (in seconds) for myStatActivity sampling Acceptable values are 1 to 86400, inclusive.
     */
    sessionsSamplingInterval: number;
    /**
     * Interval (in seconds) for myStatStatements sampling Acceptable values are 1 to 86400, inclusive.
     */
    statementsSamplingInterval: number;
}

export interface MdbMysqlClusterResources {
    /**
     * Volume of the storage available to a MySQL host, in gigabytes.
     */
    diskSize: number;
    /**
     * Type of the storage of MySQL hosts.
     */
    diskTypeId: string;
    resourcePresetId: string;
}

export interface MdbMysqlClusterRestore {
    /**
     * Backup ID. The cluster will be created from the specified backup. [How to get a list of MySQL backups](https://cloud.yandex.com/docs/managed-mysql/operations/cluster-backups).
     */
    backupId: string;
    /**
     * Timestamp of the moment to which the MySQL cluster should be restored. (Format: "2006-01-02T15:04:05" - UTC). When not set, current time is used.
     */
    time?: string;
}

export interface MdbMysqlClusterUser {
    /**
     * Authentication plugin. Allowed values: `MYSQL_NATIVE_PASSWORD`, `CACHING_SHA2_PASSWORD`, `SHA256_PASSWORD` (for version 5.7 `MYSQL_NATIVE_PASSWORD`, `SHA256_PASSWORD`)
     */
    authenticationPlugin: string;
    /**
     * User's connection limits. The structure is documented below.
     * If the attribute is not specified there will be no changes.
     */
    connectionLimits: outputs.MdbMysqlClusterUserConnectionLimits;
    /**
     * List user's global permissions     
     * Allowed permissions:  `REPLICATION_CLIENT`, `REPLICATION_SLAVE`, `PROCESS` for clear list use empty list.
     * If the attribute is not specified there will be no changes.
     */
    globalPermissions: string[];
    /**
     * Host state name. It should be set for all hosts or unset for all hosts. This field can be used by another host, to select which host will be its replication source. Please refer to `replicationSourceName` parameter.
     */
    name: string;
    /**
     * The password of the user.
     */
    password: string;
    /**
     * Set of permissions granted to the user. The structure is documented below.
     */
    permissions: outputs.MdbMysqlClusterUserPermission[];
}

export interface MdbMysqlClusterUserConnectionLimits {
    /**
     * Max connections per hour.
     */
    maxConnectionsPerHour?: number;
    /**
     * Max questions per hour.
     */
    maxQuestionsPerHour?: number;
    /**
     * Max updates per hour.
     */
    maxUpdatesPerHour?: number;
    /**
     * Max user connections.
     */
    maxUserConnections?: number;
}

export interface MdbMysqlClusterUserPermission {
    /**
     * The name of the database that the permission grants access to.
     */
    databaseName: string;
    /**
     * List user's roles in the database.
     * Allowed roles: `ALL`,`ALTER`,`ALTER_ROUTINE`,`CREATE`,`CREATE_ROUTINE`,`CREATE_TEMPORARY_TABLES`,
     * `CREATE_VIEW`,`DELETE`,`DROP`,`EVENT`,`EXECUTE`,`INDEX`,`INSERT`,`LOCK_TABLES`,`SELECT`,`SHOW_VIEW`,`TRIGGER`,`UPDATE`.
     */
    roles?: string[];
}

export interface MdbMysqlUserConnectionLimits {
    /**
     * Max connections per hour.
     */
    maxConnectionsPerHour?: number;
    /**
     * Max questions per hour.
     */
    maxQuestionsPerHour?: number;
    /**
     * Max updates per hour.
     */
    maxUpdatesPerHour?: number;
    /**
     * Max user connections.
     */
    maxUserConnections?: number;
}

export interface MdbMysqlUserPermission {
    /**
     * The name of the database that the permission grants access to.
     */
    databaseName: string;
    /**
     * List user's roles in the database.
     * Allowed roles: `ALL`,`ALTER`,`ALTER_ROUTINE`,`CREATE`,`CREATE_ROUTINE`,`CREATE_TEMPORARY_TABLES`,
     * `CREATE_VIEW`,`DELETE`,`DROP`,`EVENT`,`EXECUTE`,`INDEX`,`INSERT`,`LOCK_TABLES`,`SELECT`,`SHOW_VIEW`,`TRIGGER`,`UPDATE`.
     */
    roles?: string[];
}

export interface MdbPostgresqlClusterConfig {
    access: outputs.MdbPostgresqlClusterConfigAccess;
    autofailover: boolean;
    backupRetainPeriodDays: number;
    backupWindowStart: outputs.MdbPostgresqlClusterConfigBackupWindowStart;
    performanceDiagnostics: outputs.MdbPostgresqlClusterConfigPerformanceDiagnostics;
    poolerConfig?: outputs.MdbPostgresqlClusterConfigPoolerConfig;
    postgresqlConfig: {[key: string]: string};
    resources: outputs.MdbPostgresqlClusterConfigResources;
    version: string;
}

export interface MdbPostgresqlClusterConfigAccess {
    dataLens?: boolean;
    dataTransfer?: boolean;
    serverless?: boolean;
    webSql: boolean;
}

export interface MdbPostgresqlClusterConfigBackupWindowStart {
    hours?: number;
    minutes?: number;
}

export interface MdbPostgresqlClusterConfigPerformanceDiagnostics {
    enabled: boolean;
    sessionsSamplingInterval: number;
    statementsSamplingInterval: number;
}

export interface MdbPostgresqlClusterConfigPoolerConfig {
    poolDiscard?: boolean;
    poolingMode?: string;
}

export interface MdbPostgresqlClusterConfigResources {
    diskSize: number;
    diskTypeId?: string;
    resourcePresetId: string;
}

export interface MdbPostgresqlClusterDatabase {
    extensions?: outputs.MdbPostgresqlClusterDatabaseExtension[];
    lcCollate?: string;
    lcType?: string;
    name: string;
    owner: string;
    templateDb?: string;
}

export interface MdbPostgresqlClusterDatabaseExtension {
    name: string;
    version?: string;
}

export interface MdbPostgresqlClusterHost {
    assignPublicIp?: boolean;
    fqdn: string;
    name: string;
    priority: number;
    replicationSource: string;
    replicationSourceName: string;
    role: string;
    subnetId: string;
    zone: string;
}

export interface MdbPostgresqlClusterMaintenanceWindow {
    day?: string;
    hour?: number;
    type: string;
}

export interface MdbPostgresqlClusterRestore {
    backupId: string;
    time?: string;
    timeInclusive?: boolean;
}

export interface MdbPostgresqlClusterUser {
    connLimit: number;
    grants: string[];
    login?: boolean;
    name: string;
    password: string;
    permissions: outputs.MdbPostgresqlClusterUserPermission[];
    settings: {[key: string]: string};
}

export interface MdbPostgresqlClusterUserPermission {
    databaseName: string;
}

export interface MdbPostgresqlDatabaseExtension {
    /**
     * Name of the database extension. For more information on available extensions see [the official documentation](https://cloud.yandex.com/docs/managed-postgresql/operations/cluster-extensions).
     */
    name: string;
    /**
     * Version of the extension.
     */
    version?: string;
}

export interface MdbPostgresqlUserPermission {
    /**
     * The name of the database that the permission grants access to.
     */
    databaseName: string;
}

export interface MdbRedisClusterConfig {
    /**
     * Normal clients output buffer limits.
     * See [redis config file](https://github.com/redis/redis/blob/6.2/redis.conf#L1841).
     */
    clientOutputBufferLimitNormal: string;
    /**
     * Pubsub clients output buffer limits.
     * See [redis config file](https://github.com/redis/redis/blob/6.2/redis.conf#L1843).
     */
    clientOutputBufferLimitPubsub: string;
    /**
     * Number of databases (changing requires redis-server restart).
     */
    databases: number;
    /**
     * Redis maxmemory usage in percent
     */
    maxmemoryPercent?: number;
    /**
     * Redis key eviction policy for a dataset that reaches maximum memory.
     * Can be any of the listed in [the official RedisDB documentation](https://docs.redislabs.com/latest/rs/administering/database-operations/eviction-policy/).
     */
    maxmemoryPolicy: string;
    /**
     * Select the events that Redis will notify among a set of classes.
     */
    notifyKeyspaceEvents: string;
    /**
     * Password for the Redis cluster.
     */
    password: string;
    /**
     * Log slow queries below this number in microseconds.
     */
    slowlogLogSlowerThan: number;
    /**
     * Slow queries log length.
     */
    slowlogMaxLen: number;
    /**
     * Close the connection after a client is idle for N seconds.
     */
    timeout: number;
    /**
     * Version of Redis (6.2).
     */
    version: string;
}

export interface MdbRedisClusterHost {
    /**
     * Sets whether the host should get a public IP address or not.
     */
    assignPublicIp?: boolean;
    /**
     * The fully qualified domain name of the host.
     */
    fqdn: string;
    /**
     * Replica priority of a current replica (usable for non-sharded only).
     */
    replicaPriority?: number;
    /**
     * The name of the shard to which the host belongs.
     */
    shardName: string;
    /**
     * The ID of the subnet, to which the host belongs. The subnet must
     * be a part of the network to which the cluster belongs.
     */
    subnetId: string;
    /**
     * The availability zone where the Redis host will be created.
     * For more information see [the official documentation](https://cloud.yandex.com/docs/overview/concepts/geo-scope).
     */
    zone: string;
}

export interface MdbRedisClusterMaintenanceWindow {
    /**
     * Day of week for maintenance window if window type is weekly. Possible values: `MON`, `TUE`, `WED`, `THU`, `FRI`, `SAT`, `SUN`.
     */
    day?: string;
    /**
     * Hour of day in UTC time zone (1-24) for maintenance window if window type is weekly.
     */
    hour?: number;
    /**
     * Type of maintenance window. Can be either `ANYTIME` or `WEEKLY`. A day and hour of window need to be specified with weekly window.
     */
    type: string;
}

export interface MdbRedisClusterResources {
    /**
     * Volume of the storage available to a host, in gigabytes.
     */
    diskSize: number;
    /**
     * Type of the storage of Redis hosts - environment default is used if missing.
     */
    diskTypeId: string;
    resourcePresetId: string;
}

export interface MdbSqlServerClusterBackupWindowStart {
    /**
     * The hour at which backup will be started.
     */
    hours?: number;
    /**
     * The minute at which backup will be started.
     */
    minutes?: number;
}

export interface MdbSqlServerClusterDatabase {
    /**
     * The name of the database.
     */
    name: string;
}

export interface MdbSqlServerClusterHost {
    /**
     * Sets whether the host should get a public IP address on creation. Changing this parameter for an existing host is not supported at the moment
     */
    assignPublicIp?: boolean;
    /**
     * The fully qualified domain name of the host.
     */
    fqdn: string;
    /**
     * The ID of the subnet, to which the host belongs. The subnet must be a part of the network to which the cluster belongs.
     */
    subnetId: string;
    /**
     * The availability zone where the SQLServer host will be created.
     */
    zone: string;
}

export interface MdbSqlServerClusterResources {
    /**
     * Volume of the storage available to a SQLServer host, in gigabytes.
     */
    diskSize: number;
    /**
     * Type of the storage of SQLServer hosts.
     */
    diskTypeId: string;
    resourcePresetId: string;
}

export interface MdbSqlServerClusterUser {
    /**
     * The name of the database.
     */
    name: string;
    /**
     * The password of the user.
     */
    password: string;
    /**
     * Set of permissions granted to the user. The structure is documented below.
     */
    permissions?: outputs.MdbSqlServerClusterUserPermission[];
}

export interface MdbSqlServerClusterUserPermission {
    /**
     * The name of the database that the permission grants access to.
     */
    databaseName: string;
    /**
     * List user's roles in the database.
     * Allowed roles: `OWNER`, `SECURITYADMIN`, `ACCESSADMIN`, `BACKUPOPERATOR`, `DDLADMIN`, `DATAWRITER`, `DATAREADER`, `DENYDATAWRITER`, `DENYDATAREADER`.
     */
    roles?: string[];
}

export interface MonitoringDashboardParametrization {
    /**
     * parameters list.
     */
    parameters?: outputs.MonitoringDashboardParametrizationParameter[];
    /**
     * Selectors to select metric label values.
     */
    selectors?: string;
}

export interface MonitoringDashboardParametrizationParameter {
    /**
     * Custom values parameter. Oneof: label_values, custom, text.
     */
    customs?: outputs.MonitoringDashboardParametrizationParameterCustom[];
    /**
     * Chart description in dashboard (not enabled in UI).
     */
    description?: string;
    /**
     * Checks that target is visible or invisible.
     */
    hidden?: boolean;
    /**
     * Parameter identifier
     */
    id: string;
    /**
     * Label values parameter. Oneof: label_values, custom, text.
     */
    labelValues?: outputs.MonitoringDashboardParametrizationParameterLabelValue[];
    /**
     * Title text.
     */
    texts?: outputs.MonitoringDashboardParametrizationParameterText[];
    /**
     * -Title or empty.
     */
    title?: string;
}

export interface MonitoringDashboardParametrizationParameterCustom {
    /**
     * Default value.
     */
    defaultValues?: string[];
    /**
     * Specifies the multiselectable values of parameter.
     */
    multiselectable?: boolean;
    /**
     * Parameter values.
     */
    values?: string[];
}

export interface MonitoringDashboardParametrizationParameterLabelValue {
    /**
     * Default value.
     */
    defaultValues?: string[];
    /**
     * Labels folder ID.
     */
    folderId?: string;
    /**
     * Label key to list label values.
     */
    labelKey: string;
    /**
     * Specifies the multiselectable values of parameter.
     */
    multiselectable?: boolean;
    /**
     * Selectors to select metric label values.
     */
    selectors?: string;
}

export interface MonitoringDashboardParametrizationParameterText {
    /**
     * Default value.
     */
    defaultValue?: string;
}

export interface MonitoringDashboardWidget {
    /**
     * Chart widget settings. Oneof: text, title or chart.
     */
    charts?: outputs.MonitoringDashboardWidgetChart[];
    /**
     * Widget position.
     */
    positions?: outputs.MonitoringDashboardWidgetPosition[];
    /**
     * Title text.
     */
    texts?: outputs.MonitoringDashboardWidgetText[];
    /**
     * -Title or empty.
     */
    titles?: outputs.MonitoringDashboardWidgetTitle[];
}

export interface MonitoringDashboardWidgetChart {
    /**
     * Chart ID.
     */
    chartId?: string;
    /**
     * Chart description in dashboard (not enabled in UI).
     */
    description?: string;
    /**
     * Enable legend under chart.
     */
    displayLegend?: boolean;
    /**
     * Fixed time interval for chart. Values:
     * - FREEZE_DURATION_HOUR: Last hour.
     * - FREEZE_DURATION_DAY: Last day = last 24 hours.
     * - FREEZE_DURATION_WEEK: Last 7 days.
     * - FREEZE_DURATION_MONTH: Last 31 days.
     */
    freeze: string;
    /**
     * Names settings.
     */
    nameHidingSettings?: outputs.MonitoringDashboardWidgetChartNameHidingSetting[];
    /**
     * Queries settings.
     */
    queries?: outputs.MonitoringDashboardWidgetChartQuery[];
    /**
     * Time series settings.
     */
    seriesOverrides?: outputs.MonitoringDashboardWidgetChartSeriesOverride[];
    /**
     * -Title or empty.
     */
    title?: string;
    /**
     * Visualization settings.
     */
    visualizationSettings?: outputs.MonitoringDashboardWidgetChartVisualizationSetting[];
}

export interface MonitoringDashboardWidgetChartNameHidingSetting {
    /**
     * Series name.
     */
    names?: string[];
    /**
     * True if we want to show concrete series names only, false if we want to hide concrete series names.
     */
    positive?: boolean;
}

export interface MonitoringDashboardWidgetChartQuery {
    /**
     * Downsamplang settings.
     */
    downsamplings?: outputs.MonitoringDashboardWidgetChartQueryDownsampling[];
    /**
     * Query targets.
     */
    targets?: outputs.MonitoringDashboardWidgetChartQueryTarget[];
}

export interface MonitoringDashboardWidgetChartQueryDownsampling {
    /**
     * Disable downsampling.
     */
    disabled?: boolean;
    /**
     * Parameters for filling gaps in data.
     */
    gapFilling?: string;
    /**
     * Function that is used for downsampling.
     */
    gridAggregation?: string;
    /**
     * Time interval (grid) for downsampling in milliseconds. Points in the specified range are aggregated into one time point
     */
    gridInterval?: number;
    /**
     * Maximum number of points to be returned.
     */
    maxPoints?: number;
}

export interface MonitoringDashboardWidgetChartQueryTarget {
    /**
     * Checks that target is visible or invisible.
     */
    hidden?: boolean;
    /**
     * Query.
     */
    query?: string;
    /**
     * Text mode enabled.
     */
    textMode?: boolean;
}

export interface MonitoringDashboardWidgetChartSeriesOverride {
    /**
     * Series name or empty.
     */
    name?: string;
    /**
     * Override settings.
     */
    settings?: outputs.MonitoringDashboardWidgetChartSeriesOverrideSetting[];
    /**
     * Series index. Oneof: name or target_index.
     */
    targetIndex?: string;
}

export interface MonitoringDashboardWidgetChartSeriesOverrideSetting {
    /**
     * Series color or empty.
     */
    color?: string;
    /**
     * Stack grow down.
     */
    growDown?: boolean;
    /**
     * Series name or empty.
     */
    name?: string;
    /**
     * Stack name or empty.
     */
    stackName?: string;
    /**
     * Type.
     */
    type: string;
    /**
     * Yaxis position.
     */
    yaxisPosition: string;
}

export interface MonitoringDashboardWidgetChartVisualizationSetting {
    /**
     * Aggregation. Values:
     * - SERIES_AGGREGATION_UNSPECIFIED: Not specified (avg by default).
     * - SERIES_AGGREGATION_AVG: Average.
     * - SERIES_AGGREGATION_MIN: Minimum.
     * - SERIES_AGGREGATION_MAX: Maximum.
     * - SERIES_AGGREGATION_LAST: Last non-NaN value.
     * - SERIES_AGGREGATION_SUM: Sum.
     */
    aggregation: string;
    /**
     * Color settings.
     */
    colorSchemeSettings?: outputs.MonitoringDashboardWidgetChartVisualizationSettingColorSchemeSetting[];
    /**
     * Heatmap settings.
     */
    heatmapSettings?: outputs.MonitoringDashboardWidgetChartVisualizationSettingHeatmapSetting[];
    /**
     * Interpolate values. Values:
     * - INTERPOLATE_UNSPECIFIED: Not specified (linear by default).
     * - INTERPOLATE_LINEAR: Linear.
     * - INTERPOLATE_LEFT: Left.
     * - INTERPOLATE_RIGHT: Right.
     */
    interpolate: string;
    /**
     * Normalize values.
     */
    normalize?: boolean;
    /**
     * Show chart labels.
     */
    showLabels?: boolean;
    /**
     * -Title or empty.
     */
    title?: string;
    /**
     * Type.
     */
    type: string;
    /**
     * Y axis settings.
     */
    yaxisSettings?: outputs.MonitoringDashboardWidgetChartVisualizationSettingYaxisSetting[];
}

export interface MonitoringDashboardWidgetChartVisualizationSettingColorSchemeSetting {
    /**
     * Automatic color scheme. Oneof: automatic, standard or gradient.
     */
    automatics?: outputs.MonitoringDashboardWidgetChartVisualizationSettingColorSchemeSettingAutomatic[];
    /**
     * Gradient color scheme. Oneof: automatic, standard or gradient.
     */
    gradients?: outputs.MonitoringDashboardWidgetChartVisualizationSettingColorSchemeSettingGradient[];
    /**
     * Standard color scheme. Oneof: automatic, standard or gradient.
     */
    standards?: outputs.MonitoringDashboardWidgetChartVisualizationSettingColorSchemeSettingStandard[];
}

export interface MonitoringDashboardWidgetChartVisualizationSettingColorSchemeSettingAutomatic {
}

export interface MonitoringDashboardWidgetChartVisualizationSettingColorSchemeSettingGradient {
    /**
     * Heatmap green value.
     */
    greenValue?: string;
    /**
     * Heatmap red value.
     */
    redValue?: string;
    /**
     * Heatmap violet value.
     */
    violetValue?: string;
    /**
     * Heatmap yellow value.
     */
    yellowValue?: string;
}

export interface MonitoringDashboardWidgetChartVisualizationSettingColorSchemeSettingStandard {
}

export interface MonitoringDashboardWidgetChartVisualizationSettingHeatmapSetting {
    /**
     * Heatmap green value.
     */
    greenValue?: string;
    /**
     * Heatmap red value.
     */
    redValue?: string;
    /**
     * Heatmap violet value.
     */
    violetValue?: string;
    /**
     * Heatmap yellow value.
     */
    yellowValue?: string;
}

export interface MonitoringDashboardWidgetChartVisualizationSettingYaxisSetting {
    /**
     * Left yaxis config.
     */
    lefts?: outputs.MonitoringDashboardWidgetChartVisualizationSettingYaxisSettingLeft[];
    /**
     * Right yaxis config.
     */
    rights?: outputs.MonitoringDashboardWidgetChartVisualizationSettingYaxisSettingRight[];
}

export interface MonitoringDashboardWidgetChartVisualizationSettingYaxisSettingLeft {
    /**
     * Max value in extended number format or empty.
     */
    max?: string;
    /**
     * Min value in extended number format or empty.
     */
    min?: string;
    /**
     * Tick value precision (null as default, 0-7 in other cases).
     */
    precision?: number;
    /**
     * -Title or empty.
     */
    title?: string;
    /**
     * Type.
     */
    type: string;
    /**
     * Unit format.
     */
    unitFormat: string;
}

export interface MonitoringDashboardWidgetChartVisualizationSettingYaxisSettingRight {
    /**
     * Max value in extended number format or empty.
     */
    max?: string;
    /**
     * Min value in extended number format or empty.
     */
    min?: string;
    /**
     * Tick value precision (null as default, 0-7 in other cases).
     */
    precision?: number;
    /**
     * -Title or empty.
     */
    title?: string;
    /**
     * Type.
     */
    type?: string;
    /**
     * Unit format.
     */
    unitFormat?: string;
}

export interface MonitoringDashboardWidgetPosition {
    /**
     * Height.
     */
    h?: number;
    /**
     * Width.
     */
    w?: number;
    /**
     * X-axis top-left corner coordinate.
     */
    x?: number;
    /**
     * Y-axis top-left corner coordinate.
     */
    y?: number;
}

export interface MonitoringDashboardWidgetText {
    /**
     * Title text.
     */
    text?: string;
}

export interface MonitoringDashboardWidgetTitle {
    /**
     * Title size. Values: 
     * - TITLE_SIZE_XS: Extra small size.
     * - TITLE_SIZE_S: Small size.
     * - TITLE_SIZE_M: Middle size.
     * - TITLE_SIZE_L: Large size.
     */
    size: string;
    /**
     * Title text.
     */
    text: string;
}

export interface OrganizationmanagerSamlFederationSecuritySettings {
    /**
     * Enable encrypted assertions.
     */
    encryptedAssertions: boolean;
}

export interface ServerlessContainerConnectivity {
    networkId: string;
}

export interface ServerlessContainerImage {
    args?: string[];
    commands?: string[];
    digest: string;
    environment?: {[key: string]: string};
    /**
     * Invoke URL for the Yandex Cloud Serverless Container
     */
    url: string;
    workDir?: string;
}

export interface ServerlessContainerSecret {
    /**
     * (Required) Container's environment variable in which secret's value will be stored.
     */
    environmentVariable: string;
    /**
     * (Required) Secret's id.
     */
    id: string;
    /**
     * (Required) Secret's entries key which value will be stored in environment variable.
     */
    key: string;
    /**
     * (Required) Secret's version id.
     */
    versionId: string;
}

export interface StorageBucketAnonymousAccessFlags {
    configRead?: boolean;
    /**
     * Allows to list object in bucket anonymously.
     */
    list?: boolean;
    /**
     * Allows to read objects in bucket anonymously.
     */
    read?: boolean;
}

export interface StorageBucketCorsRule {
    /**
     * Specifies which headers are allowed.
     */
    allowedHeaders?: string[];
    /**
     * Specifies which methods are allowed. Can be `GET`, `PUT`, `POST`, `DELETE` or `HEAD`.
     */
    allowedMethods: string[];
    /**
     * Specifies which origins are allowed.
     */
    allowedOrigins: string[];
    /**
     * Specifies expose header in the response.
     */
    exposeHeaders?: string[];
    /**
     * Specifies time in seconds that browser can cache the response for a preflight request.
     */
    maxAgeSeconds?: number;
}

export interface StorageBucketGrant {
    /**
     * Unique identifier for the rule. Must be less than or equal to 255 characters in length.
     */
    id?: string;
    permissions: string[];
    type: string;
    uri?: string;
}

export interface StorageBucketHttps {
    /**
     * — Id of the certificate in Certificate Manager, that will be used for bucket.
     */
    certificateId: string;
}

export interface StorageBucketLifecycleRule {
    /**
     * Specifies the number of days after initiating a multipart upload when the multipart upload must be completed.
     */
    abortIncompleteMultipartUploadDays?: number;
    /**
     * Specifies lifecycle rule status.
     */
    enabled: boolean;
    /**
     * Specifies a period in the object's expire (documented below).
     */
    expiration?: outputs.StorageBucketLifecycleRuleExpiration;
    /**
     * Unique identifier for the rule. Must be less than or equal to 255 characters in length.
     */
    id: string;
    /**
     * Specifies when noncurrent object versions expire (documented below).
     */
    noncurrentVersionExpiration?: outputs.StorageBucketLifecycleRuleNoncurrentVersionExpiration;
    /**
     * Specifies when noncurrent object versions transitions (documented below).
     */
    noncurrentVersionTransitions?: outputs.StorageBucketLifecycleRuleNoncurrentVersionTransition[];
    /**
     * Object key prefix identifying one or more objects to which the rule applies.
     */
    prefix?: string;
    tags?: {[key: string]: string};
    /**
     * Specifies a period in the object's transitions (documented below).
     */
    transitions?: outputs.StorageBucketLifecycleRuleTransition[];
}

export interface StorageBucketLifecycleRuleExpiration {
    /**
     * Specifies the date after which you want the corresponding action to take effect.
     */
    date?: string;
    /**
     * Specifies the number of days after object creation when the specific rule action takes effect.
     */
    days?: number;
    /**
     * On a versioned bucket (versioning-enabled or versioning-suspended bucket), you can add this element in the lifecycle configuration to direct Object Storage to delete expired object delete markers.
     */
    expiredObjectDeleteMarker?: boolean;
}

export interface StorageBucketLifecycleRuleNoncurrentVersionExpiration {
    /**
     * Specifies the number of days noncurrent object versions expire.
     */
    days?: number;
}

export interface StorageBucketLifecycleRuleNoncurrentVersionTransition {
    /**
     * Specifies the number of days noncurrent object versions transition.
     */
    days?: number;
    /**
     * Specifies the storage class to which you want the noncurrent object versions to transition. Supported values: [`STANDARD_IA`, `COLD`, `ICE`].
     */
    storageClass: string;
}

export interface StorageBucketLifecycleRuleTransition {
    /**
     * Specifies the date after which you want the corresponding action to take effect.
     */
    date?: string;
    /**
     * Specifies the number of days after object creation when the specific rule action takes effect.
     */
    days?: number;
    /**
     * Specifies the storage class to which you want the object to transition. Supported values: [`STANDARD_IA`, `COLD`, `ICE`].
     */
    storageClass: string;
}

export interface StorageBucketLogging {
    /**
     * The name of the bucket that will receive the log objects.
     */
    targetBucket: string;
    /**
     * To specify a key prefix for log objects.
     */
    targetPrefix?: string;
}

export interface StorageBucketObjectLockConfiguration {
    /**
     * Enable object locking in a bucket. Require versioning to be enabled.
     */
    objectLockEnabled?: string;
    /**
     * Specifies a default locking configuration for added objects. Require objectLockEnabled to be enabled.
     */
    rule?: outputs.StorageBucketObjectLockConfigurationRule;
}

export interface StorageBucketObjectLockConfigurationRule {
    defaultRetention: outputs.StorageBucketObjectLockConfigurationRuleDefaultRetention;
}

export interface StorageBucketObjectLockConfigurationRuleDefaultRetention {
    /**
     * Specifies a retention period in days after uploading an object version. It must be a positive integer. You can't set it simultaneously with `years`.
     */
    days?: number;
    /**
     * Specifies a type of object lock. One of `["GOVERNANCE", "COMPLIANCE"]`.
     */
    mode: string;
    /**
     * Specifies a retention period in years after uploading an object version. It must be a positive integer. You can't set it simultaneously with `days`.
     */
    years?: number;
}

export interface StorageBucketServerSideEncryptionConfiguration {
    /**
     * A single object for server-side encryption by default configuration. (documented below)
     */
    rule: outputs.StorageBucketServerSideEncryptionConfigurationRule;
}

export interface StorageBucketServerSideEncryptionConfigurationRule {
    /**
     * A single object for setting server-side encryption by default. (documented below)
     */
    applyServerSideEncryptionByDefault: outputs.StorageBucketServerSideEncryptionConfigurationRuleApplyServerSideEncryptionByDefault;
}

export interface StorageBucketServerSideEncryptionConfigurationRuleApplyServerSideEncryptionByDefault {
    /**
     * The KMS master key ID used for the SSE-KMS encryption.
     */
    kmsMasterKeyId: string;
    /**
     * The server-side encryption algorithm to use. Single valid value is `aws:kms`
     */
    sseAlgorithm: string;
}

export interface StorageBucketVersioning {
    /**
     * Enable versioning. Once you version-enable a bucket, it can never return to an unversioned state. You can, however, suspend versioning on that bucket.
     */
    enabled?: boolean;
}

export interface StorageBucketWebsite {
    /**
     * An absolute path to the document to return in case of a 4XX error.
     */
    errorDocument?: string;
    /**
     * Storage returns this index document when requests are made to the root domain or any of the subfolders.
     */
    indexDocument?: string;
    /**
     * A hostname to redirect all website requests for this bucket to. Hostname can optionally be prefixed with a protocol (`http://` or `https://`) to use when redirecting requests. The default is the protocol that is used in the original request.
     */
    redirectAllRequestsTo?: string;
    /**
     * A json array containing [routing rules](https://cloud.yandex.com/docs/storage/s3/api-ref/hosting/upload#request-scheme) describing redirect behavior and when redirects are applied.
     */
    routingRules?: string;
}

export interface VpcAddressExternalIpv4Address {
    /**
     * Allocated IP address.
     */
    address: string;
    /**
     * Enable DDOS protection. Possible values are: "qrator"
     */
    ddosProtectionProvider: string;
    /**
     * Wanted outgoing smtp capability.
     */
    outgoingSmtpCapability: string;
    /**
     * Zone for allocating address.
     */
    zoneId: string;
}

export interface VpcDefaultSecurityGroupEgress {
    /**
     * Description of the security group.
     */
    description?: string;
    fromPort?: number;
    /**
     * Id of the security group.
     */
    id: string;
    /**
     * Labels to assign to this security group.
     */
    labels: {[key: string]: string};
    port?: number;
    predefinedTarget?: string;
    protocol: string;
    securityGroupId?: string;
    toPort?: number;
    v4CidrBlocks?: string[];
    v6CidrBlocks?: string[];
}

export interface VpcDefaultSecurityGroupIngress {
    /**
     * Description of the security group.
     */
    description?: string;
    fromPort?: number;
    /**
     * Id of the security group.
     */
    id: string;
    /**
     * Labels to assign to this security group.
     */
    labels: {[key: string]: string};
    port?: number;
    predefinedTarget?: string;
    protocol: string;
    securityGroupId?: string;
    toPort?: number;
    v4CidrBlocks?: string[];
    v6CidrBlocks?: string[];
}

export interface VpcGatewaySharedEgressGateway {
}

export interface VpcRouteTableStaticRoute {
    /**
     * Route prefix in CIDR notation.
     */
    destinationPrefix?: string;
    /**
     * ID of the gateway used ad next hop.
     */
    gatewayId?: string;
    /**
     * Address of the next hop.
     */
    nextHopAddress?: string;
}

export interface VpcSecurityGroupEgress {
    /**
     * Description of the security group.
     */
    description?: string;
    fromPort?: number;
    /**
     * Id of the rule.
     */
    id: string;
    /**
     * Labels to assign to this security group.
     */
    labels: {[key: string]: string};
    port?: number;
    predefinedTarget?: string;
    protocol: string;
    securityGroupId?: string;
    toPort?: number;
    v4CidrBlocks?: string[];
    v6CidrBlocks?: string[];
}

export interface VpcSecurityGroupIngress {
    /**
     * Description of the security group.
     */
    description?: string;
    fromPort?: number;
    /**
     * Id of the rule.
     */
    id: string;
    /**
     * Labels to assign to this security group.
     */
    labels: {[key: string]: string};
    port?: number;
    predefinedTarget?: string;
    protocol: string;
    securityGroupId?: string;
    toPort?: number;
    v4CidrBlocks?: string[];
    v6CidrBlocks?: string[];
}

export interface VpcSubnetDhcpOptions {
    /**
     * Domain name.
     */
    domainName?: string;
    /**
     * Domain name server IP addresses.
     */
    domainNameServers?: string[];
    /**
     * NTP server IP addresses.
     */
    ntpServers?: string[];
}

export interface YandexYdbTableColumn {
    family: string;
    name: string;
    notNull: boolean;
    type: string;
}

export interface YandexYdbTableFamily {
    compression: string;
    data: string;
    name: string;
}

export interface YandexYdbTablePartitioningSettings {
    autoPartitioningByLoad?: boolean;
    autoPartitioningBySizeEnabled?: boolean;
    autoPartitioningMaxPartitionsCount: number;
    autoPartitioningMinPartitionsCount: number;
    autoPartitioningPartitionSizeMb: number;
    partitionAtKeys: outputs.YandexYdbTablePartitioningSettingsPartitionAtKey[];
    uniformPartitions: number;
}

export interface YandexYdbTablePartitioningSettingsPartitionAtKey {
    keys: string[];
}

export interface YandexYdbTableTtl {
    columnName: string;
    expireInterval: string;
    unit: string;
}

export interface YandexYdbTopicChangefeedConsumer {
    name: string;
    startingMessageTimestampMs: number;
    supportedCodecs: string[];
}

export interface YandexYdbTopicConsumer {
    /**
     * Topic name. Type: string, required. Default value: "".
     */
    name: string;
    startingMessageTimestampMs: number;
    /**
     * Supported data encodings. Types: array[string]. Default value: ["gzip", "raw", "zstd"].
     */
    supportedCodecs: string[];
}

export interface YdbDatabaseDedicatedLocation {
    /**
     * Region for the Yandex Database cluster.
     * The structure is documented below.
     */
    region?: outputs.YdbDatabaseDedicatedLocationRegion;
}

export interface YdbDatabaseDedicatedLocationRegion {
    /**
     * Region ID for the Yandex Database cluster.
     */
    id: string;
}

export interface YdbDatabaseDedicatedScalePolicy {
    /**
     * Fixed scaling policy for the Yandex Database cluster.
     * The structure is documented below.
     */
    fixedScale: outputs.YdbDatabaseDedicatedScalePolicyFixedScale;
}

export interface YdbDatabaseDedicatedScalePolicyFixedScale {
    /**
     * Number of instances for the Yandex Database cluster.
     */
    size: number;
}

export interface YdbDatabaseDedicatedStorageConfig {
    /**
     * Amount of storage groups of selected type for the Yandex Database cluster.
     */
    groupCount: number;
    /**
     * Storage type ID for the Yandex Database cluster.
     * Available presets can be obtained via `yc ydb storage-type list` command.
     */
    storageTypeId: string;
}

export interface YdbDatabaseServerlessServerlessDatabase {
    enableThrottlingRcuLimit: boolean;
    provisionedRcuLimit: number;
    storageSizeLimit: number;
    throttlingRcuLimit: number;
}

